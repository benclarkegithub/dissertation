Encoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Encoder                                  --
├─Linear: 1-1                            76,930
├─Linear: 1-2                            4,851
=================================================================
Total params: 81,781
Trainable params: 81,781
Non-trainable params: 0
=================================================================
Encoder to Latents 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 4
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 5
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 6
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 7
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 8
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 9
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Latents to Decoder 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 4
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 5
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 6
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 7
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 8
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 9
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Decoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Decoder                                  --
├─Linear: 1-1                            4,900
├─Linear: 1-2                            77,616
=================================================================
Total params: 82,516
Trainable params: 82,516
Non-trainable params: 0
=================================================================
[Epoch   1 (35.47s)]	ELBO: 1123.658, 1261.788, 1286.954, 1293.679, 1297.740, 1299.244, 1300.493, 1299.905, 1298.818, 1297.599 (1392.256)	Log prob: 1173.200, 1273.679, 1289.275, 1294.469, 1298.365, 1300.184, 1300.905, 1300.465, 1299.330, 1297.843 (1425.810)	KLD: 49.542, 11.891, 2.321, 0.791, 0.624, 0.940, 0.412, 0.559, 0.511, 0.244 (33.554)	Grad: 0.146, 0.220, 0.279, 0.333, 0.390, 0.448, 0.512, 0.584, 0.664, 0.752
[Epoch   2 (39.30s)]	ELBO: 1330.223, 1405.403, 1440.301, 1449.046, 1455.357, 1456.833, 1458.280, 1459.060, 1458.971, 1459.039 (1495.609)	Log prob: 1345.737, 1410.512, 1443.538, 1450.330, 1456.418, 1457.381, 1458.859, 1459.328, 1459.265, 1459.152 (1524.865)	KLD: 15.515, 5.109, 3.236, 1.283, 1.060, 0.548, 0.579, 0.268, 0.295, 0.112 (29.256)	Grad: 0.082, 0.120, 0.153, 0.189, 0.229, 0.269, 0.313, 0.356, 0.402, 0.450
[Epoch   3 (40.16s)]	ELBO: 1360.218, 1423.972, 1471.459, 1513.909, 1539.003, 1548.160, 1551.703, 1553.368, 1553.660, 1553.682 (1566.152)	Log prob: 1367.492, 1427.691, 1474.173, 1517.968, 1541.092, 1549.691, 1552.769, 1553.970, 1553.828, 1554.020 (1587.705)	KLD: 7.275, 3.719, 2.715, 4.060, 2.090, 1.530, 1.065, 0.602, 0.169, 0.340 (21.553)	Grad: 0.096, 0.138, 0.172, 0.206, 0.244, 0.283, 0.323, 0.366, 0.411, 0.458
[Epoch   4 (42.81s)]	ELBO: 1381.478, 1446.518, 1493.303, 1532.146, 1564.844, 1582.158, 1591.604, 1594.457, 1596.720, 1597.951 (1597.443)	Log prob: 1385.739, 1449.676, 1495.796, 1534.712, 1567.055, 1584.254, 1593.059, 1595.310, 1597.486, 1598.680 (1617.657)	KLD: 4.263, 3.159, 2.493, 2.565, 2.210, 2.097, 1.455, 0.853, 0.767, 0.728 (20.214)	Grad: 0.094, 0.135, 0.171, 0.208, 0.245, 0.280, 0.318, 0.357, 0.400, 0.443
[Epoch   5 (40.66s)]	ELBO: 1390.805, 1459.051, 1507.401, 1545.039, 1579.630, 1598.060, 1611.278, 1616.297, 1619.337, 1620.756 (1611.541)	Log prob: 1394.324, 1462.208, 1509.952, 1547.486, 1581.799, 1600.047, 1612.953, 1617.465, 1620.283, 1621.415 (1631.481)	KLD: 3.520, 3.156, 2.551, 2.448, 2.167, 1.986, 1.676, 1.168, 0.947, 0.658 (19.940)	Grad: 0.097, 0.148, 0.185, 0.228, 0.264, 0.298, 0.335, 0.375, 0.417, 0.460
[Epoch   6 (40.11s)]	ELBO: 1397.258, 1468.515, 1517.048, 1551.517, 1586.515, 1604.816, 1618.120, 1625.995, 1629.870, 1630.895 (1620.247)	Log prob: 1400.698, 1471.766, 1519.647, 1553.892, 1588.714, 1606.727, 1619.814, 1627.398, 1630.788, 1631.479 (1640.960)	KLD: 3.439, 3.251, 2.599, 2.373, 2.197, 1.910, 1.694, 1.402, 0.919, 0.584 (20.713)	Grad: 0.127, 0.169, 0.203, 0.250, 0.285, 0.320, 0.359, 0.399, 0.443, 0.487
[Epoch   7 (47.65s)]	ELBO: 1401.738, 1476.735, 1523.068, 1556.032, 1590.900, 1609.991, 1622.851, 1631.513, 1636.841, 1638.697 (1625.513)	Log prob: 1405.224, 1479.976, 1525.686, 1558.386, 1593.109, 1611.922, 1624.523, 1632.989, 1637.912, 1639.418 (1646.372)	KLD: 3.486, 3.242, 2.618, 2.355, 2.209, 1.932, 1.672, 1.475, 1.069, 0.721 (20.859)	Grad: 0.109, 0.156, 0.185, 0.226, 0.259, 0.292, 0.326, 0.363, 0.402, 0.443
[Epoch   8 (42.77s)]	ELBO: 1404.978, 1484.300, 1528.267, 1559.698, 1593.271, 1612.680, 1625.468, 1634.934, 1641.329, 1644.551 (1631.460)	Log prob: 1408.452, 1487.542, 1530.900, 1562.017, 1595.492, 1614.630, 1627.121, 1636.447, 1642.545, 1645.542 (1652.595)	KLD: 3.473, 3.242, 2.634, 2.319, 2.220, 1.950, 1.653, 1.512, 1.216, 0.990 (21.135)	Grad: 0.111, 0.159, 0.189, 0.229, 0.262, 0.296, 0.331, 0.369, 0.409, 0.450
[Epoch   9 (41.53s)]	ELBO: 1408.322, 1490.878, 1534.279, 1563.644, 1594.922, 1614.033, 1627.078, 1637.531, 1644.922, 1648.752 (1630.181)	Log prob: 1411.732, 1494.115, 1536.985, 1565.944, 1597.165, 1615.990, 1628.718, 1639.155, 1646.224, 1649.828 (1652.509)	KLD: 3.410, 3.238, 2.707, 2.302, 2.243, 1.957, 1.640, 1.623, 1.303, 1.076 (22.328)	Grad: 0.090, 0.155, 0.186, 0.225, 0.259, 0.291, 0.325, 0.362, 0.400, 0.440
[Epoch  10 (52.57s)]	ELBO: 1412.653, 1495.241, 1540.102, 1569.009, 1596.043, 1614.821, 1628.460, 1639.105, 1646.697, 1650.767 (1632.084)	Log prob: 1416.005, 1498.496, 1542.902, 1571.297, 1598.288, 1616.769, 1630.118, 1640.790, 1648.092, 1651.900 (1654.151)	KLD: 3.352, 3.255, 2.801, 2.286, 2.245, 1.947, 1.658, 1.684, 1.394, 1.133 (22.067)	Grad: 0.086, 0.153, 0.184, 0.221, 0.260, 0.293, 0.328, 0.368, 0.408, 0.450
[Epoch  11 (44.39s)]	ELBO: 1417.561, 1498.963, 1544.604, 1573.654, 1595.806, 1614.632, 1628.779, 1639.743, 1647.486, 1652.443 (1634.438)	Log prob: 1420.888, 1502.230, 1547.485, 1575.953, 1598.022, 1616.595, 1630.491, 1641.479, 1648.898, 1653.676 (1656.104)	KLD: 3.327, 3.267, 2.882, 2.299, 2.216, 1.963, 1.711, 1.737, 1.413, 1.233 (21.666)	Grad: 0.081, 0.144, 0.182, 0.220, 0.260, 0.294, 0.330, 0.371, 0.412, 0.456
[Epoch  12 (43.75s)]	ELBO: 1422.815, 1501.638, 1548.298, 1578.088, 1595.664, 1614.545, 1629.254, 1640.029, 1648.348, 1654.038 (1635.081)	Log prob: 1426.232, 1504.882, 1551.233, 1580.398, 1597.827, 1616.547, 1630.986, 1641.808, 1649.796, 1655.354 (1657.504)	KLD: 3.416, 3.244, 2.935, 2.311, 2.162, 2.002, 1.732, 1.779, 1.448, 1.314 (22.423)	Grad: 0.075, 0.147, 0.182, 0.217, 0.254, 0.288, 0.322, 0.362, 0.402, 0.443
[Epoch  13 (42.01s)]	ELBO: 1429.656, 1502.290, 1549.855, 1579.820, 1595.182, 1614.361, 1629.305, 1640.360, 1649.077, 1655.152 (1636.878)	Log prob: 1433.399, 1505.504, 1552.789, 1582.176, 1597.290, 1616.417, 1631.058, 1642.173, 1650.545, 1656.469 (1659.568)	KLD: 3.743, 3.215, 2.935, 2.356, 2.108, 2.055, 1.754, 1.814, 1.468, 1.318 (22.689)	Grad: 0.074, 0.150, 0.188, 0.225, 0.264, 0.299, 0.335, 0.377, 0.418, 0.463
[Epoch  14 (40.56s)]	ELBO: 1435.154, 1503.948, 1552.295, 1582.539, 1597.167, 1616.645, 1631.561, 1642.401, 1651.416, 1657.839 (1640.371)	Log prob: 1439.308, 1507.146, 1555.287, 1584.955, 1599.226, 1618.730, 1633.330, 1644.231, 1652.894, 1659.199 (1664.366)	KLD: 4.155, 3.199, 2.992, 2.417, 2.058, 2.084, 1.769, 1.829, 1.478, 1.361 (23.995)	Grad: 0.082, 0.141, 0.182, 0.221, 0.257, 0.292, 0.329, 0.371, 0.413, 0.458
[Epoch  15 (48.50s)]	ELBO: 1439.381, 1505.746, 1554.638, 1585.058, 1599.496, 1619.074, 1634.192, 1644.604, 1654.077, 1660.600 (1643.007)	Log prob: 1443.839, 1508.915, 1557.651, 1587.514, 1601.520, 1621.211, 1636.005, 1646.414, 1655.564, 1661.995 (1666.897)	KLD: 4.458, 3.168, 3.012, 2.456, 2.023, 2.137, 1.813, 1.810, 1.486, 1.395 (23.891)	Grad: 0.079, 0.139, 0.180, 0.219, 0.254, 0.289, 0.327, 0.369, 0.411, 0.457
[Epoch  16 (43.83s)]	ELBO: 1442.707, 1507.657, 1556.374, 1586.593, 1601.378, 1621.108, 1636.561, 1646.661, 1656.386, 1663.228 (1644.817)	Log prob: 1447.350, 1510.830, 1559.373, 1589.089, 1603.369, 1623.284, 1638.369, 1648.427, 1657.891, 1664.638 (1668.934)	KLD: 4.642, 3.172, 2.999, 2.497, 1.991, 2.177, 1.808, 1.766, 1.505, 1.410 (24.117)	Grad: 0.080, 0.136, 0.181, 0.220, 0.253, 0.289, 0.325, 0.366, 0.407, 0.452
[Epoch  17 (45.50s)]	ELBO: 1447.649, 1509.881, 1558.908, 1589.002, 1604.210, 1624.054, 1639.644, 1649.558, 1659.549, 1665.982 (1648.789)	Log prob: 1452.323, 1513.052, 1561.897, 1591.512, 1606.176, 1626.255, 1641.471, 1651.310, 1661.074, 1667.419 (1672.759)	KLD: 4.674, 3.170, 2.989, 2.511, 1.967, 2.200, 1.827, 1.752, 1.527, 1.437 (23.970)	Grad: 0.080, 0.138, 0.181, 0.222, 0.254, 0.290, 0.327, 0.368, 0.409, 0.453
[Epoch  18 (45.00s)]	ELBO: 1452.014, 1512.515, 1560.830, 1590.978, 1606.882, 1626.960, 1642.732, 1652.505, 1662.710, 1668.708 (1648.979)	Log prob: 1456.658, 1515.685, 1563.809, 1593.492, 1608.848, 1629.202, 1644.581, 1654.245, 1664.224, 1670.141 (1672.619)	KLD: 4.644, 3.172, 2.978, 2.513, 1.966, 2.243, 1.848, 1.740, 1.515, 1.434 (23.640)	Grad: 0.085, 0.138, 0.183, 0.226, 0.258, 0.295, 0.333, 0.374, 0.416, 0.460
[Epoch  19 (50.71s)]	ELBO: 1456.162, 1515.906, 1561.995, 1591.995, 1609.151, 1628.888, 1644.636, 1654.529, 1664.804, 1670.253 (1651.927)	Log prob: 1460.755, 1519.074, 1564.994, 1594.523, 1611.119, 1631.151, 1646.494, 1656.261, 1666.341, 1671.685 (1676.128)	KLD: 4.593, 3.168, 3.000, 2.526, 1.967, 2.264, 1.859, 1.731, 1.537, 1.434 (24.201)	Grad: 0.091, 0.143, 0.190, 0.233, 0.265, 0.304, 0.341, 0.382, 0.425, 0.469
[Epoch  20 (49.26s)]	ELBO: 1459.198, 1519.835, 1563.948, 1593.263, 1610.999, 1630.524, 1646.161, 1656.182, 1666.679, 1672.201 (1653.417)	Log prob: 1463.795, 1523.034, 1566.959, 1595.806, 1612.963, 1632.798, 1648.016, 1657.920, 1668.226, 1673.639 (1677.693)	KLD: 4.596, 3.201, 3.011, 2.543, 1.964, 2.273, 1.856, 1.738, 1.548, 1.440 (24.276)	Grad: 0.086, 0.138, 0.186, 0.227, 0.259, 0.296, 0.332, 0.373, 0.414, 0.457
[Epoch  21 (46.69s)]	ELBO: 1461.299, 1523.678, 1566.478, 1594.658, 1612.550, 1631.648, 1647.190, 1657.094, 1667.589, 1673.405 (1649.949)	Log prob: 1465.887, 1526.931, 1569.446, 1597.163, 1614.511, 1633.928, 1649.033, 1658.832, 1669.143, 1674.855 (1674.565)	KLD: 4.587, 3.252, 2.968, 2.506, 1.961, 2.279, 1.843, 1.738, 1.554, 1.451 (24.616)	Grad: 0.091, 0.150, 0.197, 0.236, 0.270, 0.308, 0.346, 0.387, 0.429, 0.473
[Epoch  22 (49.29s)]	ELBO: 1463.070, 1526.948, 1569.521, 1596.294, 1614.381, 1632.855, 1648.334, 1658.199, 1668.477, 1674.746 (1654.421)	Log prob: 1467.682, 1530.238, 1572.469, 1598.761, 1616.362, 1635.149, 1650.169, 1659.958, 1670.043, 1676.214 (1678.629)	KLD: 4.612, 3.292, 2.947, 2.466, 1.981, 2.294, 1.835, 1.758, 1.566, 1.469 (24.208)	Grad: 0.096, 0.153, 0.199, 0.239, 0.274, 0.314, 0.352, 0.394, 0.437, 0.481
[Epoch  23 (54.54s)]	ELBO: 1464.841, 1529.929, 1572.376, 1598.610, 1617.099, 1634.934, 1649.962, 1659.876, 1670.052, 1676.673 (1658.476)	Log prob: 1469.465, 1533.292, 1575.275, 1601.063, 1619.098, 1637.211, 1651.805, 1661.635, 1671.614, 1678.154 (1683.051)	KLD: 4.625, 3.364, 2.900, 2.452, 2.000, 2.277, 1.842, 1.759, 1.561, 1.481 (24.575)	Grad: 0.092, 0.147, 0.193, 0.231, 0.265, 0.303, 0.340, 0.380, 0.422, 0.464
[Epoch  24 (46.19s)]	ELBO: 1466.416, 1531.839, 1574.127, 1600.228, 1618.549, 1636.151, 1650.904, 1660.780, 1670.895, 1677.567 (1658.653)	Log prob: 1471.021, 1535.236, 1577.037, 1602.674, 1620.564, 1638.418, 1652.739, 1662.527, 1672.461, 1679.069 (1682.135)	KLD: 4.605, 3.397, 2.909, 2.446, 2.015, 2.267, 1.835, 1.745, 1.565, 1.503 (23.481)	Grad: 0.096, 0.151, 0.197, 0.235, 0.270, 0.309, 0.347, 0.389, 0.432, 0.476
[Epoch  25 (45.56s)]	ELBO: 1468.155, 1534.791, 1576.967, 1602.525, 1620.560, 1637.407, 1651.742, 1661.789, 1671.660, 1678.689 (1658.876)	Log prob: 1472.805, 1538.220, 1579.838, 1604.950, 1622.570, 1639.654, 1653.580, 1663.525, 1673.251, 1680.204 (1682.558)	KLD: 4.649, 3.427, 2.871, 2.425, 2.009, 2.247, 1.837, 1.735, 1.591, 1.515 (23.682)	Grad: 0.100, 0.156, 0.201, 0.239, 0.275, 0.312, 0.351, 0.392, 0.435, 0.478
[Epoch  26 (48.63s)]	ELBO: 1469.773, 1536.471, 1578.693, 1604.292, 1622.231, 1638.904, 1652.923, 1662.780, 1672.366, 1679.482 (1658.890)	Log prob: 1474.445, 1539.904, 1581.576, 1606.711, 1624.254, 1641.108, 1654.758, 1664.504, 1673.966, 1681.014 (1683.847)	KLD: 4.670, 3.433, 2.882, 2.418, 2.022, 2.206, 1.835, 1.725, 1.602, 1.531 (24.957)	Grad: 0.098, 0.153, 0.198, 0.238, 0.273, 0.311, 0.350, 0.392, 0.435, 0.480
[Epoch  27 (48.03s)]	ELBO: 1471.198, 1538.467, 1580.770, 1606.332, 1624.448, 1640.937, 1654.478, 1664.736, 1674.173, 1681.436 (1663.203)	Log prob: 1475.877, 1541.930, 1583.629, 1608.737, 1626.464, 1643.115, 1656.308, 1666.477, 1675.770, 1682.957 (1686.945)	KLD: 4.680, 3.464, 2.860, 2.404, 2.016, 2.177, 1.831, 1.741, 1.598, 1.522 (23.743)	Grad: 0.094, 0.150, 0.194, 0.230, 0.265, 0.302, 0.339, 0.379, 0.421, 0.464
[Epoch  28 (46.95s)]	ELBO: 1472.761, 1540.424, 1582.337, 1608.106, 1626.678, 1643.083, 1656.359, 1666.649, 1675.795, 1683.066 (1662.140)	Log prob: 1477.485, 1543.910, 1585.196, 1610.521, 1628.707, 1645.225, 1658.180, 1668.380, 1677.392, 1684.590 (1686.641)	KLD: 4.725, 3.486, 2.858, 2.414, 2.029, 2.143, 1.821, 1.731, 1.597, 1.525 (24.501)	Grad: 0.093, 0.149, 0.193, 0.227, 0.262, 0.298, 0.335, 0.373, 0.414, 0.455
[Epoch  29 (49.67s)]	ELBO: 1473.528, 1541.331, 1583.059, 1609.109, 1627.480, 1644.071, 1657.096, 1667.223, 1676.217, 1683.448 (1662.375)	Log prob: 1478.234, 1544.824, 1585.917, 1611.510, 1629.545, 1646.208, 1658.913, 1668.949, 1677.814, 1684.960 (1687.066)	KLD: 4.706, 3.492, 2.858, 2.400, 2.064, 2.138, 1.817, 1.726, 1.597, 1.512 (24.691)	Grad: 0.092, 0.148, 0.193, 0.229, 0.263, 0.300, 0.337, 0.376, 0.417, 0.459
[Epoch  30 (48.50s)]	ELBO: 1475.161, 1543.434, 1584.920, 1611.040, 1629.290, 1645.648, 1658.528, 1668.929, 1677.731, 1685.106 (1664.056)	Log prob: 1479.902, 1546.927, 1587.784, 1613.449, 1631.383, 1647.753, 1660.358, 1670.662, 1679.340, 1686.620 (1688.444)	KLD: 4.742, 3.494, 2.864, 2.409, 2.094, 2.106, 1.830, 1.734, 1.608, 1.514 (24.389)	Grad: 0.089, 0.144, 0.188, 0.223, 0.258, 0.293, 0.330, 0.369, 0.410, 0.450
[Epoch  31 (47.01s)]	ELBO: 1475.677, 1543.665, 1584.925, 1611.056, 1629.716, 1645.984, 1659.109, 1669.488, 1678.256, 1685.634 (1665.036)	Log prob: 1480.408, 1547.166, 1587.771, 1613.473, 1631.802, 1648.062, 1660.948, 1671.220, 1679.863, 1687.155 (1689.630)	KLD: 4.732, 3.501, 2.845, 2.415, 2.085, 2.079, 1.839, 1.732, 1.606, 1.521 (24.594)	Grad: 0.103, 0.159, 0.202, 0.236, 0.271, 0.308, 0.345, 0.385, 0.427, 0.469
[Epoch  32 (49.32s)]	ELBO: 1477.053, 1545.520, 1586.177, 1612.157, 1630.438, 1646.412, 1659.698, 1670.539, 1679.354, 1686.540 (1666.743)	Log prob: 1481.817, 1549.019, 1589.009, 1614.556, 1632.556, 1648.491, 1661.544, 1672.284, 1680.958, 1688.044 (1691.196)	KLD: 4.764, 3.500, 2.833, 2.400, 2.118, 2.080, 1.847, 1.745, 1.604, 1.502 (24.453)	Grad: 0.094, 0.149, 0.194, 0.231, 0.265, 0.301, 0.339, 0.378, 0.420, 0.461
[Epoch  33 (39.45s)]	ELBO: 1478.147, 1547.041, 1587.733, 1613.964, 1632.683, 1648.042, 1661.465, 1671.932, 1680.623, 1687.906 (1667.673)	Log prob: 1482.917, 1550.570, 1590.588, 1616.391, 1634.807, 1650.093, 1663.318, 1673.663, 1682.225, 1689.415 (1692.365)	KLD: 4.770, 3.530, 2.855, 2.428, 2.125, 2.049, 1.853, 1.731, 1.603, 1.508 (24.692)	Grad: 0.091, 0.146, 0.191, 0.225, 0.260, 0.296, 0.333, 0.371, 0.412, 0.452
[Epoch  34 (34.25s)]	ELBO: 1478.696, 1547.994, 1588.315, 1614.634, 1633.523, 1648.752, 1662.306, 1673.036, 1681.836, 1689.003 (1670.442)	Log prob: 1483.442, 1551.527, 1591.135, 1617.055, 1635.646, 1650.807, 1664.164, 1674.761, 1683.435, 1690.502 (1694.880)	KLD: 4.745, 3.533, 2.820, 2.421, 2.125, 2.053, 1.859, 1.725, 1.599, 1.500 (24.439)	Grad: 0.098, 0.158, 0.203, 0.239, 0.274, 0.311, 0.349, 0.389, 0.431, 0.473
[Epoch  35 (39.08s)]	ELBO: 1479.439, 1549.093, 1589.178, 1615.707, 1634.674, 1649.808, 1663.276, 1673.982, 1682.721, 1689.810 (1668.761)	Log prob: 1484.172, 1552.601, 1592.038, 1618.119, 1636.796, 1651.851, 1665.118, 1675.705, 1684.332, 1691.304 (1693.524)	KLD: 4.733, 3.508, 2.862, 2.413, 2.121, 2.043, 1.843, 1.723, 1.611, 1.494 (24.763)	Grad: 0.093, 0.150, 0.194, 0.229, 0.263, 0.299, 0.337, 0.376, 0.417, 0.459
[Epoch  36 (33.35s)]	ELBO: 1479.385, 1549.046, 1589.223, 1616.054, 1634.890, 1650.399, 1663.905, 1674.454, 1683.175, 1690.651 (1671.551)	Log prob: 1484.087, 1552.559, 1592.068, 1618.479, 1637.026, 1652.433, 1665.749, 1676.197, 1684.790, 1692.169 (1695.714)	KLD: 4.702, 3.513, 2.845, 2.425, 2.135, 2.033, 1.844, 1.742, 1.615, 1.517 (24.162)	Grad: 0.098, 0.156, 0.198, 0.234, 0.267, 0.303, 0.341, 0.379, 0.420, 0.461
[Epoch  37 (33.43s)]	ELBO: 1480.750, 1550.641, 1590.337, 1617.220, 1636.229, 1651.317, 1664.901, 1675.551, 1684.189, 1691.272 (1670.320)	Log prob: 1485.456, 1554.179, 1593.185, 1619.637, 1638.357, 1653.353, 1666.756, 1677.283, 1685.785, 1692.778 (1694.828)	KLD: 4.707, 3.538, 2.848, 2.416, 2.128, 2.035, 1.856, 1.731, 1.596, 1.506 (24.508)	Grad: 0.093, 0.150, 0.194, 0.227, 0.261, 0.297, 0.334, 0.372, 0.413, 0.453
[Epoch  38 (33.16s)]	ELBO: 1481.265, 1550.920, 1590.739, 1617.479, 1636.542, 1651.618, 1665.323, 1676.219, 1684.836, 1691.830 (1673.928)	Log prob: 1485.945, 1554.440, 1593.573, 1619.880, 1638.669, 1653.664, 1667.185, 1677.974, 1686.446, 1693.327 (1698.127)	KLD: 4.678, 3.521, 2.835, 2.401, 2.128, 2.046, 1.862, 1.754, 1.609, 1.497 (24.199)	Grad: 0.099, 0.158, 0.202, 0.238, 0.272, 0.308, 0.347, 0.387, 0.430, 0.472
[Epoch  39 (34.93s)]	ELBO: 1481.031, 1551.199, 1590.891, 1618.228, 1637.282, 1652.576, 1666.150, 1676.851, 1685.450, 1692.320 (1673.739)	Log prob: 1485.691, 1554.735, 1593.756, 1620.642, 1639.417, 1654.634, 1668.012, 1678.582, 1687.039, 1693.816 (1698.216)	KLD: 4.660, 3.536, 2.864, 2.414, 2.133, 2.058, 1.863, 1.731, 1.589, 1.496 (24.476)	Grad: 0.100, 0.159, 0.204, 0.239, 0.274, 0.311, 0.349, 0.388, 0.431, 0.473
[Epoch  40 (32.26s)]	ELBO: 1482.031, 1552.767, 1592.348, 1619.338, 1638.946, 1654.128, 1667.356, 1678.146, 1686.867, 1693.767 (1673.732)	Log prob: 1486.643, 1556.298, 1595.183, 1621.752, 1641.094, 1656.178, 1669.224, 1679.886, 1688.466, 1695.253 (1697.923)	KLD: 4.610, 3.533, 2.835, 2.414, 2.147, 2.050, 1.868, 1.740, 1.599, 1.485 (24.191)	Grad: 0.095, 0.154, 0.199, 0.232, 0.267, 0.303, 0.341, 0.379, 0.421, 0.462
[Epoch  41 (35.76s)]	ELBO: 1482.572, 1553.184, 1592.331, 1619.484, 1639.008, 1654.160, 1667.215, 1677.977, 1686.882, 1693.587 (1673.941)	Log prob: 1487.140, 1556.732, 1595.188, 1621.888, 1641.151, 1656.229, 1669.078, 1679.708, 1688.480, 1695.081 (1697.875)	KLD: 4.568, 3.548, 2.857, 2.403, 2.142, 2.068, 1.863, 1.731, 1.599, 1.494 (23.934)	Grad: 0.099, 0.162, 0.206, 0.240, 0.275, 0.312, 0.351, 0.391, 0.434, 0.477
[Epoch  42 (31.43s)]	ELBO: 1483.306, 1554.600, 1594.221, 1621.329, 1640.778, 1655.907, 1668.947, 1679.507, 1688.367, 1694.952 (1672.758)	Log prob: 1487.875, 1558.184, 1597.060, 1623.754, 1642.941, 1657.983, 1670.803, 1681.230, 1689.969, 1696.439 (1697.360)	KLD: 4.569, 3.583, 2.839, 2.424, 2.163, 2.076, 1.857, 1.721, 1.601, 1.488 (24.602)	Grad: 0.103, 0.162, 0.206, 0.241, 0.275, 0.313, 0.351, 0.391, 0.434, 0.477
[Epoch  43 (37.45s)]	ELBO: 1484.085, 1555.448, 1594.777, 1621.813, 1641.192, 1656.050, 1668.796, 1679.617, 1688.670, 1695.278 (1673.014)	Log prob: 1488.634, 1559.031, 1597.648, 1624.216, 1643.332, 1658.119, 1670.668, 1681.342, 1690.295, 1696.758 (1697.005)	KLD: 4.549, 3.584, 2.872, 2.403, 2.140, 2.068, 1.871, 1.723, 1.625, 1.481 (23.992)	Grad: 0.096, 0.158, 0.202, 0.236, 0.270, 0.307, 0.346, 0.385, 0.428, 0.470
[Epoch  44 (33.76s)]	ELBO: 1484.106, 1555.467, 1594.636, 1621.718, 1640.969, 1656.163, 1668.667, 1679.483, 1688.532, 1694.939 (1671.902)	Log prob: 1488.646, 1559.027, 1597.519, 1624.122, 1643.108, 1658.245, 1670.541, 1681.204, 1690.150, 1696.404 (1695.913)	KLD: 4.540, 3.560, 2.882, 2.405, 2.139, 2.082, 1.873, 1.720, 1.618, 1.465 (24.012)	Grad: 0.099, 0.165, 0.209, 0.242, 0.277, 0.315, 0.352, 0.392, 0.435, 0.477
[Epoch  45 (30.84s)]	ELBO: 1484.712, 1556.155, 1595.483, 1622.449, 1641.821, 1656.902, 1669.478, 1680.275, 1689.267, 1695.671 (1673.967)	Log prob: 1489.210, 1559.724, 1598.376, 1624.855, 1643.965, 1658.981, 1671.348, 1681.988, 1690.895, 1697.153 (1698.037)	KLD: 4.496, 3.568, 2.893, 2.407, 2.144, 2.079, 1.869, 1.714, 1.629, 1.482 (24.070)	Grad: 0.099, 0.163, 0.207, 0.242, 0.276, 0.313, 0.350, 0.390, 0.432, 0.474
[Epoch  46 (30.38s)]	ELBO: 1485.500, 1556.796, 1596.353, 1623.239, 1642.448, 1657.447, 1669.973, 1680.713, 1689.793, 1696.222 (1671.655)	Log prob: 1489.976, 1560.363, 1599.254, 1625.660, 1644.585, 1659.528, 1671.838, 1682.431, 1691.414, 1697.694 (1695.580)	KLD: 4.477, 3.567, 2.901, 2.421, 2.138, 2.082, 1.866, 1.719, 1.620, 1.472 (23.924)	Grad: 0.099, 0.163, 0.208, 0.243, 0.277, 0.315, 0.353, 0.393, 0.437, 0.480
[Epoch  47 (32.32s)]	ELBO: 1485.980, 1557.042, 1596.750, 1623.689, 1642.929, 1658.162, 1670.479, 1681.229, 1690.236, 1696.684 (1674.565)	Log prob: 1490.442, 1560.611, 1599.647, 1626.114, 1645.075, 1660.262, 1672.359, 1682.946, 1691.867, 1698.163 (1698.990)	KLD: 4.463, 3.569, 2.898, 2.425, 2.146, 2.100, 1.879, 1.718, 1.633, 1.480 (24.424)	Grad: 0.102, 0.168, 0.211, 0.244, 0.278, 0.314, 0.351, 0.390, 0.432, 0.473
[Epoch  48 (32.22s)]	ELBO: 1486.783, 1557.785, 1597.146, 1623.654, 1642.809, 1658.145, 1670.585, 1681.418, 1690.336, 1696.568 (1674.384)	Log prob: 1491.220, 1561.307, 1600.053, 1626.076, 1644.932, 1660.246, 1672.475, 1683.119, 1691.940, 1698.046 (1698.108)	KLD: 4.437, 3.523, 2.907, 2.423, 2.123, 2.102, 1.891, 1.700, 1.605, 1.479 (23.724)	Grad: 0.101, 0.166, 0.209, 0.243, 0.277, 0.313, 0.350, 0.388, 0.429, 0.469
[Epoch  49 (31.23s)]	ELBO: 1486.718, 1557.930, 1597.303, 1623.862, 1643.085, 1658.741, 1671.102, 1681.913, 1690.720, 1696.811 (1675.600)	Log prob: 1491.149, 1561.465, 1600.219, 1626.266, 1645.214, 1660.854, 1672.990, 1683.620, 1692.321, 1698.244 (1699.457)	KLD: 4.430, 3.535, 2.915, 2.405, 2.127, 2.113, 1.890, 1.707, 1.600, 1.433 (23.856)	Grad: 0.100, 0.166, 0.209, 0.243, 0.277, 0.313, 0.351, 0.390, 0.432, 0.473
[Epoch  50 (31.89s)]	ELBO: 1486.515, 1557.591, 1597.483, 1623.996, 1643.311, 1658.712, 1670.926, 1681.794, 1690.505, 1696.755 (1677.351)	Log prob: 1490.936, 1561.151, 1600.392, 1626.414, 1645.449, 1660.811, 1672.792, 1683.510, 1692.129, 1698.182 (1701.386)	KLD: 4.421, 3.560, 2.909, 2.419, 2.138, 2.098, 1.867, 1.715, 1.622, 1.426 (24.035)	Grad: 0.111, 0.177, 0.220, 0.253, 0.287, 0.324, 0.361, 0.400, 0.441, 0.482
[Epoch  51 (30.02s)]	ELBO: 1486.664, 1556.832, 1596.996, 1623.167, 1642.205, 1657.885, 1670.216, 1681.064, 1689.955, 1695.870 (1675.581)	Log prob: 1491.103, 1560.348, 1599.908, 1625.586, 1644.354, 1659.981, 1672.089, 1682.782, 1691.541, 1697.315 (1699.584)	KLD: 4.438, 3.516, 2.913, 2.420, 2.149, 2.095, 1.874, 1.717, 1.587, 1.445 (24.003)	Grad: 0.104, 0.173, 0.215, 0.248, 0.283, 0.320, 0.357, 0.396, 0.438, 0.478
[Epoch  52 (37.38s)]	ELBO: 1487.956, 1557.745, 1597.864, 1623.807, 1643.074, 1658.578, 1671.129, 1681.974, 1690.818, 1696.462 (1674.729)	Log prob: 1492.380, 1561.266, 1600.782, 1626.224, 1645.208, 1660.680, 1673.017, 1683.698, 1692.407, 1697.855 (1698.597)	KLD: 4.424, 3.520, 2.918, 2.418, 2.133, 2.101, 1.888, 1.725, 1.589, 1.393 (23.868)	Grad: 0.100, 0.168, 0.212, 0.245, 0.280, 0.317, 0.354, 0.393, 0.433, 0.475
[Epoch  53 (31.17s)]	ELBO: 1487.231, 1557.253, 1597.438, 1623.303, 1642.654, 1658.607, 1671.047, 1681.974, 1690.702, 1696.307 (1675.325)	Log prob: 1491.673, 1560.762, 1600.355, 1625.709, 1644.796, 1660.698, 1672.935, 1683.694, 1692.298, 1697.695 (1699.966)	KLD: 4.442, 3.509, 2.915, 2.406, 2.142, 2.090, 1.887, 1.720, 1.597, 1.389 (24.641)	Grad: 0.111, 0.183, 0.225, 0.259, 0.294, 0.332, 0.371, 0.411, 0.454, 0.496
[Epoch  54 (29.86s)]	ELBO: 1488.986, 1558.104, 1598.630, 1624.152, 1643.618, 1659.111, 1671.804, 1682.748, 1691.402, 1697.050 (1673.908)	Log prob: 1493.419, 1561.616, 1601.544, 1626.545, 1645.799, 1661.208, 1673.687, 1684.491, 1692.990, 1698.435 (1697.967)	KLD: 4.433, 3.512, 2.914, 2.393, 2.180, 2.097, 1.884, 1.742, 1.588, 1.385 (24.059)	Grad: 0.110, 0.177, 0.219, 0.253, 0.288, 0.324, 0.362, 0.402, 0.443, 0.485
[Epoch  55 (29.57s)]	ELBO: 1489.235, 1558.977, 1599.512, 1625.359, 1644.580, 1660.323, 1672.838, 1683.728, 1692.301, 1697.796 (1675.085)	Log prob: 1493.678, 1562.505, 1602.439, 1627.740, 1646.729, 1662.426, 1674.717, 1685.459, 1693.884, 1699.163 (1698.994)	KLD: 4.443, 3.528, 2.926, 2.382, 2.149, 2.103, 1.879, 1.731, 1.585, 1.367 (23.909)	Grad: 0.106, 0.172, 0.215, 0.248, 0.283, 0.319, 0.356, 0.394, 0.434, 0.474
[Epoch  56 (30.73s)]	ELBO: 1489.621, 1560.011, 1600.217, 1626.013, 1645.391, 1661.158, 1673.570, 1684.567, 1693.096, 1698.629 (1678.494)	Log prob: 1494.075, 1563.565, 1603.146, 1628.409, 1647.559, 1663.244, 1675.443, 1686.305, 1694.683, 1699.966 (1702.426)	KLD: 4.453, 3.555, 2.928, 2.395, 2.168, 2.087, 1.871, 1.739, 1.586, 1.338 (23.932)	Grad: 0.114, 0.175, 0.217, 0.250, 0.284, 0.320, 0.357, 0.396, 0.437, 0.476
[Epoch  57 (29.75s)]	ELBO: 1490.561, 1560.649, 1601.012, 1626.959, 1646.392, 1662.058, 1674.578, 1685.243, 1693.696, 1699.005 (1676.762)	Log prob: 1495.007, 1564.224, 1603.942, 1629.342, 1648.556, 1664.167, 1676.452, 1686.977, 1695.274, 1700.345 (1701.060)	KLD: 4.448, 3.575, 2.932, 2.382, 2.165, 2.108, 1.875, 1.734, 1.580, 1.340 (24.297)	Grad: 0.107, 0.170, 0.213, 0.246, 0.281, 0.317, 0.354, 0.392, 0.432, 0.472
[Epoch  58 (30.51s)]	ELBO: 1490.932, 1560.648, 1601.194, 1627.508, 1646.837, 1662.355, 1674.840, 1685.749, 1694.067, 1699.304 (1679.402)	Log prob: 1495.397, 1564.214, 1604.147, 1629.888, 1648.987, 1664.458, 1676.726, 1687.494, 1695.625, 1700.642 (1703.707)	KLD: 4.464, 3.567, 2.951, 2.379, 2.148, 2.102, 1.886, 1.745, 1.559, 1.338 (24.306)	Grad: 0.116, 0.180, 0.223, 0.257, 0.292, 0.329, 0.365, 0.404, 0.444, 0.484
[Epoch  59 (27.04s)]	ELBO: 1491.219, 1561.420, 1602.126, 1628.008, 1647.459, 1662.988, 1675.584, 1686.311, 1694.629, 1700.058 (1678.428)	Log prob: 1495.692, 1564.982, 1605.101, 1630.372, 1649.625, 1665.096, 1677.458, 1688.045, 1696.194, 1701.393 (1702.280)	KLD: 4.473, 3.561, 2.974, 2.364, 2.166, 2.106, 1.874, 1.734, 1.565, 1.335 (23.852)	Grad: 0.123, 0.188, 0.231, 0.263, 0.299, 0.336, 0.373, 0.412, 0.453, 0.493
[Epoch  60 (28.31s)]	ELBO: 1491.371, 1562.146, 1602.481, 1628.516, 1647.771, 1663.818, 1676.185, 1686.859, 1695.222, 1700.478 (1679.081)	Log prob: 1495.860, 1565.706, 1605.461, 1630.861, 1649.929, 1665.906, 1678.060, 1688.600, 1696.770, 1701.805 (1702.996)	KLD: 4.489, 3.559, 2.980, 2.344, 2.159, 2.088, 1.874, 1.742, 1.548, 1.327 (23.915)	Grad: 0.106, 0.171, 0.215, 0.248, 0.283, 0.321, 0.359, 0.398, 0.440, 0.481
[Epoch  61 (33.38s)]	ELBO: 1491.546, 1562.023, 1602.710, 1628.515, 1647.914, 1664.067, 1676.379, 1686.797, 1695.299, 1700.548 (1679.958)	Log prob: 1496.033, 1565.574, 1605.672, 1630.857, 1650.070, 1666.167, 1678.240, 1688.524, 1696.860, 1701.869 (1704.454)	KLD: 4.488, 3.551, 2.963, 2.342, 2.158, 2.101, 1.861, 1.728, 1.560, 1.322 (24.496)	Grad: 0.122, 0.180, 0.224, 0.258, 0.293, 0.330, 0.368, 0.407, 0.449, 0.489
[Epoch  62 (31.77s)]	ELBO: 1492.743, 1562.346, 1603.318, 1629.143, 1648.388, 1664.514, 1677.065, 1687.591, 1695.942, 1701.135 (1678.957)	Log prob: 1497.240, 1565.924, 1606.295, 1631.472, 1650.541, 1666.619, 1678.928, 1689.317, 1697.492, 1702.443 (1702.550)	KLD: 4.497, 3.577, 2.976, 2.328, 2.152, 2.106, 1.863, 1.726, 1.550, 1.308 (23.593)	Grad: 0.110, 0.181, 0.225, 0.260, 0.295, 0.333, 0.371, 0.411, 0.453, 0.495
[Epoch  63 (29.10s)]	ELBO: 1492.548, 1562.710, 1603.628, 1629.413, 1648.601, 1664.865, 1677.455, 1688.123, 1696.521, 1701.727 (1679.211)	Log prob: 1497.049, 1566.277, 1606.621, 1631.749, 1650.746, 1666.952, 1679.339, 1689.862, 1698.078, 1703.021 (1703.548)	KLD: 4.501, 3.568, 2.994, 2.336, 2.146, 2.087, 1.885, 1.738, 1.557, 1.295 (24.337)	Grad: 0.114, 0.179, 0.221, 0.255, 0.290, 0.327, 0.364, 0.403, 0.443, 0.483
[Epoch  64 (30.48s)]	ELBO: 1492.729, 1562.638, 1603.407, 1629.228, 1648.389, 1664.675, 1677.290, 1687.738, 1696.282, 1701.507 (1681.706)	Log prob: 1497.235, 1566.204, 1606.405, 1631.545, 1650.543, 1666.776, 1679.167, 1689.469, 1697.856, 1702.806 (1705.338)	KLD: 4.504, 3.567, 2.999, 2.316, 2.154, 2.100, 1.878, 1.730, 1.572, 1.298 (23.631)	Grad: 0.119, 0.187, 0.232, 0.266, 0.302, 0.340, 0.378, 0.418, 0.460, 0.501
[Epoch  65 (32.09s)]	ELBO: 1493.264, 1563.113, 1603.669, 1629.727, 1648.667, 1665.158, 1677.826, 1688.247, 1696.542, 1701.681 (1681.360)	Log prob: 1497.774, 1566.663, 1606.662, 1632.054, 1650.809, 1667.227, 1679.697, 1689.977, 1698.096, 1702.978 (1705.435)	KLD: 4.511, 3.550, 2.994, 2.328, 2.142, 2.069, 1.870, 1.731, 1.556, 1.297 (24.075)	Grad: 0.117, 0.185, 0.230, 0.264, 0.299, 0.336, 0.373, 0.412, 0.452, 0.492
[Epoch  66 (31.51s)]	ELBO: 1493.483, 1562.962, 1604.282, 1630.357, 1649.192, 1665.871, 1678.559, 1688.891, 1697.264, 1702.508 (1681.625)	Log prob: 1497.972, 1566.534, 1607.292, 1632.682, 1651.299, 1667.975, 1680.438, 1690.620, 1698.831, 1703.783 (1705.744)	KLD: 4.489, 3.571, 3.010, 2.324, 2.107, 2.104, 1.878, 1.728, 1.568, 1.277 (24.119)	Grad: 0.111, 0.187, 0.229, 0.263, 0.297, 0.334, 0.371, 0.410, 0.450, 0.490
[Epoch  67 (33.28s)]	ELBO: 1494.102, 1564.385, 1605.280, 1631.087, 1649.854, 1666.504, 1679.185, 1689.355, 1697.603, 1702.751 (1681.331)	Log prob: 1498.625, 1567.965, 1608.285, 1633.407, 1651.977, 1668.598, 1681.067, 1691.063, 1699.175, 1704.038 (1705.199)	KLD: 4.524, 3.580, 3.005, 2.320, 2.124, 2.093, 1.881, 1.708, 1.571, 1.287 (23.869)	Grad: 0.113, 0.175, 0.220, 0.255, 0.291, 0.329, 0.366, 0.407, 0.449, 0.490
[Epoch  68 (28.64s)]	ELBO: 1494.468, 1564.531, 1605.761, 1631.772, 1650.476, 1667.232, 1680.010, 1690.003, 1698.337, 1703.511 (1681.965)	Log prob: 1498.978, 1568.118, 1608.785, 1634.079, 1652.603, 1669.333, 1681.879, 1691.734, 1699.914, 1704.801 (1706.178)	KLD: 4.509, 3.588, 3.024, 2.306, 2.128, 2.101, 1.869, 1.730, 1.577, 1.290 (24.213)	Grad: 0.115, 0.182, 0.225, 0.259, 0.294, 0.332, 0.369, 0.408, 0.448, 0.487
[Epoch  69 (30.93s)]	ELBO: 1493.855, 1563.828, 1605.030, 1630.796, 1649.708, 1666.601, 1679.288, 1689.239, 1697.622, 1702.739 (1679.056)	Log prob: 1498.401, 1567.394, 1608.021, 1633.109, 1651.821, 1668.698, 1681.153, 1690.950, 1699.203, 1704.031 (1703.128)	KLD: 4.545, 3.565, 2.991, 2.312, 2.114, 2.096, 1.864, 1.712, 1.580, 1.292 (24.072)	Grad: 0.123, 0.192, 0.237, 0.270, 0.306, 0.344, 0.381, 0.421, 0.462, 0.503
[Epoch  70 (35.26s)]	ELBO: 1494.277, 1563.494, 1604.321, 1630.326, 1649.036, 1666.146, 1678.621, 1688.555, 1696.784, 1701.991 (1682.320)	Log prob: 1498.840, 1567.064, 1607.309, 1632.630, 1651.141, 1668.256, 1680.489, 1690.276, 1698.365, 1703.283 (1706.387)	KLD: 4.563, 3.569, 2.990, 2.305, 2.104, 2.110, 1.868, 1.720, 1.580, 1.290 (24.066)	Grad: 0.115, 0.187, 0.231, 0.266, 0.302, 0.340, 0.378, 0.419, 0.462, 0.504
[Epoch  71 (30.83s)]	ELBO: 1495.069, 1564.513, 1604.772, 1630.997, 1649.660, 1666.717, 1679.236, 1689.080, 1697.470, 1702.825 (1682.865)	Log prob: 1499.652, 1568.077, 1607.765, 1633.301, 1651.753, 1668.820, 1681.106, 1690.812, 1699.050, 1704.122 (1707.112)	KLD: 4.582, 3.564, 2.995, 2.305, 2.092, 2.103, 1.871, 1.734, 1.580, 1.296 (24.248)	Grad: 0.118, 0.182, 0.227, 0.261, 0.296, 0.333, 0.369, 0.408, 0.449, 0.488
[Epoch  72 (31.75s)]	ELBO: 1495.175, 1564.830, 1605.252, 1631.309, 1649.877, 1666.781, 1679.304, 1689.207, 1697.298, 1702.462 (1680.115)	Log prob: 1499.752, 1568.421, 1608.226, 1633.628, 1651.984, 1668.859, 1681.157, 1690.941, 1698.860, 1703.753 (1704.608)	KLD: 4.578, 3.591, 2.974, 2.318, 2.106, 2.079, 1.856, 1.733, 1.561, 1.291 (24.493)	Grad: 0.121, 0.192, 0.235, 0.269, 0.305, 0.342, 0.379, 0.419, 0.459, 0.500
[Epoch  73 (31.18s)]	ELBO: 1493.522, 1562.605, 1603.643, 1629.696, 1648.420, 1665.904, 1678.387, 1688.138, 1696.350, 1701.743 (1682.214)	Log prob: 1498.148, 1566.176, 1606.621, 1632.020, 1650.525, 1667.989, 1680.246, 1689.867, 1697.938, 1703.043 (1705.921)	KLD: 4.625, 3.569, 2.979, 2.324, 2.105, 2.084, 1.859, 1.728, 1.589, 1.300 (23.707)	Grad: 0.126, 0.194, 0.239, 0.274, 0.310, 0.348, 0.385, 0.426, 0.467, 0.509
[Epoch  74 (32.89s)]	ELBO: 1495.431, 1565.427, 1606.810, 1633.104, 1651.387, 1668.476, 1680.768, 1690.469, 1698.660, 1703.918 (1681.520)	Log prob: 1500.020, 1569.043, 1609.793, 1635.404, 1653.489, 1670.555, 1682.615, 1692.183, 1700.242, 1705.203 (1705.666)	KLD: 4.588, 3.616, 2.984, 2.299, 2.102, 2.077, 1.848, 1.713, 1.583, 1.285 (24.146)	Grad: 0.117, 0.182, 0.228, 0.262, 0.298, 0.336, 0.374, 0.415, 0.456, 0.498
[Epoch  75 (31.12s)]	ELBO: 1494.537, 1564.576, 1605.628, 1632.303, 1650.902, 1668.170, 1680.101, 1689.811, 1697.681, 1702.996 (1678.842)	Log prob: 1499.135, 1568.193, 1608.627, 1634.607, 1653.010, 1670.237, 1681.932, 1691.530, 1699.234, 1704.275 (1703.054)	KLD: 4.598, 3.617, 2.999, 2.304, 2.107, 2.067, 1.831, 1.719, 1.552, 1.279 (24.212)	Grad: 0.127, 0.196, 0.241, 0.276, 0.313, 0.351, 0.390, 0.430, 0.472, 0.514
[Epoch  76 (33.42s)]	ELBO: 1495.011, 1565.034, 1606.740, 1633.540, 1652.095, 1669.162, 1681.353, 1691.068, 1699.253, 1704.549 (1681.618)	Log prob: 1499.604, 1568.659, 1609.748, 1635.850, 1654.204, 1671.250, 1683.190, 1692.791, 1700.807, 1705.834 (1705.780)	KLD: 4.593, 3.624, 3.007, 2.311, 2.109, 2.088, 1.837, 1.724, 1.553, 1.284 (24.161)	Grad: 0.121, 0.190, 0.234, 0.267, 0.302, 0.340, 0.377, 0.417, 0.458, 0.498
[Epoch  77 (27.80s)]	ELBO: 1494.979, 1564.902, 1606.540, 1632.949, 1651.893, 1668.855, 1680.977, 1690.498, 1698.625, 1703.964 (1675.404)	Log prob: 1499.575, 1568.504, 1609.526, 1635.253, 1654.003, 1670.943, 1682.772, 1692.212, 1700.180, 1705.255 (1699.190)	KLD: 4.596, 3.601, 2.986, 2.304, 2.111, 2.089, 1.794, 1.714, 1.556, 1.291 (23.786)	Grad: 0.120, 0.190, 0.235, 0.270, 0.306, 0.344, 0.381, 0.421, 0.463, 0.504
[Epoch  78 (31.38s)]	ELBO: 1495.919, 1564.979, 1606.244, 1632.990, 1651.782, 1669.024, 1680.968, 1690.424, 1698.392, 1703.626 (1682.188)	Log prob: 1500.555, 1568.583, 1609.245, 1635.284, 1653.897, 1671.123, 1682.767, 1692.124, 1699.915, 1704.923 (1706.409)	KLD: 4.635, 3.603, 3.002, 2.292, 2.114, 2.099, 1.800, 1.702, 1.522, 1.297 (24.221)	Grad: 0.122, 0.193, 0.240, 0.274, 0.311, 0.350, 0.388, 0.428, 0.470, 0.511
[Epoch  79 (34.45s)]	ELBO: 1495.818, 1564.674, 1606.166, 1632.645, 1651.689, 1669.294, 1681.123, 1690.591, 1698.501, 1703.853 (1681.695)	Log prob: 1500.460, 1568.277, 1609.135, 1634.954, 1653.802, 1671.374, 1682.916, 1692.295, 1700.051, 1705.134 (1705.745)	KLD: 4.641, 3.603, 2.970, 2.309, 2.113, 2.080, 1.792, 1.705, 1.552, 1.281 (24.050)	Grad: 0.120, 0.187, 0.234, 0.269, 0.306, 0.344, 0.383, 0.423, 0.464, 0.505
[Epoch  80 (30.49s)]	ELBO: 1496.959, 1565.581, 1607.224, 1633.888, 1652.649, 1670.008, 1682.021, 1691.533, 1699.308, 1704.479 (1683.506)	Log prob: 1501.604, 1569.203, 1610.259, 1636.204, 1654.763, 1672.092, 1683.803, 1693.236, 1700.848, 1705.755 (1707.310)	KLD: 4.645, 3.623, 3.035, 2.316, 2.115, 2.085, 1.783, 1.704, 1.540, 1.275 (23.804)	Grad: 0.120, 0.186, 0.233, 0.268, 0.305, 0.344, 0.381, 0.422, 0.462, 0.504
[Epoch  81 (30.46s)]	ELBO: 1496.670, 1564.974, 1606.797, 1633.250, 1652.277, 1669.539, 1681.374, 1690.699, 1698.387, 1703.373 (1681.004)	Log prob: 1501.309, 1568.591, 1609.791, 1635.562, 1654.406, 1671.605, 1683.165, 1692.411, 1699.902, 1704.672 (1704.474)	KLD: 4.638, 3.617, 2.994, 2.314, 2.130, 2.067, 1.791, 1.712, 1.515, 1.299 (23.470)	Grad: 0.122, 0.192, 0.241, 0.277, 0.314, 0.352, 0.390, 0.430, 0.471, 0.513
[Epoch  82 (30.89s)]	ELBO: 1496.131, 1564.549, 1606.548, 1632.774, 1651.821, 1669.218, 1681.019, 1690.378, 1698.257, 1703.367 (1680.724)	Log prob: 1500.757, 1568.151, 1609.545, 1635.082, 1653.963, 1671.313, 1682.791, 1692.084, 1699.786, 1704.651 (1704.672)	KLD: 4.627, 3.602, 2.998, 2.308, 2.144, 2.095, 1.772, 1.706, 1.530, 1.282 (23.948)	Grad: 0.124, 0.188, 0.237, 0.272, 0.309, 0.348, 0.386, 0.427, 0.468, 0.510
[Epoch  83 (31.74s)]	ELBO: 1495.502, 1564.081, 1605.958, 1632.398, 1651.449, 1669.187, 1680.922, 1690.262, 1698.068, 1703.462 (1681.288)	Log prob: 1500.146, 1567.681, 1608.958, 1634.692, 1653.582, 1671.297, 1682.669, 1691.974, 1699.584, 1704.724 (1705.426)	KLD: 4.646, 3.599, 2.999, 2.293, 2.132, 2.111, 1.747, 1.710, 1.514, 1.264 (24.138)	Grad: 0.127, 0.192, 0.241, 0.276, 0.313, 0.352, 0.391, 0.431, 0.473, 0.514
[Epoch  84 (29.93s)]	ELBO: 1495.683, 1563.821, 1605.522, 1631.910, 1650.659, 1668.713, 1680.419, 1689.674, 1697.262, 1702.392 (1682.666)	Log prob: 1500.336, 1567.429, 1608.534, 1634.209, 1652.770, 1670.818, 1682.168, 1691.380, 1698.802, 1703.658 (1706.433)	KLD: 4.652, 3.608, 3.013, 2.298, 2.110, 2.104, 1.748, 1.706, 1.542, 1.267 (23.766)	Grad: 0.127, 0.197, 0.247, 0.282, 0.320, 0.359, 0.397, 0.438, 0.479, 0.522
[Epoch  85 (30.79s)]	ELBO: 1496.162, 1563.542, 1605.499, 1632.173, 1650.827, 1668.872, 1680.554, 1689.879, 1697.523, 1702.701 (1680.041)	Log prob: 1500.855, 1567.135, 1608.505, 1634.488, 1652.959, 1670.986, 1682.328, 1691.588, 1699.031, 1703.948 (1703.787)	KLD: 4.694, 3.591, 3.007, 2.314, 2.133, 2.113, 1.774, 1.709, 1.507, 1.247 (23.746)	Grad: 0.128, 0.194, 0.243, 0.279, 0.316, 0.355, 0.394, 0.434, 0.475, 0.517
[Epoch  86 (26.44s)]	ELBO: 1496.711, 1564.602, 1606.357, 1633.061, 1651.857, 1670.078, 1681.859, 1691.151, 1698.667, 1703.909 (1682.626)	Log prob: 1501.380, 1568.205, 1609.355, 1635.379, 1653.992, 1672.208, 1683.609, 1692.871, 1700.165, 1705.162 (1706.627)	KLD: 4.670, 3.604, 2.997, 2.318, 2.136, 2.130, 1.749, 1.719, 1.498, 1.253 (24.001)	Grad: 0.125, 0.181, 0.232, 0.267, 0.303, 0.341, 0.378, 0.418, 0.458, 0.498
[Epoch  87 (30.65s)]	ELBO: 1497.523, 1565.285, 1607.515, 1633.806, 1652.543, 1670.677, 1682.655, 1691.964, 1699.649, 1704.970 (1683.559)	Log prob: 1502.194, 1568.914, 1610.505, 1636.127, 1654.678, 1672.807, 1684.403, 1693.658, 1701.154, 1706.219 (1707.859)	KLD: 4.671, 3.629, 2.990, 2.321, 2.135, 2.131, 1.748, 1.696, 1.503, 1.251 (24.301)	Grad: 0.125, 0.190, 0.238, 0.273, 0.309, 0.349, 0.387, 0.428, 0.468, 0.510
[Epoch  88 (32.25s)]	ELBO: 1498.365, 1565.833, 1607.934, 1634.172, 1652.926, 1670.889, 1683.014, 1692.214, 1699.678, 1704.753 (1683.135)	Log prob: 1503.036, 1569.438, 1610.952, 1636.488, 1655.038, 1673.022, 1684.765, 1693.902, 1701.186, 1706.002 (1707.442)	KLD: 4.671, 3.605, 3.018, 2.317, 2.111, 2.132, 1.752, 1.688, 1.508, 1.246 (24.307)	Grad: 0.119, 0.188, 0.238, 0.274, 0.311, 0.350, 0.387, 0.427, 0.468, 0.509
[Epoch  89 (29.10s)]	ELBO: 1498.232, 1565.693, 1607.934, 1634.004, 1652.726, 1670.940, 1682.979, 1692.396, 1699.782, 1704.979 (1679.260)	Log prob: 1502.912, 1569.327, 1610.955, 1636.321, 1654.839, 1673.071, 1684.727, 1694.109, 1701.284, 1706.213 (1703.375)	KLD: 4.680, 3.635, 3.021, 2.315, 2.114, 2.131, 1.747, 1.713, 1.502, 1.235 (24.114)	Grad: 0.126, 0.189, 0.238, 0.274, 0.311, 0.352, 0.390, 0.430, 0.470, 0.512
[Epoch  90 (29.00s)]	ELBO: 1497.643, 1565.571, 1607.961, 1633.463, 1652.310, 1670.498, 1682.607, 1691.941, 1699.510, 1704.313 (1682.979)	Log prob: 1502.341, 1569.202, 1610.978, 1635.781, 1654.429, 1672.629, 1684.370, 1693.660, 1701.016, 1705.548 (1707.242)	KLD: 4.698, 3.632, 3.016, 2.318, 2.119, 2.131, 1.763, 1.718, 1.506, 1.234 (24.263)	Grad: 0.127, 0.191, 0.240, 0.277, 0.314, 0.354, 0.392, 0.432, 0.473, 0.515
[Epoch  91 (29.88s)]	ELBO: 1499.648, 1566.411, 1608.697, 1634.085, 1652.723, 1670.673, 1682.781, 1692.192, 1699.869, 1704.846 (1682.272)	Log prob: 1504.359, 1570.036, 1611.728, 1636.394, 1654.854, 1672.804, 1684.546, 1693.887, 1701.361, 1706.091 (1705.829)	KLD: 4.712, 3.623, 3.032, 2.309, 2.131, 2.129, 1.763, 1.696, 1.493, 1.245 (23.558)	Grad: 0.117, 0.187, 0.236, 0.272, 0.308, 0.346, 0.383, 0.422, 0.461, 0.501
[Epoch  92 (30.32s)]	ELBO: 1498.497, 1565.871, 1607.880, 1633.207, 1651.855, 1669.971, 1682.221, 1691.530, 1699.135, 1704.256 (1682.590)	Log prob: 1503.224, 1569.484, 1610.898, 1635.516, 1653.990, 1672.103, 1683.975, 1693.241, 1700.621, 1705.495 (1706.299)	KLD: 4.727, 3.614, 3.019, 2.309, 2.135, 2.133, 1.754, 1.711, 1.487, 1.239 (23.709)	Grad: 0.128, 0.194, 0.243, 0.280, 0.317, 0.357, 0.395, 0.436, 0.476, 0.518
[Epoch  93 (28.93s)]	ELBO: 1499.038, 1566.590, 1609.147, 1634.043, 1652.405, 1670.492, 1682.653, 1691.888, 1699.265, 1704.222 (1683.805)	Log prob: 1503.774, 1570.229, 1612.177, 1636.360, 1654.519, 1672.653, 1684.423, 1693.595, 1700.756, 1705.436 (1707.922)	KLD: 4.736, 3.639, 3.031, 2.316, 2.114, 2.161, 1.770, 1.707, 1.491, 1.214 (24.117)	Grad: 0.124, 0.189, 0.240, 0.277, 0.314, 0.355, 0.392, 0.432, 0.473, 0.514
[Epoch  94 (29.80s)]	ELBO: 1499.846, 1567.857, 1610.310, 1634.997, 1653.077, 1671.153, 1683.212, 1692.176, 1699.441, 1704.260 (1678.621)	Log prob: 1504.604, 1571.494, 1613.351, 1637.313, 1655.196, 1673.276, 1684.956, 1693.880, 1700.927, 1705.501 (1702.508)	KLD: 4.758, 3.635, 3.041, 2.314, 2.119, 2.122, 1.745, 1.703, 1.487, 1.242 (23.887)	Grad: 0.121, 0.186, 0.237, 0.274, 0.311, 0.350, 0.386, 0.425, 0.464, 0.505
[Epoch  95 (26.24s)]	ELBO: 1499.885, 1567.589, 1610.390, 1634.851, 1653.042, 1671.152, 1683.014, 1692.157, 1699.315, 1704.008 (1680.791)	Log prob: 1504.641, 1571.242, 1613.432, 1637.162, 1655.160, 1673.291, 1684.765, 1693.869, 1700.803, 1705.224 (1704.644)	KLD: 4.755, 3.652, 3.042, 2.311, 2.118, 2.137, 1.752, 1.712, 1.488, 1.216 (23.854)	Grad: 0.127, 0.197, 0.247, 0.285, 0.322, 0.362, 0.398, 0.437, 0.477, 0.518
[Epoch  96 (30.28s)]	ELBO: 1500.256, 1568.193, 1610.676, 1634.899, 1652.967, 1671.067, 1683.013, 1692.432, 1699.621, 1704.277 (1682.250)	Log prob: 1505.015, 1571.866, 1613.733, 1637.203, 1655.068, 1673.195, 1684.760, 1694.135, 1701.110, 1705.466 (1706.041)	KLD: 4.759, 3.672, 3.057, 2.304, 2.101, 2.127, 1.747, 1.704, 1.488, 1.189 (23.791)	Grad: 0.122, 0.189, 0.239, 0.277, 0.314, 0.353, 0.390, 0.429, 0.468, 0.508
[Epoch  97 (31.45s)]	ELBO: 1500.178, 1567.141, 1610.363, 1634.761, 1652.739, 1670.940, 1683.091, 1692.630, 1699.838, 1704.579 (1680.989)	Log prob: 1504.942, 1570.811, 1613.414, 1637.052, 1654.844, 1673.059, 1684.845, 1694.334, 1701.309, 1705.784 (1704.964)	KLD: 4.764, 3.669, 3.051, 2.291, 2.105, 2.118, 1.754, 1.703, 1.472, 1.205 (23.975)	Grad: 0.130, 0.201, 0.251, 0.288, 0.326, 0.367, 0.405, 0.445, 0.486, 0.527
[Epoch  98 (28.48s)]	ELBO: 1500.278, 1567.954, 1610.997, 1635.185, 1653.383, 1671.435, 1683.465, 1692.659, 1699.772, 1704.327 (1682.491)	Log prob: 1505.067, 1571.614, 1614.052, 1637.477, 1655.492, 1673.558, 1685.203, 1694.363, 1701.242, 1705.520 (1706.527)	KLD: 4.790, 3.659, 3.054, 2.293, 2.108, 2.124, 1.738, 1.703, 1.471, 1.193 (24.036)	Grad: 0.127, 0.194, 0.245, 0.283, 0.321, 0.360, 0.397, 0.436, 0.477, 0.518
[Epoch  99 (28.44s)]	ELBO: 1501.198, 1569.101, 1612.078, 1636.704, 1654.679, 1672.802, 1684.737, 1694.148, 1701.306, 1705.905 (1681.178)	Log prob: 1506.000, 1572.772, 1615.137, 1638.996, 1656.801, 1674.917, 1686.484, 1695.831, 1702.773, 1707.095 (1705.120)	KLD: 4.802, 3.671, 3.060, 2.293, 2.122, 2.115, 1.747, 1.684, 1.467, 1.189 (23.943)	Grad: 0.122, 0.191, 0.241, 0.278, 0.315, 0.354, 0.391, 0.430, 0.469, 0.508
[Epoch 100 (30.51s)]	ELBO: 1501.293, 1569.541, 1612.644, 1637.010, 1654.877, 1672.865, 1684.847, 1694.197, 1701.205, 1705.831 (1683.384)	Log prob: 1506.107, 1573.207, 1615.687, 1639.300, 1656.967, 1674.975, 1686.604, 1695.885, 1702.665, 1707.005 (1707.488)	KLD: 4.814, 3.666, 3.042, 2.290, 2.090, 2.110, 1.755, 1.689, 1.460, 1.175 (24.104)	Grad: 0.126, 0.190, 0.241, 0.278, 0.316, 0.356, 0.394, 0.433, 0.473, 0.514
Best epoch: 93	Training time: 3595.75s	Best ELBO: 1705.905 (1683.805)	Best log prob: 1707.095 (1707.922)
Avg. mu: -0.471, 0.115, 0.136, 0.235, -0.133, 0.111, 0.058, 0.250, 0.024, -0.020
Avg. var: 0.000, 0.001, 0.003, 0.007, 0.016, 0.018, 0.022, 0.029, 0.041, 0.074
Max. mu: 1.875, 3.526, 3.200, 2.688, 2.849, 4.738, 4.572, 4.642, 2.377, 3.181
Max. var: 0.016, 0.011, 0.025, 0.037, 0.125, 0.169, 0.098, 0.251, 0.183, 0.423
Min. mu: -6.371, -3.605, -3.540, -3.493, -3.382, -3.248, -2.999, -2.729, -3.948, -3.564
Min. var: 0.000, 0.000, 0.000, 0.001, 0.002, 0.001, 0.005, 0.003, 0.009, 0.015
Cov. mu:
[[1.805 0.057 0.007 -0.006 0.035 0.181 0.093 -0.127 -0.007 -0.135]
 [0.057 1.162 0.062 -0.021 -0.033 -0.020 -0.015 -0.001 -0.049 0.008]
 [0.007 0.062 0.728 -0.077 0.040 -0.022 0.069 0.004 -0.029 0.016]
 [-0.006 -0.021 -0.077 0.522 0.009 0.007 0.002 -0.004 0.016 0.000]
 [0.035 -0.033 0.040 0.009 0.668 0.019 0.050 -0.023 -0.028 0.008]
 [0.181 -0.020 -0.022 0.007 0.019 0.813 0.016 -0.022 0.004 -0.008]
 [0.093 -0.015 0.069 0.002 0.050 0.016 0.587 0.018 -0.052 0.001]
 [-0.127 -0.001 0.004 -0.004 -0.023 -0.022 0.018 0.573 0.082 0.049]
 [-0.007 -0.049 -0.029 0.016 -0.028 0.004 -0.052 0.082 0.537 0.020]
 [-0.135 0.008 0.016 0.000 0.008 -0.008 0.001 0.049 0.020 0.708]]
