Encoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Encoder                                  --
├─Linear: 1-1                            76,930
├─Linear: 1-2                            4,851
=================================================================
Total params: 81,781
Trainable params: 81,781
Non-trainable params: 0
=================================================================
Encoder to Latents 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 4
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 5
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Latents to Decoder 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 4
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 5
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Decoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Decoder                                  --
├─Linear: 1-1                            4,900
├─Linear: 1-2                            77,616
=================================================================
Total params: 82,516
Trainable params: 82,516
Non-trainable params: 0
=================================================================
[Epoch   1 (26.66s)]	ELBO: 1283.615, 1385.541, 1425.390, 1437.422, 1442.903, 1444.091 (1561.419)	Log prob: 1300.947, 1390.936, 1427.533, 1438.616, 1443.734, 1444.706 (1575.871)	KLD: 17.331, 5.394, 2.143, 1.194, 0.831, 0.614 (14.452)	Grad: 0.089, 0.068, 0.051, 0.048, 0.049, 0.052
[Epoch   2 (32.10s)]	ELBO: 1402.080, 1469.147, 1534.363, 1572.123, 1595.627, 1602.387 (1608.039)	Log prob: 1405.279, 1472.056, 1537.151, 1574.472, 1597.715, 1603.802 (1623.151)	KLD: 3.199, 2.909, 2.790, 2.349, 2.087, 1.416 (15.113)	Grad: 0.058, 0.051, 0.045, 0.034, 0.041, 0.036
[Epoch   3 (31.06s)]	ELBO: 1421.301, 1491.284, 1550.220, 1589.284, 1615.201, 1627.740 (1619.560)	Log prob: 1424.644, 1494.329, 1553.046, 1591.750, 1617.400, 1629.590 (1635.690)	KLD: 3.343, 3.044, 2.825, 2.467, 2.199, 1.852 (16.131)	Grad: 0.049, 0.052, 0.041, 0.036, 0.043, 0.039
[Epoch   4 (31.66s)]	ELBO: 1430.623, 1509.569, 1563.084, 1598.422, 1623.912, 1638.124 (1627.420)	Log prob: 1434.129, 1512.768, 1565.964, 1600.983, 1626.197, 1640.093 (1643.286)	KLD: 3.506, 3.199, 2.878, 2.561, 2.286, 1.969 (15.866)	Grad: 0.047, 0.051, 0.041, 0.039, 0.044, 0.041
[Epoch   5 (35.13s)]	ELBO: 1437.184, 1519.125, 1573.236, 1605.295, 1629.108, 1643.854 (1631.064)	Log prob: 1440.781, 1522.393, 1576.168, 1607.859, 1631.445, 1645.851 (1647.364)	KLD: 3.597, 3.268, 2.934, 2.564, 2.336, 1.999 (16.299)	Grad: 0.054, 0.050, 0.042, 0.041, 0.045, 0.045
[Epoch   6 (32.86s)]	ELBO: 1443.069, 1523.856, 1579.554, 1610.031, 1632.404, 1647.322 (1626.491)	Log prob: 1446.741, 1527.171, 1582.568, 1612.572, 1634.776, 1649.339 (1642.846)	KLD: 3.671, 3.315, 3.014, 2.542, 2.374, 2.015 (16.355)	Grad: 0.058, 0.051, 0.044, 0.042, 0.045, 0.045
[Epoch   7 (31.87s)]	ELBO: 1449.195, 1527.799, 1583.579, 1613.205, 1634.427, 1648.997 (1631.842)	Log prob: 1452.921, 1531.152, 1586.613, 1615.729, 1636.810, 1651.035 (1649.674)	KLD: 3.727, 3.353, 3.033, 2.525, 2.381, 2.037 (17.832)	Grad: 0.060, 0.053, 0.045, 0.042, 0.045, 0.045
[Epoch   8 (32.30s)]	ELBO: 1455.380, 1531.496, 1586.522, 1616.271, 1635.904, 1650.481 (1631.712)	Log prob: 1459.173, 1534.849, 1589.568, 1618.776, 1638.304, 1652.524 (1647.843)	KLD: 3.793, 3.354, 3.048, 2.504, 2.400, 2.041 (16.132)	Grad: 0.061, 0.052, 0.047, 0.043, 0.046, 0.045
[Epoch   9 (33.30s)]	ELBO: 1460.636, 1535.614, 1589.942, 1619.991, 1639.030, 1653.728 (1636.855)	Log prob: 1464.463, 1539.015, 1592.997, 1622.496, 1641.438, 1655.784 (1653.895)	KLD: 3.827, 3.402, 3.054, 2.506, 2.409, 2.057 (17.039)	Grad: 0.065, 0.049, 0.048, 0.043, 0.045, 0.046
[Epoch  10 (40.11s)]	ELBO: 1465.920, 1539.042, 1593.094, 1623.035, 1641.735, 1656.529 (1638.470)	Log prob: 1469.796, 1542.458, 1596.147, 1625.554, 1644.155, 1658.568 (1655.210)	KLD: 3.876, 3.417, 3.054, 2.520, 2.419, 2.039 (16.741)	Grad: 0.066, 0.050, 0.049, 0.044, 0.046, 0.046
[Epoch  11 (37.89s)]	ELBO: 1470.329, 1542.081, 1595.705, 1625.494, 1644.194, 1658.886 (1640.071)	Log prob: 1474.249, 1545.574, 1598.781, 1628.025, 1646.597, 1660.933 (1657.612)	KLD: 3.921, 3.494, 3.077, 2.532, 2.403, 2.047 (17.541)	Grad: 0.065, 0.049, 0.050, 0.044, 0.047, 0.048
[Epoch  12 (35.24s)]	ELBO: 1474.005, 1544.027, 1596.994, 1626.851, 1645.490, 1660.213 (1640.956)	Log prob: 1477.984, 1547.555, 1600.092, 1629.392, 1647.907, 1662.270 (1658.848)	KLD: 3.979, 3.528, 3.097, 2.540, 2.418, 2.057 (17.893)	Grad: 0.068, 0.048, 0.050, 0.046, 0.046, 0.047
[Epoch  13 (33.92s)]	ELBO: 1477.474, 1546.111, 1598.546, 1628.623, 1647.250, 1661.974 (1643.301)	Log prob: 1481.500, 1549.687, 1601.645, 1631.176, 1649.644, 1663.988 (1660.633)	KLD: 4.026, 3.576, 3.098, 2.552, 2.393, 2.014 (17.333)	Grad: 0.067, 0.049, 0.051, 0.046, 0.046, 0.047
[Epoch  14 (34.49s)]	ELBO: 1481.138, 1548.172, 1600.249, 1630.644, 1649.096, 1663.530 (1644.522)	Log prob: 1485.267, 1551.747, 1603.345, 1633.199, 1651.497, 1665.536 (1661.905)	KLD: 4.129, 3.575, 3.096, 2.554, 2.400, 2.007 (17.383)	Grad: 0.069, 0.049, 0.052, 0.046, 0.046, 0.048
[Epoch  15 (33.98s)]	ELBO: 1484.207, 1550.032, 1602.051, 1632.335, 1650.650, 1664.862 (1643.383)	Log prob: 1488.460, 1553.616, 1605.140, 1634.905, 1653.028, 1666.841 (1662.013)	KLD: 4.254, 3.584, 3.089, 2.569, 2.378, 1.979 (18.630)	Grad: 0.072, 0.050, 0.053, 0.047, 0.046, 0.048
[Epoch  16 (34.16s)]	ELBO: 1486.207, 1551.060, 1601.860, 1632.451, 1650.380, 1664.705 (1643.711)	Log prob: 1490.612, 1554.649, 1604.959, 1635.007, 1652.749, 1666.689 (1661.802)	KLD: 4.404, 3.588, 3.099, 2.556, 2.369, 1.984 (18.091)	Grad: 0.075, 0.050, 0.054, 0.047, 0.047, 0.049
[Epoch  17 (34.48s)]	ELBO: 1489.046, 1553.566, 1602.911, 1633.440, 1651.299, 1665.353 (1643.250)	Log prob: 1493.593, 1557.139, 1606.025, 1635.984, 1653.658, 1667.323 (1662.079)	KLD: 4.547, 3.573, 3.115, 2.546, 2.361, 1.970 (18.830)	Grad: 0.077, 0.051, 0.054, 0.048, 0.047, 0.050
[Epoch  18 (34.89s)]	ELBO: 1491.729, 1555.535, 1603.226, 1633.745, 1651.431, 1665.171 (1642.398)	Log prob: 1496.382, 1559.108, 1606.316, 1636.301, 1653.772, 1667.119 (1660.901)	KLD: 4.653, 3.572, 3.091, 2.556, 2.342, 1.948 (18.504)	Grad: 0.077, 0.052, 0.055, 0.048, 0.047, 0.050
[Epoch  19 (36.34s)]	ELBO: 1493.030, 1556.770, 1603.845, 1634.441, 1651.952, 1665.667 (1645.902)	Log prob: 1497.779, 1560.350, 1606.958, 1636.998, 1654.280, 1667.612 (1664.133)	KLD: 4.749, 3.581, 3.113, 2.557, 2.327, 1.945 (18.231)	Grad: 0.081, 0.052, 0.055, 0.048, 0.047, 0.050
[Epoch  20 (34.66s)]	ELBO: 1492.829, 1557.655, 1603.942, 1634.771, 1652.335, 1666.170 (1642.826)	Log prob: 1497.650, 1561.249, 1607.044, 1637.317, 1654.682, 1668.114 (1661.133)	KLD: 4.821, 3.593, 3.102, 2.547, 2.346, 1.943 (18.307)	Grad: 0.085, 0.052, 0.056, 0.048, 0.048, 0.051
[Epoch  21 (34.98s)]	ELBO: 1495.797, 1560.198, 1605.665, 1636.691, 1654.205, 1667.801 (1649.767)	Log prob: 1500.634, 1563.776, 1608.780, 1639.239, 1656.530, 1669.736 (1668.296)	KLD: 4.836, 3.578, 3.114, 2.549, 2.325, 1.936 (18.529)	Grad: 0.085, 0.052, 0.056, 0.048, 0.048, 0.051
[Epoch  22 (34.62s)]	ELBO: 1496.144, 1560.682, 1605.860, 1636.762, 1654.190, 1668.042 (1643.533)	Log prob: 1501.038, 1564.267, 1608.961, 1639.317, 1656.533, 1669.973 (1661.987)	KLD: 4.894, 3.585, 3.102, 2.554, 2.343, 1.931 (18.455)	Grad: 0.086, 0.052, 0.057, 0.048, 0.049, 0.052
[Epoch  23 (34.92s)]	ELBO: 1498.302, 1561.975, 1606.500, 1637.495, 1654.804, 1668.509 (1638.160)	Log prob: 1503.178, 1565.541, 1609.587, 1640.052, 1657.142, 1670.442 (1656.084)	KLD: 4.876, 3.566, 3.088, 2.557, 2.337, 1.932 (17.924)	Grad: 0.088, 0.052, 0.057, 0.048, 0.050, 0.052
[Epoch  24 (37.84s)]	ELBO: 1498.036, 1561.538, 1606.197, 1637.203, 1654.562, 1668.094 (1647.480)	Log prob: 1502.965, 1565.110, 1609.286, 1639.746, 1656.903, 1670.027 (1665.392)	KLD: 4.929, 3.573, 3.089, 2.543, 2.340, 1.933 (17.912)	Grad: 0.092, 0.052, 0.058, 0.049, 0.049, 0.052
[Epoch  25 (33.35s)]	ELBO: 1500.216, 1563.600, 1607.723, 1638.906, 1656.032, 1669.689 (1645.426)	Log prob: 1505.149, 1567.176, 1610.802, 1641.451, 1658.355, 1671.621 (1663.081)	KLD: 4.933, 3.576, 3.078, 2.545, 2.323, 1.932 (17.654)	Grad: 0.096, 0.053, 0.056, 0.049, 0.050, 0.053
[Epoch  26 (33.39s)]	ELBO: 1501.743, 1564.639, 1608.370, 1639.394, 1656.338, 1670.130 (1646.800)	Log prob: 1506.680, 1568.199, 1611.481, 1641.944, 1658.686, 1672.054 (1664.975)	KLD: 4.937, 3.559, 3.111, 2.549, 2.348, 1.924 (18.175)	Grad: 0.097, 0.053, 0.058, 0.050, 0.050, 0.053
[Epoch  27 (33.88s)]	ELBO: 1502.886, 1565.832, 1609.341, 1640.005, 1657.006, 1670.446 (1642.316)	Log prob: 1507.845, 1569.402, 1612.439, 1642.567, 1659.347, 1672.380 (1660.930)	KLD: 4.960, 3.570, 3.098, 2.561, 2.341, 1.933 (18.614)	Grad: 0.101, 0.054, 0.059, 0.050, 0.050, 0.053
[Epoch  28 (37.03s)]	ELBO: 1503.905, 1567.714, 1610.006, 1640.688, 1657.347, 1670.982 (1645.285)	Log prob: 1508.852, 1571.290, 1613.117, 1643.250, 1659.675, 1672.889 (1663.872)	KLD: 4.948, 3.578, 3.111, 2.561, 2.327, 1.907 (18.586)	Grad: 0.102, 0.054, 0.058, 0.049, 0.049, 0.053
[Epoch  29 (41.16s)]	ELBO: 1505.751, 1569.148, 1611.068, 1641.631, 1658.008, 1671.787 (1648.801)	Log prob: 1510.704, 1572.703, 1614.139, 1644.193, 1660.323, 1673.686 (1667.160)	KLD: 4.952, 3.555, 3.070, 2.562, 2.315, 1.899 (18.359)	Grad: 0.103, 0.055, 0.058, 0.050, 0.050, 0.054
[Epoch  30 (34.66s)]	ELBO: 1505.589, 1569.610, 1610.827, 1641.453, 1657.717, 1671.395 (1649.647)	Log prob: 1510.550, 1573.158, 1613.908, 1644.009, 1660.013, 1673.311 (1668.075)	KLD: 4.961, 3.549, 3.081, 2.555, 2.297, 1.916 (18.428)	Grad: 0.107, 0.055, 0.059, 0.050, 0.050, 0.054
[Epoch  31 (35.38s)]	ELBO: 1506.476, 1569.470, 1610.694, 1640.893, 1657.117, 1670.345 (1646.037)	Log prob: 1511.467, 1573.004, 1613.769, 1643.452, 1659.414, 1672.228 (1664.198)	KLD: 4.991, 3.534, 3.074, 2.559, 2.297, 1.884 (18.161)	Grad: 0.113, 0.055, 0.059, 0.051, 0.051, 0.055
[Epoch  32 (34.93s)]	ELBO: 1507.921, 1570.691, 1611.292, 1641.530, 1657.582, 1671.033 (1645.584)	Log prob: 1512.963, 1574.214, 1614.372, 1644.095, 1659.861, 1672.906 (1663.546)	KLD: 5.043, 3.524, 3.082, 2.565, 2.281, 1.872 (17.962)	Grad: 0.113, 0.056, 0.060, 0.052, 0.052, 0.056
[Epoch  33 (35.60s)]	ELBO: 1508.456, 1571.591, 1611.990, 1642.013, 1658.062, 1671.227 (1648.117)	Log prob: 1513.491, 1575.115, 1615.063, 1644.583, 1660.340, 1673.110 (1666.194)	KLD: 5.035, 3.525, 3.073, 2.572, 2.277, 1.881 (18.078)	Grad: 0.116, 0.057, 0.060, 0.051, 0.052, 0.055
[Epoch  34 (34.59s)]	ELBO: 1510.421, 1573.100, 1613.321, 1643.240, 1659.211, 1672.093 (1648.014)	Log prob: 1515.452, 1576.627, 1616.402, 1645.816, 1661.480, 1673.976 (1665.964)	KLD: 5.031, 3.526, 3.081, 2.576, 2.270, 1.883 (17.950)	Grad: 0.119, 0.057, 0.061, 0.052, 0.052, 0.056
[Epoch  35 (35.10s)]	ELBO: 1510.424, 1573.514, 1613.658, 1643.365, 1659.349, 1672.331 (1651.105)	Log prob: 1515.489, 1577.067, 1616.748, 1645.931, 1661.614, 1674.202 (1669.486)	KLD: 5.065, 3.552, 3.091, 2.563, 2.265, 1.871 (18.381)	Grad: 0.123, 0.056, 0.060, 0.052, 0.052, 0.055
[Epoch  36 (37.31s)]	ELBO: 1511.655, 1574.537, 1614.332, 1644.110, 1659.969, 1672.521 (1641.647)	Log prob: 1516.721, 1578.080, 1617.418, 1646.663, 1662.223, 1674.374 (1659.638)	KLD: 5.068, 3.542, 3.086, 2.552, 2.254, 1.854 (17.991)	Grad: 0.126, 0.057, 0.060, 0.051, 0.052, 0.056
[Epoch  37 (35.37s)]	ELBO: 1510.831, 1573.286, 1613.215, 1642.853, 1658.711, 1671.362 (1645.282)	Log prob: 1515.950, 1576.831, 1616.302, 1645.406, 1660.965, 1673.207 (1664.050)	KLD: 5.120, 3.545, 3.086, 2.554, 2.254, 1.845 (18.769)	Grad: 0.132, 0.059, 0.061, 0.052, 0.053, 0.056
[Epoch  38 (35.70s)]	ELBO: 1510.487, 1572.781, 1613.068, 1643.028, 1658.711, 1671.174 (1643.703)	Log prob: 1515.644, 1576.335, 1616.199, 1645.578, 1660.969, 1672.994 (1662.706)	KLD: 5.156, 3.555, 3.129, 2.552, 2.259, 1.821 (19.003)	Grad: 0.131, 0.059, 0.064, 0.052, 0.053, 0.056
[Epoch  39 (35.71s)]	ELBO: 1513.551, 1575.858, 1615.402, 1645.069, 1660.788, 1673.162 (1651.115)	Log prob: 1518.676, 1579.416, 1618.511, 1647.621, 1663.024, 1674.971 (1669.486)	KLD: 5.123, 3.557, 3.109, 2.552, 2.237, 1.809 (18.371)	Grad: 0.127, 0.060, 0.062, 0.052, 0.052, 0.056
[Epoch  40 (35.21s)]	ELBO: 1513.617, 1576.299, 1615.437, 1644.875, 1660.400, 1672.712 (1649.533)	Log prob: 1518.776, 1579.854, 1618.556, 1647.431, 1662.641, 1674.506 (1668.355)	KLD: 5.160, 3.555, 3.118, 2.557, 2.241, 1.795 (18.822)	Grad: 0.134, 0.061, 0.062, 0.052, 0.052, 0.056
[Epoch  41 (35.33s)]	ELBO: 1514.196, 1576.621, 1616.318, 1645.699, 1661.105, 1673.312 (1652.176)	Log prob: 1519.344, 1580.181, 1619.446, 1648.259, 1663.355, 1675.113 (1670.331)	KLD: 5.147, 3.559, 3.127, 2.559, 2.250, 1.802 (18.155)	Grad: 0.139, 0.061, 0.062, 0.053, 0.053, 0.057
[Epoch  42 (41.69s)]	ELBO: 1514.829, 1577.002, 1615.986, 1645.475, 1661.243, 1673.386 (1647.901)	Log prob: 1520.004, 1580.586, 1619.096, 1648.024, 1663.487, 1675.155 (1666.120)	KLD: 5.175, 3.584, 3.110, 2.549, 2.245, 1.768 (18.219)	Grad: 0.134, 0.061, 0.063, 0.053, 0.052, 0.055
[Epoch  43 (36.29s)]	ELBO: 1515.843, 1577.928, 1617.144, 1646.119, 1661.736, 1673.354 (1643.815)	Log prob: 1521.043, 1581.511, 1620.282, 1648.674, 1663.945, 1675.106 (1662.529)	KLD: 5.200, 3.584, 3.138, 2.555, 2.209, 1.752 (18.714)	Grad: 0.145, 0.061, 0.062, 0.053, 0.053, 0.057
[Epoch  44 (34.23s)]	ELBO: 1516.601, 1578.808, 1617.853, 1646.724, 1662.181, 1673.874 (1647.152)	Log prob: 1521.781, 1582.417, 1620.986, 1649.281, 1664.396, 1675.623 (1665.364)	KLD: 5.180, 3.609, 3.132, 2.557, 2.215, 1.749 (18.212)	Grad: 0.144, 0.062, 0.063, 0.053, 0.053, 0.057
[Epoch  45 (33.30s)]	ELBO: 1515.621, 1577.396, 1617.184, 1646.248, 1661.977, 1673.686 (1648.278)	Log prob: 1520.807, 1581.016, 1620.300, 1648.816, 1664.201, 1675.426 (1666.827)	KLD: 5.185, 3.620, 3.116, 2.566, 2.227, 1.740 (18.548)	Grad: 0.150, 0.061, 0.063, 0.053, 0.053, 0.057
[Epoch  46 (35.33s)]	ELBO: 1516.698, 1578.497, 1618.172, 1647.385, 1663.188, 1674.763 (1643.908)	Log prob: 1521.882, 1582.131, 1621.302, 1649.960, 1665.396, 1676.482 (1662.101)	KLD: 5.184, 3.634, 3.129, 2.576, 2.207, 1.720 (18.193)	Grad: 0.153, 0.061, 0.063, 0.053, 0.053, 0.056
[Epoch  47 (42.40s)]	ELBO: 1517.341, 1579.256, 1618.349, 1647.318, 1663.361, 1674.593 (1644.485)	Log prob: 1522.497, 1582.899, 1621.479, 1649.854, 1665.587, 1676.308 (1662.749)	KLD: 5.156, 3.642, 3.131, 2.536, 2.227, 1.714 (18.265)	Grad: 0.147, 0.063, 0.063, 0.052, 0.053, 0.056
[Epoch  48 (36.04s)]	ELBO: 1516.659, 1577.646, 1616.766, 1645.542, 1661.974, 1673.159 (1647.632)	Log prob: 1521.799, 1581.269, 1619.901, 1648.098, 1664.185, 1674.850 (1666.220)	KLD: 5.140, 3.624, 3.136, 2.555, 2.211, 1.692 (18.589)	Grad: 0.151, 0.062, 0.064, 0.053, 0.053, 0.056
[Epoch  49 (37.86s)]	ELBO: 1516.312, 1576.636, 1616.328, 1644.954, 1661.451, 1672.530 (1649.903)	Log prob: 1521.461, 1580.266, 1619.452, 1647.504, 1663.662, 1674.190 (1667.991)	KLD: 5.150, 3.631, 3.125, 2.549, 2.212, 1.659 (18.088)	Grad: 0.159, 0.064, 0.065, 0.053, 0.054, 0.057
[Epoch  50 (34.87s)]	ELBO: 1516.910, 1578.901, 1618.578, 1647.434, 1663.962, 1674.577 (1652.314)	Log prob: 1522.068, 1582.546, 1621.718, 1650.007, 1666.172, 1676.225 (1670.658)	KLD: 5.159, 3.646, 3.139, 2.573, 2.209, 1.649 (18.343)	Grad: 0.169, 0.063, 0.064, 0.053, 0.053, 0.056
[Epoch  51 (37.41s)]	ELBO: 1519.028, 1581.004, 1620.648, 1649.318, 1665.777, 1676.487 (1648.109)	Log prob: 1524.160, 1584.649, 1623.786, 1651.896, 1667.984, 1678.131 (1666.609)	KLD: 5.132, 3.645, 3.139, 2.577, 2.207, 1.645 (18.500)	Grad: 0.159, 0.063, 0.063, 0.052, 0.052, 0.055
[Epoch  52 (35.29s)]	ELBO: 1517.137, 1579.858, 1619.247, 1648.184, 1664.641, 1675.145 (1645.494)	Log prob: 1522.241, 1583.530, 1622.398, 1650.751, 1666.852, 1676.784 (1663.741)	KLD: 5.104, 3.672, 3.151, 2.566, 2.212, 1.640 (18.247)	Grad: 0.163, 0.063, 0.064, 0.052, 0.052, 0.056
[Epoch  53 (35.02s)]	ELBO: 1513.043, 1574.118, 1613.419, 1642.519, 1659.729, 1670.077 (1644.613)	Log prob: 1518.078, 1577.796, 1616.547, 1645.075, 1661.959, 1671.697 (1662.961)	KLD: 5.034, 3.678, 3.128, 2.555, 2.230, 1.619 (18.349)	Grad: 0.164, 0.063, 0.063, 0.053, 0.054, 0.057
[Epoch  54 (35.47s)]	ELBO: 1513.471, 1574.437, 1614.020, 1643.290, 1660.547, 1670.976 (1635.034)	Log prob: 1518.501, 1578.144, 1617.146, 1645.844, 1662.749, 1672.593 (1653.068)	KLD: 5.030, 3.707, 3.126, 2.553, 2.202, 1.616 (18.034)	Grad: 0.168, 0.064, 0.064, 0.052, 0.053, 0.057
[Epoch  55 (35.88s)]	ELBO: 1515.963, 1576.557, 1615.895, 1644.943, 1662.455, 1672.939 (1638.828)	Log prob: 1520.987, 1580.266, 1619.041, 1647.510, 1664.690, 1674.542 (1657.081)	KLD: 5.023, 3.710, 3.147, 2.567, 2.235, 1.602 (18.253)	Grad: 0.168, 0.064, 0.063, 0.052, 0.053, 0.056
[Epoch  56 (35.53s)]	ELBO: 1505.398, 1566.128, 1606.314, 1636.026, 1654.644, 1665.387 (1639.968)	Log prob: 1510.372, 1569.842, 1609.437, 1638.587, 1656.904, 1667.001 (1658.167)	KLD: 4.975, 3.715, 3.123, 2.562, 2.261, 1.614 (18.199)	Grad: 0.179, 0.066, 0.065, 0.054, 0.056, 0.058
[Epoch  57 (36.90s)]	ELBO: 1505.885, 1565.826, 1606.517, 1636.422, 1655.403, 1666.569 (1644.305)	Log prob: 1510.837, 1569.526, 1609.681, 1639.003, 1657.676, 1668.169 (1662.814)	KLD: 4.953, 3.699, 3.163, 2.580, 2.272, 1.599 (18.509)	Grad: 0.173, 0.065, 0.065, 0.053, 0.054, 0.057
[Epoch  58 (37.71s)]	ELBO: 1513.200, 1574.508, 1614.144, 1644.120, 1661.812, 1672.729 (1648.508)	Log prob: 1518.199, 1578.224, 1617.320, 1646.695, 1664.067, 1674.327 (1666.405)	KLD: 5.000, 3.717, 3.178, 2.573, 2.255, 1.598 (17.897)	Grad: 0.189, 0.065, 0.065, 0.052, 0.053, 0.056
[Epoch  59 (39.73s)]	ELBO: 1518.912, 1580.379, 1619.296, 1648.741, 1665.822, 1676.561 (1651.906)	Log prob: 1523.982, 1584.079, 1622.453, 1651.302, 1668.056, 1678.137 (1670.017)	KLD: 5.070, 3.700, 3.157, 2.562, 2.235, 1.577 (18.112)	Grad: 0.179, 0.065, 0.061, 0.050, 0.051, 0.055
[Epoch  60 (38.22s)]	ELBO: 1519.514, 1581.547, 1620.015, 1649.307, 1666.379, 1677.098 (1653.484)	Log prob: 1524.584, 1585.247, 1623.166, 1651.857, 1668.613, 1678.675 (1671.088)	KLD: 5.070, 3.700, 3.151, 2.550, 2.234, 1.577 (17.604)	Grad: 0.182, 0.065, 0.061, 0.051, 0.051, 0.054
[Epoch  61 (37.83s)]	ELBO: 1519.415, 1581.746, 1620.389, 1649.422, 1666.290, 1677.415 (1653.073)	Log prob: 1524.489, 1585.443, 1623.544, 1651.987, 1668.539, 1679.002 (1671.487)	KLD: 5.075, 3.697, 3.155, 2.565, 2.248, 1.588 (18.413)	Grad: 0.186, 0.067, 0.064, 0.051, 0.051, 0.054
[Epoch  62 (34.94s)]	ELBO: 1522.277, 1583.968, 1622.546, 1651.632, 1668.959, 1680.017 (1658.961)	Log prob: 1527.332, 1587.695, 1625.704, 1654.194, 1671.200, 1681.585 (1676.817)	KLD: 5.055, 3.727, 3.158, 2.560, 2.240, 1.568 (17.856)	Grad: 0.176, 0.065, 0.061, 0.050, 0.050, 0.053
[Epoch  63 (34.89s)]	ELBO: 1523.119, 1584.339, 1623.332, 1652.769, 1670.190, 1681.005 (1656.475)	Log prob: 1528.157, 1588.052, 1626.506, 1655.350, 1672.432, 1682.550 (1674.532)	KLD: 5.038, 3.712, 3.175, 2.580, 2.242, 1.545 (18.056)	Grad: 0.174, 0.065, 0.061, 0.050, 0.050, 0.053
[Epoch  64 (35.43s)]	ELBO: 1522.848, 1585.137, 1623.877, 1652.962, 1670.182, 1681.222 (1656.278)	Log prob: 1527.876, 1588.858, 1627.056, 1655.527, 1672.429, 1682.763 (1674.403)	KLD: 5.029, 3.719, 3.178, 2.565, 2.247, 1.542 (18.126)	Grad: 0.182, 0.067, 0.062, 0.051, 0.050, 0.052
[Epoch  65 (41.63s)]	ELBO: 1522.141, 1584.554, 1623.176, 1652.149, 1669.508, 1680.568 (1657.759)	Log prob: 1527.197, 1588.263, 1626.345, 1654.713, 1671.731, 1682.095 (1675.888)	KLD: 5.057, 3.708, 3.168, 2.565, 2.222, 1.527 (18.128)	Grad: 0.186, 0.067, 0.061, 0.051, 0.051, 0.054
[Epoch  66 (40.68s)]	ELBO: 1521.416, 1583.477, 1622.478, 1651.453, 1669.290, 1680.001 (1649.317)	Log prob: 1526.441, 1587.217, 1625.675, 1654.045, 1671.519, 1681.544 (1667.660)	KLD: 5.024, 3.739, 3.197, 2.590, 2.229, 1.543 (18.343)	Grad: 0.182, 0.067, 0.063, 0.051, 0.051, 0.054
[Epoch  67 (38.27s)]	ELBO: 1517.253, 1579.211, 1619.073, 1648.224, 1666.500, 1677.435 (1642.175)	Log prob: 1522.265, 1582.958, 1622.264, 1650.794, 1668.735, 1678.979 (1660.164)	KLD: 5.011, 3.746, 3.190, 2.569, 2.236, 1.544 (17.989)	Grad: 0.194, 0.066, 0.063, 0.052, 0.052, 0.055
[Epoch  68 (40.63s)]	ELBO: 1519.971, 1582.800, 1622.203, 1650.876, 1668.670, 1679.961 (1656.527)	Log prob: 1525.034, 1586.560, 1625.383, 1653.464, 1670.907, 1681.496 (1674.795)	KLD: 5.063, 3.760, 3.180, 2.588, 2.237, 1.536 (18.268)	Grad: 0.194, 0.067, 0.063, 0.051, 0.051, 0.054
[Epoch  69 (39.65s)]	ELBO: 1521.153, 1584.176, 1622.971, 1651.573, 1669.196, 1680.637 (1647.372)	Log prob: 1526.240, 1587.929, 1626.160, 1654.150, 1671.424, 1682.189 (1665.992)	KLD: 5.087, 3.754, 3.189, 2.577, 2.228, 1.552 (18.620)	Grad: 0.195, 0.068, 0.063, 0.050, 0.051, 0.054
[Epoch  70 (37.56s)]	ELBO: 1521.131, 1583.242, 1621.733, 1650.455, 1668.163, 1679.717 (1653.621)	Log prob: 1526.246, 1586.989, 1624.906, 1653.058, 1670.382, 1681.290 (1672.028)	KLD: 5.116, 3.747, 3.172, 2.602, 2.219, 1.574 (18.407)	Grad: 0.197, 0.069, 0.062, 0.050, 0.050, 0.053
[Epoch  71 (29.20s)]	ELBO: 1521.884, 1583.975, 1621.616, 1650.111, 1667.791, 1679.400 (1657.433)	Log prob: 1527.013, 1587.702, 1624.804, 1652.691, 1669.999, 1680.949 (1676.248)	KLD: 5.130, 3.727, 3.187, 2.581, 2.208, 1.550 (18.814)	Grad: 0.189, 0.067, 0.062, 0.050, 0.049, 0.053
[Epoch  72 (28.14s)]	ELBO: 1523.458, 1585.421, 1622.976, 1651.108, 1668.927, 1680.461 (1650.533)	Log prob: 1528.601, 1589.179, 1626.148, 1653.720, 1671.139, 1681.998 (1668.994)	KLD: 5.143, 3.757, 3.172, 2.614, 2.212, 1.538 (18.460)	Grad: 0.174, 0.065, 0.060, 0.050, 0.049, 0.051
[Epoch  73 (28.18s)]	ELBO: 1524.459, 1585.961, 1623.773, 1652.014, 1669.821, 1681.756 (1657.324)	Log prob: 1529.634, 1589.700, 1626.948, 1654.638, 1672.033, 1683.317 (1676.015)	KLD: 5.176, 3.739, 3.174, 2.623, 2.212, 1.561 (18.691)	Grad: 0.192, 0.066, 0.062, 0.050, 0.049, 0.052
[Epoch  74 (26.38s)]	ELBO: 1522.930, 1583.753, 1621.792, 1650.196, 1668.289, 1680.400 (1648.982)	Log prob: 1528.101, 1587.494, 1624.968, 1652.797, 1670.532, 1681.979 (1667.617)	KLD: 5.172, 3.742, 3.178, 2.602, 2.243, 1.579 (18.635)	Grad: 0.183, 0.071, 0.061, 0.050, 0.050, 0.053
[Epoch  75 (20.88s)]	ELBO: 1516.751, 1577.415, 1616.496, 1645.436, 1664.246, 1676.255 (1643.762)	Log prob: 1521.910, 1581.182, 1619.710, 1648.046, 1666.495, 1677.834 (1662.114)	KLD: 5.160, 3.767, 3.214, 2.610, 2.249, 1.579 (18.353)	Grad: 0.191, 0.069, 0.063, 0.052, 0.051, 0.054
[Epoch  76 (20.42s)]	ELBO: 1512.023, 1572.715, 1613.162, 1642.204, 1661.669, 1673.719 (1654.452)	Log prob: 1517.201, 1576.468, 1616.360, 1644.830, 1663.917, 1675.306 (1672.902)	KLD: 5.177, 3.752, 3.197, 2.625, 2.247, 1.587 (18.450)	Grad: 0.197, 0.072, 0.064, 0.053, 0.052, 0.054
[Epoch  77 (21.41s)]	ELBO: 1518.483, 1579.353, 1618.129, 1646.797, 1665.976, 1678.238 (1648.355)	Log prob: 1523.747, 1583.088, 1621.303, 1649.423, 1668.232, 1679.826 (1666.684)	KLD: 5.265, 3.736, 3.174, 2.625, 2.257, 1.588 (18.329)	Grad: 0.182, 0.068, 0.061, 0.052, 0.050, 0.052
[Epoch  78 (19.94s)]	ELBO: 1521.292, 1582.991, 1621.589, 1650.236, 1669.298, 1681.295 (1656.768)	Log prob: 1526.546, 1586.753, 1624.756, 1652.870, 1671.548, 1682.882 (1675.304)	KLD: 5.253, 3.761, 3.166, 2.633, 2.249, 1.586 (18.536)	Grad: 0.195, 0.069, 0.061, 0.050, 0.049, 0.052
[Epoch  79 (18.83s)]	ELBO: 1520.696, 1582.144, 1621.021, 1649.527, 1668.644, 1680.831 (1654.128)	Log prob: 1525.948, 1585.901, 1624.198, 1652.173, 1670.896, 1682.412 (1672.695)	KLD: 5.252, 3.758, 3.178, 2.648, 2.253, 1.580 (18.567)	Grad: 0.191, 0.069, 0.062, 0.051, 0.050, 0.052
[Epoch  80 (21.22s)]	ELBO: 1516.598, 1576.951, 1616.445, 1645.570, 1665.383, 1677.424 (1651.473)	Log prob: 1521.819, 1580.688, 1619.619, 1648.212, 1667.636, 1678.986 (1670.158)	KLD: 5.222, 3.736, 3.173, 2.642, 2.253, 1.562 (18.686)	Grad: 0.190, 0.068, 0.062, 0.052, 0.051, 0.053
[Epoch  81 (23.66s)]	ELBO: 1516.466, 1577.064, 1617.935, 1646.416, 1665.829, 1677.839 (1652.817)	Log prob: 1521.708, 1580.852, 1621.131, 1649.045, 1668.092, 1679.446 (1671.575)	KLD: 5.242, 3.789, 3.194, 2.630, 2.263, 1.607 (18.758)	Grad: 0.207, 0.073, 0.062, 0.052, 0.051, 0.053
[Epoch  82 (23.38s)]	ELBO: 1519.005, 1579.763, 1620.560, 1648.902, 1667.859, 1680.061 (1653.336)	Log prob: 1524.228, 1583.543, 1623.773, 1651.521, 1670.079, 1681.672 (1671.997)	KLD: 5.223, 3.779, 3.213, 2.620, 2.222, 1.611 (18.662)	Grad: 0.196, 0.071, 0.062, 0.052, 0.049, 0.052
[Epoch  83 (20.11s)]	ELBO: 1520.641, 1581.365, 1621.660, 1649.832, 1668.572, 1680.566 (1652.430)	Log prob: 1525.879, 1585.163, 1624.862, 1652.452, 1670.806, 1682.159 (1670.959)	KLD: 5.238, 3.799, 3.201, 2.620, 2.234, 1.592 (18.528)	Grad: 0.201, 0.070, 0.062, 0.051, 0.050, 0.051
[Epoch  84 (20.11s)]	ELBO: 1521.833, 1582.925, 1622.364, 1650.900, 1669.990, 1682.113 (1651.360)	Log prob: 1527.061, 1586.695, 1625.561, 1653.537, 1672.220, 1683.692 (1670.093)	KLD: 5.228, 3.770, 3.196, 2.636, 2.229, 1.580 (18.734)	Grad: 0.190, 0.068, 0.062, 0.051, 0.049, 0.051
[Epoch  85 (19.91s)]	ELBO: 1519.365, 1580.272, 1620.426, 1649.085, 1668.681, 1680.629 (1647.989)	Log prob: 1524.552, 1584.043, 1623.642, 1651.748, 1670.913, 1682.216 (1666.198)	KLD: 5.188, 3.773, 3.216, 2.663, 2.232, 1.587 (18.208)	Grad: 0.192, 0.069, 0.063, 0.052, 0.049, 0.052
[Epoch  86 (20.78s)]	ELBO: 1518.994, 1580.363, 1620.620, 1649.655, 1669.211, 1681.125 (1646.902)	Log prob: 1524.210, 1584.122, 1623.857, 1652.307, 1671.435, 1682.700 (1665.351)	KLD: 5.216, 3.759, 3.238, 2.651, 2.224, 1.574 (18.449)	Grad: 0.211, 0.069, 0.062, 0.051, 0.049, 0.051
No improvement after 25 epochs...
Best epoch(s): [62]	Training time(s): 2866.43s (2866.43s)	Best ELBO: 1682.113 (1658.961)	Best log prob: 1683.692 (1676.817)
Avg. mu: -0.315, -0.410, 0.225, 0.085, 0.460, 0.065
Avg. var: 0.000, 0.001, 0.002, 0.006, 0.012, 0.040
Max. mu: 3.549, 2.672, 2.432, 3.327, 2.375, 2.980
Max. var: 0.013, 0.039, 0.027, 0.069, 0.193, 0.386
Min. mu: -5.382, -5.936, -2.938, -3.367, -2.428, -2.787
Min. var: 0.000, 0.000, 0.000, 0.000, 0.002, 0.008
Cov. mu:
[[1.409 -0.335 -0.025 0.163 -0.124 0.148]
 [-0.335 0.825 -0.074 -0.074 0.066 -0.082]
 [-0.025 -0.074 0.530 -0.018 -0.011 -0.007]
 [0.163 -0.074 -0.018 0.423 0.002 0.019]
 [-0.124 0.066 -0.011 0.002 0.428 -0.051]
 [0.148 -0.082 -0.007 0.019 -0.051 0.588]]
Avg. mu: -0.315, -0.410, 0.225, 0.085, 0.460, 0.065
Avg. var: 0.000, 0.001, 0.002, 0.006, 0.012, 0.040
Max. mu: 3.549, 2.672, 2.432, 3.327, 2.375, 2.980
Max. var: 0.013, 0.039, 0.027, 0.069, 0.193, 0.386
Min. mu: -5.382, -5.936, -2.938, -3.367, -2.428, -2.787
Min. var: 0.000, 0.000, 0.000, 0.000, 0.002, 0.008
Cov. mu:
[[1.409 -0.335 -0.025 0.163 -0.124 0.148]
 [-0.335 0.825 -0.074 -0.074 0.066 -0.082]
 [-0.025 -0.074 0.530 -0.018 -0.011 -0.007]
 [0.163 -0.074 -0.018 0.423 0.002 0.019]
 [-0.124 0.066 -0.011 0.002 0.428 -0.051]
 [0.148 -0.082 -0.007 0.019 -0.051 0.588]]
Avg. mu: -0.315, -0.410, 0.225, 0.085, 0.460, 0.065
Avg. var: 0.000, 0.001, 0.002, 0.006, 0.012, 0.040
Max. mu: 3.549, 2.672, 2.432, 3.327, 2.375, 2.980
Max. var: 0.013, 0.039, 0.027, 0.069, 0.193, 0.386
Min. mu: -5.382, -5.936, -2.938, -3.367, -2.428, -2.787
Min. var: 0.000, 0.000, 0.000, 0.000, 0.002, 0.008
Cov. mu:
[[1.409 -0.335 -0.025 0.163 -0.124 0.148]
 [-0.335 0.825 -0.074 -0.074 0.066 -0.082]
 [-0.025 -0.074 0.530 -0.018 -0.011 -0.007]
 [0.163 -0.074 -0.018 0.423 0.002 0.019]
 [-0.124 0.066 -0.011 0.002 0.428 -0.051]
 [0.148 -0.082 -0.007 0.019 -0.051 0.588]]
Avg. mu: -0.315, -0.410, 0.225, 0.085, 0.460, 0.065
Avg. var: 0.000, 0.001, 0.002, 0.006, 0.012, 0.040
Max. mu: 3.549, 2.672, 2.432, 3.327, 2.375, 2.980
Max. var: 0.013, 0.039, 0.027, 0.069, 0.193, 0.386
Min. mu: -5.382, -5.936, -2.938, -3.367, -2.428, -2.787
Min. var: 0.000, 0.000, 0.000, 0.000, 0.002, 0.008
Cov. mu:
[[1.409 -0.335 -0.025 0.163 -0.124 0.148]
 [-0.335 0.825 -0.074 -0.074 0.066 -0.082]
 [-0.025 -0.074 0.530 -0.018 -0.011 -0.007]
 [0.163 -0.074 -0.018 0.423 0.002 0.019]
 [-0.124 0.066 -0.011 0.002 0.428 -0.051]
 [0.148 -0.082 -0.007 0.019 -0.051 0.588]]
