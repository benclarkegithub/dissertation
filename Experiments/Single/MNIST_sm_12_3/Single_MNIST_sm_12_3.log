Encoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Encoder                                  --
├─Linear: 1-1                            76,930
├─Linear: 1-2                            4,851
=================================================================
Total params: 81,781
Trainable params: 81,781
Non-trainable params: 0
=================================================================
Encoder to Latents 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            150
├─Linear: 1-2                            150
=================================================================
Total params: 300
Trainable params: 300
Non-trainable params: 0
=================================================================
Encoder to Latents 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            150
├─Linear: 1-2                            150
=================================================================
Total params: 300
Trainable params: 300
Non-trainable params: 0
=================================================================
Encoder to Latents 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            150
├─Linear: 1-2                            150
=================================================================
Total params: 300
Trainable params: 300
Non-trainable params: 0
=================================================================
Encoder to Latents 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            150
├─Linear: 1-2                            150
=================================================================
Total params: 300
Trainable params: 300
Non-trainable params: 0
=================================================================
Latents to Decoder 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            196
=================================================================
Total params: 196
Trainable params: 196
Non-trainable params: 0
=================================================================
Latents to Decoder 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            196
=================================================================
Total params: 196
Trainable params: 196
Non-trainable params: 0
=================================================================
Latents to Decoder 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            196
=================================================================
Total params: 196
Trainable params: 196
Non-trainable params: 0
=================================================================
Latents to Decoder 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            196
=================================================================
Total params: 196
Trainable params: 196
Non-trainable params: 0
=================================================================
Decoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Decoder                                  --
├─Linear: 1-1                            4,900
├─Linear: 1-2                            77,616
=================================================================
Total params: 82,516
Trainable params: 82,516
Non-trainable params: 0
=================================================================
[Epoch   1 (29.50s)]	ELBO: 1370.841, 1417.662, 1425.117, 1426.931 (1561.344)	Log prob: 1394.853, 1420.180, 1426.341, 1427.923 (1585.277)	KLD: 24.013, 2.518, 1.225, 0.991 (23.933)	Grad: 0.092, 0.045, 0.043, 0.047
[Epoch   2 (30.05s)]	ELBO: 1510.774, 1611.713, 1627.727, 1630.176 (1639.650)	Log prob: 1521.957, 1619.096, 1630.355, 1631.329 (1660.584)	KLD: 11.183, 7.384, 2.629, 1.154 (20.933)	Grad: 0.101, 0.052, 0.036, 0.031
[Epoch   3 (31.65s)]	ELBO: 1543.923, 1645.324, 1673.464, 1678.498 (1676.266)	Log prob: 1553.764, 1652.210, 1677.403, 1679.997 (1698.739)	KLD: 9.841, 6.885, 3.940, 1.499 (22.473)	Grad: 0.097, 0.062, 0.036, 0.029
[Epoch   4 (31.50s)]	ELBO: 1563.485, 1658.853, 1698.142, 1705.531 (1695.178)	Log prob: 1573.245, 1665.766, 1703.080, 1707.496 (1719.291)	KLD: 9.759, 6.915, 4.939, 1.966 (24.113)	Grad: 0.090, 0.062, 0.039, 0.030
[Epoch   5 (31.73s)]	ELBO: 1575.978, 1666.511, 1708.839, 1720.521 (1703.371)	Log prob: 1585.961, 1673.540, 1714.048, 1723.446 (1728.222)	KLD: 9.983, 7.030, 5.209, 2.926 (24.851)	Grad: 0.089, 0.063, 0.041, 0.032
[Epoch   6 (32.42s)]	ELBO: 1584.417, 1671.310, 1714.695, 1729.590 (1709.859)	Log prob: 1594.604, 1678.398, 1719.989, 1732.934 (1735.683)	KLD: 10.187, 7.088, 5.294, 3.343 (25.825)	Grad: 0.088, 0.064, 0.043, 0.034
[Epoch   7 (31.79s)]	ELBO: 1590.477, 1675.286, 1719.076, 1735.250 (1713.115)	Log prob: 1600.727, 1682.452, 1724.466, 1738.734 (1738.921)	KLD: 10.250, 7.168, 5.388, 3.484 (25.806)	Grad: 0.087, 0.061, 0.044, 0.035
[Epoch   8 (32.05s)]	ELBO: 1595.060, 1678.351, 1722.215, 1738.549 (1715.902)	Log prob: 1605.403, 1685.565, 1727.649, 1742.129 (1741.846)	KLD: 10.342, 7.213, 5.433, 3.579 (25.944)	Grad: 0.088, 0.062, 0.045, 0.036
[Epoch   9 (32.15s)]	ELBO: 1598.667, 1680.867, 1724.911, 1741.330 (1719.366)	Log prob: 1609.084, 1688.090, 1730.381, 1744.925 (1745.924)	KLD: 10.416, 7.223, 5.469, 3.595 (26.559)	Grad: 0.087, 0.059, 0.045, 0.036
[Epoch  10 (35.02s)]	ELBO: 1601.362, 1682.693, 1726.997, 1743.482 (1720.850)	Log prob: 1611.855, 1689.949, 1732.482, 1747.103 (1748.245)	KLD: 10.493, 7.256, 5.484, 3.621 (27.395)	Grad: 0.091, 0.061, 0.046, 0.037
[Epoch  11 (33.69s)]	ELBO: 1604.201, 1684.623, 1728.776, 1745.379 (1717.376)	Log prob: 1614.731, 1691.866, 1734.306, 1749.001 (1743.940)	KLD: 10.530, 7.241, 5.531, 3.623 (26.563)	Grad: 0.090, 0.060, 0.046, 0.037
[Epoch  12 (33.45s)]	ELBO: 1606.263, 1686.413, 1730.431, 1747.283 (1725.303)	Log prob: 1616.861, 1693.652, 1735.994, 1750.903 (1752.166)	KLD: 10.598, 7.239, 5.564, 3.622 (26.863)	Grad: 0.089, 0.061, 0.047, 0.037
[Epoch  13 (33.33s)]	ELBO: 1608.055, 1687.786, 1731.511, 1748.503 (1724.143)	Log prob: 1618.687, 1695.001, 1737.055, 1752.108 (1750.890)	KLD: 10.632, 7.215, 5.544, 3.605 (26.748)	Grad: 0.092, 0.060, 0.047, 0.038
[Epoch  14 (33.46s)]	ELBO: 1609.787, 1688.898, 1732.523, 1749.708 (1724.402)	Log prob: 1620.496, 1696.086, 1738.096, 1753.341 (1751.844)	KLD: 10.708, 7.188, 5.573, 3.635 (27.442)	Grad: 0.092, 0.059, 0.047, 0.038
[Epoch  15 (33.32s)]	ELBO: 1611.213, 1690.033, 1733.502, 1750.889 (1725.237)	Log prob: 1621.965, 1697.191, 1739.094, 1754.520 (1751.834)	KLD: 10.752, 7.160, 5.593, 3.632 (26.597)	Grad: 0.094, 0.059, 0.047, 0.038
[Epoch  16 (38.00s)]	ELBO: 1612.621, 1690.791, 1734.037, 1751.592 (1727.266)	Log prob: 1623.433, 1697.935, 1739.631, 1755.178 (1754.379)	KLD: 10.812, 7.144, 5.593, 3.586 (27.114)	Grad: 0.093, 0.060, 0.047, 0.038
[Epoch  17 (36.00s)]	ELBO: 1614.014, 1691.590, 1734.428, 1752.091 (1727.859)	Log prob: 1624.886, 1698.689, 1740.013, 1755.685 (1755.257)	KLD: 10.871, 7.100, 5.584, 3.595 (27.398)	Grad: 0.095, 0.060, 0.047, 0.038
[Epoch  18 (34.30s)]	ELBO: 1615.369, 1692.301, 1734.978, 1752.735 (1728.331)	Log prob: 1626.302, 1699.369, 1740.525, 1756.320 (1754.477)	KLD: 10.933, 7.067, 5.548, 3.584 (26.146)	Grad: 0.094, 0.059, 0.048, 0.039
[Epoch  19 (33.14s)]	ELBO: 1616.546, 1692.930, 1735.198, 1752.998 (1726.566)	Log prob: 1627.491, 1699.973, 1740.766, 1756.583 (1753.293)	KLD: 10.947, 7.043, 5.569, 3.583 (26.727)	Grad: 0.096, 0.058, 0.048, 0.039
[Epoch  20 (33.59s)]	ELBO: 1617.728, 1693.755, 1735.612, 1753.439 (1728.545)	Log prob: 1628.718, 1700.750, 1741.139, 1757.029 (1755.492)	KLD: 10.989, 6.996, 5.527, 3.589 (26.946)	Grad: 0.097, 0.059, 0.048, 0.039
[Epoch  21 (32.91s)]	ELBO: 1618.887, 1694.393, 1736.047, 1754.021 (1728.892)	Log prob: 1629.911, 1701.348, 1741.566, 1757.576 (1755.802)	KLD: 11.024, 6.956, 5.519, 3.555 (26.909)	Grad: 0.097, 0.058, 0.048, 0.039
[Epoch  22 (33.27s)]	ELBO: 1619.739, 1694.658, 1736.240, 1754.184 (1726.577)	Log prob: 1630.793, 1701.644, 1741.760, 1757.764 (1754.012)	KLD: 11.053, 6.986, 5.521, 3.581 (27.434)	Grad: 0.099, 0.059, 0.049, 0.040
[Epoch  23 (33.24s)]	ELBO: 1620.751, 1695.400, 1736.735, 1754.688 (1725.866)	Log prob: 1631.817, 1702.349, 1742.246, 1758.241 (1752.669)	KLD: 11.067, 6.948, 5.510, 3.553 (26.803)	Grad: 0.100, 0.058, 0.048, 0.040
[Epoch  24 (33.86s)]	ELBO: 1621.672, 1695.812, 1736.968, 1754.810 (1729.110)	Log prob: 1632.754, 1702.705, 1742.443, 1758.371 (1756.196)	KLD: 11.084, 6.893, 5.475, 3.560 (27.086)	Grad: 0.102, 0.058, 0.049, 0.040
[Epoch  25 (33.66s)]	ELBO: 1622.432, 1696.363, 1737.504, 1755.439 (1731.323)	Log prob: 1633.549, 1703.259, 1742.981, 1759.001 (1758.604)	KLD: 11.118, 6.895, 5.479, 3.563 (27.282)	Grad: 0.102, 0.058, 0.049, 0.040
[Epoch  26 (33.06s)]	ELBO: 1623.228, 1696.766, 1737.790, 1755.655 (1729.937)	Log prob: 1634.355, 1703.635, 1743.264, 1759.198 (1757.081)	KLD: 11.127, 6.869, 5.475, 3.545 (27.143)	Grad: 0.100, 0.057, 0.049, 0.040
[Epoch  27 (33.52s)]	ELBO: 1623.705, 1697.181, 1738.126, 1756.047 (1726.640)	Log prob: 1634.843, 1704.046, 1743.620, 1759.562 (1752.665)	KLD: 11.139, 6.864, 5.492, 3.515 (26.025)	Grad: 0.105, 0.058, 0.049, 0.040
[Epoch  28 (33.04s)]	ELBO: 1624.550, 1697.574, 1738.275, 1756.139 (1727.945)	Log prob: 1635.692, 1704.405, 1743.740, 1759.680 (1755.144)	KLD: 11.142, 6.831, 5.465, 3.540 (27.199)	Grad: 0.102, 0.058, 0.049, 0.041
[Epoch  29 (33.11s)]	ELBO: 1625.074, 1697.934, 1738.497, 1756.410 (1727.378)	Log prob: 1636.203, 1704.752, 1743.956, 1759.930 (1753.552)	KLD: 11.129, 6.819, 5.460, 3.520 (26.174)	Grad: 0.102, 0.057, 0.049, 0.041
[Epoch  30 (33.37s)]	ELBO: 1625.412, 1698.178, 1738.555, 1756.510 (1730.117)	Log prob: 1636.567, 1704.973, 1744.046, 1760.025 (1757.898)	KLD: 11.155, 6.794, 5.492, 3.515 (27.782)	Grad: 0.105, 0.058, 0.049, 0.041
[Epoch  31 (32.43s)]	ELBO: 1626.065, 1698.593, 1738.473, 1756.345 (1729.171)	Log prob: 1637.178, 1705.360, 1743.937, 1759.865 (1755.594)	KLD: 11.113, 6.767, 5.465, 3.518 (26.423)	Grad: 0.106, 0.058, 0.049, 0.042
[Epoch  32 (32.72s)]	ELBO: 1626.753, 1699.201, 1738.738, 1756.706 (1729.819)	Log prob: 1637.882, 1705.933, 1744.180, 1760.223 (1756.045)	KLD: 11.129, 6.731, 5.441, 3.517 (26.226)	Grad: 0.107, 0.059, 0.049, 0.041
[Epoch  33 (35.83s)]	ELBO: 1626.927, 1699.207, 1738.601, 1756.644 (1732.073)	Log prob: 1638.022, 1705.965, 1744.044, 1760.156 (1758.618)	KLD: 11.095, 6.757, 5.445, 3.511 (26.545)	Grad: 0.110, 0.058, 0.050, 0.043
[Epoch  34 (32.42s)]	ELBO: 1627.591, 1699.810, 1738.640, 1756.722 (1728.836)	Log prob: 1638.677, 1706.541, 1744.092, 1760.238 (1755.272)	KLD: 11.085, 6.730, 5.452, 3.515 (26.436)	Grad: 0.109, 0.058, 0.050, 0.042
[Epoch  35 (32.62s)]	ELBO: 1627.952, 1700.124, 1738.751, 1756.765 (1730.297)	Log prob: 1639.021, 1706.869, 1744.185, 1760.298 (1756.019)	KLD: 11.069, 6.744, 5.435, 3.533 (25.722)	Grad: 0.115, 0.058, 0.050, 0.043
[Epoch  36 (31.76s)]	ELBO: 1628.712, 1700.520, 1738.849, 1756.974 (1727.971)	Log prob: 1639.793, 1707.225, 1744.271, 1760.476 (1754.758)	KLD: 11.081, 6.705, 5.421, 3.501 (26.787)	Grad: 0.110, 0.058, 0.050, 0.043
[Epoch  37 (32.28s)]	ELBO: 1628.978, 1700.688, 1738.936, 1757.200 (1729.205)	Log prob: 1640.096, 1707.439, 1744.357, 1760.725 (1756.758)	KLD: 11.118, 6.751, 5.421, 3.524 (27.553)	Grad: 0.112, 0.059, 0.051, 0.043
[Epoch  38 (33.78s)]	ELBO: 1629.292, 1700.968, 1738.909, 1757.121 (1731.550)	Log prob: 1640.402, 1707.703, 1744.350, 1760.638 (1758.677)	KLD: 11.108, 6.734, 5.442, 3.518 (27.126)	Grad: 0.113, 0.060, 0.050, 0.044
[Epoch  39 (37.08s)]	ELBO: 1629.598, 1701.419, 1739.064, 1757.141 (1731.368)	Log prob: 1640.725, 1708.151, 1744.459, 1760.664 (1757.852)	KLD: 11.127, 6.732, 5.395, 3.522 (26.484)	Grad: 0.119, 0.059, 0.050, 0.044
[Epoch  40 (33.98s)]	ELBO: 1630.190, 1701.501, 1739.227, 1757.354 (1730.174)	Log prob: 1641.336, 1708.230, 1744.599, 1760.889 (1756.592)	KLD: 11.146, 6.731, 5.371, 3.534 (26.418)	Grad: 0.114, 0.061, 0.051, 0.044
[Epoch  41 (33.10s)]	ELBO: 1630.130, 1701.761, 1739.181, 1757.317 (1731.498)	Log prob: 1641.283, 1708.494, 1744.553, 1760.849 (1757.876)	KLD: 11.154, 6.732, 5.372, 3.531 (26.378)	Grad: 0.120, 0.060, 0.051, 0.044
[Epoch  42 (32.99s)]	ELBO: 1630.665, 1702.359, 1739.559, 1757.783 (1732.157)	Log prob: 1641.837, 1709.107, 1744.916, 1761.299 (1758.781)	KLD: 11.170, 6.748, 5.357, 3.517 (26.624)	Grad: 0.118, 0.060, 0.050, 0.044
[Epoch  43 (32.17s)]	ELBO: 1630.899, 1702.255, 1739.435, 1757.619 (1728.079)	Log prob: 1642.073, 1708.978, 1744.801, 1761.180 (1754.644)	KLD: 11.174, 6.722, 5.365, 3.560 (26.565)	Grad: 0.123, 0.061, 0.052, 0.045
[Epoch  44 (32.62s)]	ELBO: 1631.128, 1702.460, 1739.627, 1757.814 (1731.586)	Log prob: 1642.312, 1709.196, 1744.978, 1761.360 (1758.750)	KLD: 11.184, 6.735, 5.352, 3.545 (27.164)	Grad: 0.122, 0.061, 0.051, 0.045
[Epoch  45 (33.18s)]	ELBO: 1631.361, 1702.779, 1739.726, 1758.024 (1729.546)	Log prob: 1642.530, 1709.509, 1745.080, 1761.553 (1756.297)	KLD: 11.170, 6.731, 5.354, 3.529 (26.751)	Grad: 0.125, 0.061, 0.051, 0.045
[Epoch  46 (32.72s)]	ELBO: 1631.623, 1702.969, 1739.715, 1757.859 (1728.935)	Log prob: 1642.833, 1709.733, 1745.020, 1761.400 (1754.464)	KLD: 11.211, 6.764, 5.305, 3.542 (25.528)	Grad: 0.127, 0.061, 0.051, 0.045
[Epoch  47 (33.23s)]	ELBO: 1631.783, 1702.981, 1739.535, 1757.709 (1727.988)	Log prob: 1642.993, 1709.749, 1744.831, 1761.256 (1754.298)	KLD: 11.209, 6.766, 5.296, 3.546 (26.310)	Grad: 0.127, 0.062, 0.052, 0.046
[Epoch  48 (32.61s)]	ELBO: 1632.275, 1703.416, 1739.762, 1758.023 (1730.614)	Log prob: 1643.503, 1710.179, 1745.052, 1761.550 (1758.198)	KLD: 11.226, 6.764, 5.290, 3.526 (27.584)	Grad: 0.128, 0.062, 0.051, 0.045
[Epoch  49 (32.91s)]	ELBO: 1632.288, 1703.459, 1739.895, 1758.058 (1732.298)	Log prob: 1643.529, 1710.221, 1745.190, 1761.600 (1758.654)	KLD: 11.241, 6.761, 5.296, 3.543 (26.356)	Grad: 0.131, 0.062, 0.052, 0.046
[Epoch  50 (32.63s)]	ELBO: 1632.629, 1703.728, 1740.246, 1758.384 (1730.829)	Log prob: 1643.905, 1710.492, 1745.510, 1761.926 (1757.479)	KLD: 11.276, 6.765, 5.264, 3.541 (26.651)	Grad: 0.134, 0.062, 0.052, 0.046
[Epoch  51 (32.73s)]	ELBO: 1633.106, 1704.050, 1740.300, 1758.532 (1729.274)	Log prob: 1644.400, 1710.813, 1745.568, 1762.080 (1755.924)	KLD: 11.294, 6.765, 5.269, 3.549 (26.650)	Grad: 0.132, 0.062, 0.052, 0.046
[Epoch  52 (33.07s)]	ELBO: 1633.198, 1704.009, 1740.396, 1758.472 (1730.194)	Log prob: 1644.497, 1710.822, 1745.651, 1762.012 (1756.829)	KLD: 11.298, 6.814, 5.253, 3.541 (26.635)	Grad: 0.135, 0.063, 0.051, 0.046
[Epoch  53 (33.30s)]	ELBO: 1633.440, 1704.490, 1740.945, 1759.032 (1732.343)	Log prob: 1644.781, 1711.293, 1746.190, 1762.598 (1759.434)	KLD: 11.341, 6.805, 5.246, 3.566 (27.091)	Grad: 0.136, 0.064, 0.051, 0.047
[Epoch  54 (32.69s)]	ELBO: 1633.938, 1704.942, 1741.156, 1759.243 (1727.519)	Log prob: 1645.291, 1711.746, 1746.401, 1762.787 (1753.980)	KLD: 11.354, 6.803, 5.244, 3.544 (26.461)	Grad: 0.139, 0.064, 0.052, 0.047
[Epoch  55 (33.87s)]	ELBO: 1634.108, 1705.050, 1741.229, 1759.226 (1729.359)	Log prob: 1645.460, 1711.837, 1746.449, 1762.753 (1756.444)	KLD: 11.353, 6.786, 5.219, 3.528 (27.085)	Grad: 0.139, 0.063, 0.051, 0.046
[Epoch  56 (33.94s)]	ELBO: 1634.244, 1705.022, 1741.162, 1759.152 (1732.363)	Log prob: 1645.646, 1711.817, 1746.372, 1762.724 (1759.510)	KLD: 11.402, 6.796, 5.209, 3.571 (27.147)	Grad: 0.141, 0.064, 0.052, 0.048
[Epoch  57 (31.17s)]	ELBO: 1634.365, 1705.301, 1741.455, 1759.527 (1731.745)	Log prob: 1645.755, 1712.125, 1746.676, 1763.104 (1759.002)	KLD: 11.391, 6.825, 5.222, 3.576 (27.257)	Grad: 0.143, 0.065, 0.052, 0.048
[Epoch  58 (31.56s)]	ELBO: 1634.794, 1705.773, 1741.804, 1759.916 (1732.020)	Log prob: 1646.209, 1712.592, 1747.005, 1763.459 (1759.392)	KLD: 11.415, 6.819, 5.201, 3.542 (27.372)	Grad: 0.143, 0.064, 0.052, 0.047
[Epoch  59 (32.68s)]	ELBO: 1634.868, 1705.835, 1741.901, 1759.885 (1732.535)	Log prob: 1646.319, 1712.667, 1747.082, 1763.443 (1758.906)	KLD: 11.451, 6.833, 5.181, 3.558 (26.371)	Grad: 0.147, 0.064, 0.052, 0.048
[Epoch  60 (32.51s)]	ELBO: 1635.286, 1706.161, 1742.176, 1760.293 (1730.146)	Log prob: 1646.715, 1712.986, 1747.330, 1763.845 (1757.356)	KLD: 11.429, 6.824, 5.153, 3.552 (27.209)	Grad: 0.144, 0.064, 0.052, 0.047
[Epoch  61 (36.38s)]	ELBO: 1635.200, 1706.165, 1742.099, 1760.055 (1723.783)	Log prob: 1646.638, 1712.973, 1747.246, 1763.604 (1751.649)	KLD: 11.438, 6.808, 5.148, 3.549 (27.865)	Grad: 0.148, 0.065, 0.053, 0.048
[Epoch  62 (29.87s)]	ELBO: 1635.542, 1706.328, 1742.340, 1760.381 (1729.458)	Log prob: 1646.990, 1713.148, 1747.501, 1763.922 (1756.294)	KLD: 11.449, 6.822, 5.160, 3.541 (26.836)	Grad: 0.149, 0.064, 0.052, 0.049
[Epoch  63 (26.11s)]	ELBO: 1635.656, 1706.438, 1742.355, 1760.190 (1728.059)	Log prob: 1647.158, 1713.259, 1747.489, 1763.753 (1754.401)	KLD: 11.502, 6.821, 5.135, 3.565 (26.342)	Grad: 0.149, 0.065, 0.052, 0.049
[Epoch  64 (26.33s)]	ELBO: 1635.728, 1706.709, 1742.491, 1760.634 (1733.117)	Log prob: 1647.228, 1713.511, 1747.637, 1764.202 (1759.849)	KLD: 11.499, 6.801, 5.146, 3.566 (26.732)	Grad: 0.157, 0.064, 0.053, 0.049
[Epoch  65 (26.05s)]	ELBO: 1635.848, 1706.778, 1742.561, 1760.660 (1730.268)	Log prob: 1647.345, 1713.562, 1747.700, 1764.216 (1756.798)	KLD: 11.498, 6.786, 5.138, 3.555 (26.529)	Grad: 0.152, 0.066, 0.053, 0.050
[Epoch  66 (25.83s)]	ELBO: 1636.216, 1707.052, 1742.792, 1760.818 (1730.454)	Log prob: 1647.748, 1713.854, 1747.909, 1764.396 (1757.660)	KLD: 11.532, 6.801, 5.117, 3.578 (27.206)	Grad: 0.158, 0.067, 0.053, 0.050
[Epoch  67 (25.67s)]	ELBO: 1636.285, 1707.236, 1742.945, 1761.014 (1728.729)	Log prob: 1647.851, 1714.035, 1748.066, 1764.578 (1755.622)	KLD: 11.566, 6.798, 5.121, 3.565 (26.893)	Grad: 0.158, 0.065, 0.054, 0.051
[Epoch  68 (25.65s)]	ELBO: 1636.314, 1707.467, 1743.075, 1761.199 (1733.449)	Log prob: 1647.895, 1714.269, 1748.179, 1764.756 (1759.885)	KLD: 11.580, 6.803, 5.104, 3.559 (26.436)	Grad: 0.162, 0.065, 0.054, 0.050
[Epoch  69 (25.59s)]	ELBO: 1636.489, 1707.342, 1743.116, 1761.109 (1733.151)	Log prob: 1648.057, 1714.166, 1748.205, 1764.683 (1760.518)	KLD: 11.568, 6.824, 5.089, 3.574 (27.367)	Grad: 0.162, 0.066, 0.054, 0.051
[Epoch  70 (25.37s)]	ELBO: 1636.859, 1707.633, 1743.276, 1761.361 (1733.393)	Log prob: 1648.434, 1714.445, 1748.378, 1764.926 (1759.917)	KLD: 11.575, 6.812, 5.101, 3.564 (26.525)	Grad: 0.159, 0.065, 0.054, 0.052
[Epoch  71 (25.67s)]	ELBO: 1636.485, 1707.417, 1743.104, 1761.124 (1729.394)	Log prob: 1648.071, 1714.241, 1748.207, 1764.691 (1756.211)	KLD: 11.586, 6.824, 5.102, 3.567 (26.817)	Grad: 0.164, 0.066, 0.055, 0.052
[Epoch  72 (26.14s)]	ELBO: 1636.957, 1707.692, 1743.191, 1761.375 (1728.140)	Log prob: 1648.569, 1714.496, 1748.308, 1764.939 (1755.367)	KLD: 11.612, 6.805, 5.118, 3.565 (27.227)	Grad: 0.161, 0.066, 0.055, 0.052
[Epoch  73 (26.07s)]	ELBO: 1637.121, 1707.787, 1743.315, 1761.394 (1731.785)	Log prob: 1648.739, 1714.592, 1748.396, 1764.977 (1759.367)	KLD: 11.617, 6.804, 5.079, 3.581 (27.582)	Grad: 0.163, 0.067, 0.055, 0.053
[Epoch  74 (25.84s)]	ELBO: 1636.965, 1707.814, 1743.263, 1761.426 (1732.427)	Log prob: 1648.619, 1714.602, 1748.354, 1764.995 (1758.671)	KLD: 11.655, 6.787, 5.092, 3.569 (26.245)	Grad: 0.171, 0.067, 0.056, 0.052
[Epoch  75 (25.79s)]	ELBO: 1637.399, 1708.138, 1743.442, 1761.572 (1730.826)	Log prob: 1649.043, 1714.964, 1748.536, 1765.167 (1757.019)	KLD: 11.643, 6.825, 5.093, 3.594 (26.193)	Grad: 0.164, 0.066, 0.056, 0.054
[Epoch  76 (25.96s)]	ELBO: 1637.366, 1708.108, 1743.379, 1761.624 (1731.150)	Log prob: 1649.036, 1714.892, 1748.464, 1765.216 (1757.882)	KLD: 11.670, 6.784, 5.085, 3.592 (26.732)	Grad: 0.169, 0.067, 0.056, 0.053
[Epoch  77 (25.70s)]	ELBO: 1637.570, 1708.191, 1743.522, 1761.710 (1732.464)	Log prob: 1649.262, 1714.983, 1748.593, 1765.290 (1759.443)	KLD: 11.692, 6.791, 5.069, 3.581 (26.979)	Grad: 0.167, 0.066, 0.055, 0.053
[Epoch  78 (25.86s)]	ELBO: 1637.375, 1708.176, 1743.441, 1761.631 (1731.680)	Log prob: 1649.087, 1714.952, 1748.515, 1765.213 (1758.385)	KLD: 11.711, 6.776, 5.073, 3.583 (26.705)	Grad: 0.173, 0.066, 0.057, 0.055
[Epoch  79 (26.04s)]	ELBO: 1637.564, 1708.218, 1743.531, 1761.751 (1732.011)	Log prob: 1649.261, 1714.989, 1748.587, 1765.356 (1758.768)	KLD: 11.697, 6.771, 5.056, 3.606 (26.757)	Grad: 0.168, 0.067, 0.057, 0.055
[Epoch  80 (27.14s)]	ELBO: 1637.870, 1708.461, 1743.582, 1761.688 (1732.559)	Log prob: 1649.578, 1715.227, 1748.630, 1765.288 (1759.275)	KLD: 11.707, 6.765, 5.048, 3.600 (26.716)	Grad: 0.172, 0.066, 0.057, 0.056
[Epoch  81 (26.97s)]	ELBO: 1637.779, 1708.549, 1743.643, 1761.829 (1731.209)	Log prob: 1649.508, 1715.320, 1748.692, 1765.406 (1758.005)	KLD: 11.728, 6.771, 5.050, 3.577 (26.796)	Grad: 0.181, 0.067, 0.057, 0.056
[Epoch  82 (24.93s)]	ELBO: 1637.699, 1708.345, 1743.237, 1761.379 (1730.738)	Log prob: 1649.426, 1715.096, 1748.288, 1764.991 (1757.038)	KLD: 11.727, 6.750, 5.051, 3.611 (26.300)	Grad: 0.181, 0.068, 0.058, 0.057
[Epoch  83 (24.81s)]	ELBO: 1637.825, 1708.557, 1743.619, 1761.721 (1732.258)	Log prob: 1649.611, 1715.310, 1748.668, 1765.314 (1759.469)	KLD: 11.786, 6.751, 5.049, 3.593 (27.211)	Grad: 0.179, 0.067, 0.058, 0.057
[Epoch  84 (25.08s)]	ELBO: 1638.125, 1708.588, 1743.659, 1761.917 (1730.485)	Log prob: 1649.897, 1715.377, 1748.730, 1765.517 (1757.313)	KLD: 11.774, 6.789, 5.072, 3.602 (26.828)	Grad: 0.184, 0.068, 0.058, 0.056
[Epoch  85 (21.53s)]	ELBO: 1638.088, 1708.789, 1743.687, 1761.941 (1730.316)	Log prob: 1649.882, 1715.568, 1748.720, 1765.558 (1757.088)	KLD: 11.795, 6.778, 5.033, 3.615 (26.772)	Grad: 0.183, 0.068, 0.058, 0.057
[Epoch  86 (18.67s)]	ELBO: 1638.336, 1708.923, 1743.902, 1762.038 (1731.707)	Log prob: 1650.185, 1715.690, 1748.942, 1765.677 (1758.289)	KLD: 11.849, 6.765, 5.039, 3.640 (26.582)	Grad: 0.178, 0.067, 0.058, 0.057
[Epoch  87 (20.49s)]	ELBO: 1638.573, 1709.147, 1744.007, 1762.124 (1732.879)	Log prob: 1650.417, 1715.888, 1749.013, 1765.733 (1759.962)	KLD: 11.845, 6.741, 5.007, 3.610 (27.082)	Grad: 0.183, 0.068, 0.059, 0.058
[Epoch  88 (22.48s)]	ELBO: 1638.564, 1709.131, 1743.833, 1762.065 (1731.974)	Log prob: 1650.426, 1715.862, 1748.870, 1765.663 (1758.523)	KLD: 11.861, 6.732, 5.036, 3.596 (26.549)	Grad: 0.188, 0.068, 0.059, 0.058
[Epoch  89 (22.06s)]	ELBO: 1638.625, 1709.283, 1743.866, 1762.086 (1730.863)	Log prob: 1650.485, 1716.047, 1748.898, 1765.696 (1757.747)	KLD: 11.861, 6.764, 5.033, 3.610 (26.884)	Grad: 0.190, 0.067, 0.059, 0.059
[Epoch  90 (19.25s)]	ELBO: 1638.651, 1709.097, 1743.797, 1761.951 (1728.285)	Log prob: 1650.541, 1715.818, 1748.820, 1765.540 (1755.464)	KLD: 11.890, 6.723, 5.022, 3.590 (27.179)	Grad: 0.195, 0.070, 0.061, 0.059
[Epoch  91 (19.56s)]	ELBO: 1638.789, 1709.020, 1743.481, 1761.507 (1730.745)	Log prob: 1650.679, 1715.758, 1748.501, 1765.130 (1758.606)	KLD: 11.891, 6.738, 5.019, 3.622 (27.861)	Grad: 0.196, 0.069, 0.060, 0.061
[Epoch  92 (19.49s)]	ELBO: 1638.522, 1709.117, 1743.682, 1761.848 (1731.681)	Log prob: 1650.417, 1715.852, 1748.714, 1765.484 (1758.968)	KLD: 11.895, 6.735, 5.032, 3.635 (27.286)	Grad: 0.196, 0.070, 0.061, 0.061
No improvement after 25 epochs...
Best epoch(s): [68]	Training time(s): 2782.13s (2782.13s)	Best ELBO: 1762.124 (1733.449)	Best log prob: 1765.733 (1760.518)
Avg. mu: 0.039, -0.446, 0.021, 0.070, 0.109, 0.057, 0.159, 0.017, 0.070, 0.038, 0.132, 0.006
Avg. var: 0.000, 0.001, 0.000, 0.019, 0.006, 0.008, 0.026, 0.033, 0.030, 0.102, 0.113, 0.110
Max. mu: 2.401, 1.119, 1.545, 3.439, 2.524, 3.012, 3.082, 3.032, 3.205, 4.243, 3.756, 3.845
Max. var: 0.003, 0.005, 0.003, 0.095, 0.045, 0.081, 0.115, 0.193, 0.219, 0.433, 0.552, 0.550
Min. mu: -2.930, -3.631, -2.528, -3.200, -3.357, -3.601, -3.178, -3.434, -3.100, -3.310, -3.163, -3.707
Min. var: 0.000, 0.000, 0.000, 0.005, 0.001, 0.001, 0.005, 0.007, 0.005, 0.031, 0.027, 0.029
Cov. mu:
[[0.580 0.015 -0.038 -0.125 -0.012 0.097 0.101 0.003 0.060 -0.004 -0.051
  -0.039]
 [0.015 0.496 -0.029 0.079 0.027 0.025 0.008 0.089 -0.114 0.066 -0.013
  -0.021]
 [-0.038 -0.029 0.590 0.033 -0.048 -0.037 -0.045 0.095 -0.035 -0.067
  0.040 -0.027]
 [-0.125 0.079 0.033 0.827 0.010 -0.031 -0.132 -0.015 -0.034 0.010 0.054
  0.025]
 [-0.012 0.027 -0.048 0.010 0.462 0.041 0.031 -0.043 0.005 -0.000 0.018
  -0.033]
 [0.097 0.025 -0.037 -0.031 0.041 0.487 0.075 -0.002 0.019 -0.008 -0.010
  -0.045]
 [0.101 0.008 -0.045 -0.132 0.031 0.075 0.662 0.022 0.011 -0.004 -0.046
  -0.041]
 [0.003 0.089 0.095 -0.015 -0.043 -0.002 0.022 0.703 -0.073 0.011 0.002
  0.004]
 [0.060 -0.114 -0.035 -0.034 0.005 0.019 0.011 -0.073 0.678 -0.023 -0.013
  0.052]
 [-0.004 0.066 -0.067 0.010 -0.000 -0.008 -0.004 0.011 -0.023 0.778
  -0.016 0.031]
 [-0.051 -0.013 0.040 0.054 0.018 -0.010 -0.046 0.002 -0.013 -0.016 0.736
  -0.039]
 [-0.039 -0.021 -0.027 0.025 -0.033 -0.045 -0.041 0.004 0.052 0.031
  -0.039 0.776]]
Avg. mu: 0.039, -0.446, 0.021, 0.070, 0.109, 0.057, 0.159, 0.017, 0.070, 0.038, 0.132, 0.006
Avg. var: 0.000, 0.001, 0.000, 0.019, 0.006, 0.008, 0.026, 0.033, 0.030, 0.102, 0.113, 0.110
Max. mu: 2.401, 1.119, 1.545, 3.439, 2.524, 3.012, 3.082, 3.032, 3.205, 4.243, 3.756, 3.845
Max. var: 0.003, 0.005, 0.003, 0.095, 0.045, 0.081, 0.115, 0.193, 0.219, 0.433, 0.552, 0.550
Min. mu: -2.930, -3.631, -2.528, -3.200, -3.357, -3.601, -3.178, -3.434, -3.100, -3.310, -3.163, -3.707
Min. var: 0.000, 0.000, 0.000, 0.005, 0.001, 0.001, 0.005, 0.007, 0.005, 0.031, 0.027, 0.029
Cov. mu:
[[0.580 0.015 -0.038 -0.125 -0.012 0.097 0.101 0.003 0.060 -0.004 -0.051
  -0.039]
 [0.015 0.496 -0.029 0.079 0.027 0.025 0.008 0.089 -0.114 0.066 -0.013
  -0.021]
 [-0.038 -0.029 0.590 0.033 -0.048 -0.037 -0.045 0.095 -0.035 -0.067
  0.040 -0.027]
 [-0.125 0.079 0.033 0.827 0.010 -0.031 -0.132 -0.015 -0.034 0.010 0.054
  0.025]
 [-0.012 0.027 -0.048 0.010 0.462 0.041 0.031 -0.043 0.005 -0.000 0.018
  -0.033]
 [0.097 0.025 -0.037 -0.031 0.041 0.487 0.075 -0.002 0.019 -0.008 -0.010
  -0.045]
 [0.101 0.008 -0.045 -0.132 0.031 0.075 0.662 0.022 0.011 -0.004 -0.046
  -0.041]
 [0.003 0.089 0.095 -0.015 -0.043 -0.002 0.022 0.703 -0.073 0.011 0.002
  0.004]
 [0.060 -0.114 -0.035 -0.034 0.005 0.019 0.011 -0.073 0.678 -0.023 -0.013
  0.052]
 [-0.004 0.066 -0.067 0.010 -0.000 -0.008 -0.004 0.011 -0.023 0.778
  -0.016 0.031]
 [-0.051 -0.013 0.040 0.054 0.018 -0.010 -0.046 0.002 -0.013 -0.016 0.736
  -0.039]
 [-0.039 -0.021 -0.027 0.025 -0.033 -0.045 -0.041 0.004 0.052 0.031
  -0.039 0.776]]
