Encoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Encoder                                  --
├─Linear: 1-1                            76,930
├─Linear: 1-2                            4,851
=================================================================
Total params: 81,781
Trainable params: 81,781
Non-trainable params: 0
=================================================================
Encoder to Latents 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            100
├─Linear: 1-2                            100
=================================================================
Total params: 200
Trainable params: 200
Non-trainable params: 0
=================================================================
Encoder to Latents 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            100
├─Linear: 1-2                            100
=================================================================
Total params: 200
Trainable params: 200
Non-trainable params: 0
=================================================================
Encoder to Latents 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            100
├─Linear: 1-2                            100
=================================================================
Total params: 200
Trainable params: 200
Non-trainable params: 0
=================================================================
Encoder to Latents 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            100
├─Linear: 1-2                            100
=================================================================
Total params: 200
Trainable params: 200
Non-trainable params: 0
=================================================================
Encoder to Latents 4
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            100
├─Linear: 1-2                            100
=================================================================
Total params: 200
Trainable params: 200
Non-trainable params: 0
=================================================================
Latents to Decoder 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            147
=================================================================
Total params: 147
Trainable params: 147
Non-trainable params: 0
=================================================================
Latents to Decoder 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            147
=================================================================
Total params: 147
Trainable params: 147
Non-trainable params: 0
=================================================================
Latents to Decoder 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            147
=================================================================
Total params: 147
Trainable params: 147
Non-trainable params: 0
=================================================================
Latents to Decoder 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            147
=================================================================
Total params: 147
Trainable params: 147
Non-trainable params: 0
=================================================================
Latents to Decoder 4
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            147
=================================================================
Total params: 147
Trainable params: 147
Non-trainable params: 0
=================================================================
Decoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Decoder                                  --
├─Linear: 1-1                            4,900
├─Linear: 1-2                            77,616
=================================================================
Total params: 82,516
Trainable params: 82,516
Non-trainable params: 0
=================================================================
[Epoch   1 (133.52s)]	ELBO: 1351.373, 1420.154, 1436.418, 1439.677, 1441.280 (1567.602)	Log prob: 1373.597, 1424.580, 1438.117, 1440.536, 1441.799 (1587.213)	KLD: 22.224, 4.425, 1.698, 0.859, 0.519 (19.612)	Grad: 0.090, 0.049, 0.042, 0.045, 0.047
[Epoch   2 (104.75s)]	ELBO: 1468.540, 1562.913, 1609.740, 1627.022, 1629.491 (1629.212)	Log prob: 1475.511, 1568.064, 1614.032, 1629.340, 1630.352 (1649.728)	KLD: 6.971, 5.151, 4.289, 2.317, 0.862 (20.515)	Grad: 0.095, 0.047, 0.038, 0.037, 0.030
[Epoch   3 (115.48s)]	ELBO: 1487.716, 1582.791, 1634.198, 1658.484, 1663.762 (1650.577)	Log prob: 1494.666, 1588.051, 1638.606, 1661.704, 1665.297 (1672.565)	KLD: 6.951, 5.259, 4.410, 3.220, 1.535 (21.988)	Grad: 0.092, 0.050, 0.044, 0.038, 0.030
[Epoch   4 (130.13s)]	ELBO: 1504.177, 1593.163, 1644.144, 1671.268, 1680.346 (1662.139)	Log prob: 1511.356, 1598.456, 1648.617, 1674.806, 1682.589 (1685.745)	KLD: 7.179, 5.294, 4.472, 3.538, 2.243 (23.606)	Grad: 0.088, 0.048, 0.047, 0.039, 0.034
[Epoch   5 (159.41s)]	ELBO: 1518.750, 1599.949, 1650.052, 1678.419, 1688.759 (1662.375)	Log prob: 1526.091, 1605.270, 1654.629, 1682.112, 1691.248 (1685.483)	KLD: 7.341, 5.321, 4.577, 3.693, 2.488 (23.108)	Grad: 0.091, 0.049, 0.049, 0.040, 0.036
[Epoch   6 (153.28s)]	ELBO: 1530.196, 1605.555, 1653.900, 1682.056, 1693.607 (1668.806)	Log prob: 1537.558, 1610.878, 1658.514, 1685.857, 1696.224 (1692.520)	KLD: 7.362, 5.322, 4.615, 3.801, 2.618 (23.715)	Grad: 0.091, 0.050, 0.051, 0.042, 0.038
[Epoch   7 (169.35s)]	ELBO: 1537.697, 1610.073, 1657.114, 1684.879, 1697.423 (1669.565)	Log prob: 1545.154, 1615.384, 1661.811, 1688.701, 1700.100 (1695.313)	KLD: 7.457, 5.311, 4.696, 3.823, 2.677 (25.748)	Grad: 0.097, 0.051, 0.053, 0.044, 0.039
[Epoch   8 (160.58s)]	ELBO: 1544.271, 1614.639, 1660.638, 1687.783, 1700.825 (1672.490)	Log prob: 1551.815, 1619.913, 1665.373, 1691.603, 1703.506 (1696.453)	KLD: 7.543, 5.272, 4.735, 3.822, 2.679 (23.964)	Grad: 0.096, 0.051, 0.054, 0.045, 0.041
[Epoch   9 (146.72s)]	ELBO: 1548.665, 1618.209, 1663.891, 1690.273, 1703.708 (1676.590)	Log prob: 1556.333, 1623.455, 1668.657, 1694.084, 1706.380 (1700.617)	KLD: 7.669, 5.246, 4.767, 3.810, 2.672 (24.028)	Grad: 0.101, 0.052, 0.056, 0.045, 0.041
[Epoch  10 (153.53s)]	ELBO: 1552.566, 1621.628, 1666.538, 1692.755, 1706.253 (1679.342)	Log prob: 1560.369, 1626.832, 1671.327, 1696.521, 1708.933 (1703.727)	KLD: 7.802, 5.203, 4.790, 3.769, 2.679 (24.384)	Grad: 0.102, 0.054, 0.055, 0.046, 0.042
[Epoch  11 (141.78s)]	ELBO: 1556.243, 1624.918, 1669.195, 1694.901, 1708.538 (1682.169)	Log prob: 1564.082, 1630.090, 1673.995, 1698.653, 1711.255 (1706.436)	KLD: 7.839, 5.173, 4.800, 3.751, 2.717 (24.267)	Grad: 0.102, 0.052, 0.056, 0.046, 0.043
[Epoch  12 (152.60s)]	ELBO: 1558.785, 1627.404, 1671.481, 1696.727, 1710.427 (1681.143)	Log prob: 1566.695, 1632.581, 1676.306, 1700.437, 1713.168 (1705.057)	KLD: 7.910, 5.176, 4.824, 3.710, 2.741 (23.914)	Grad: 0.107, 0.053, 0.055, 0.045, 0.043
[Epoch  13 (160.50s)]	ELBO: 1562.247, 1630.299, 1673.789, 1698.973, 1712.414 (1682.654)	Log prob: 1570.205, 1635.470, 1678.634, 1702.630, 1715.168 (1706.945)	KLD: 7.958, 5.171, 4.846, 3.656, 2.753 (24.291)	Grad: 0.103, 0.053, 0.055, 0.045, 0.042
[Epoch  14 (147.23s)]	ELBO: 1564.377, 1632.362, 1675.679, 1700.287, 1713.860 (1680.317)	Log prob: 1572.421, 1637.512, 1680.511, 1703.942, 1716.605 (1705.404)	KLD: 8.044, 5.150, 4.832, 3.654, 2.746 (25.087)	Grad: 0.109, 0.054, 0.055, 0.044, 0.043
[Epoch  15 (149.94s)]	ELBO: 1566.163, 1633.948, 1676.892, 1701.225, 1714.869 (1675.808)	Log prob: 1574.210, 1639.066, 1681.727, 1704.840, 1717.584 (1700.361)	KLD: 8.047, 5.118, 4.834, 3.616, 2.717 (24.553)	Grad: 0.108, 0.053, 0.055, 0.044, 0.042
[Epoch  16 (152.42s)]	ELBO: 1568.125, 1636.097, 1678.545, 1702.531, 1716.246 (1686.906)	Log prob: 1576.169, 1641.230, 1683.341, 1706.132, 1718.940 (1711.496)	KLD: 8.043, 5.132, 4.795, 3.600, 2.693 (24.590)	Grad: 0.115, 0.054, 0.054, 0.044, 0.042
[Epoch  17 (142.94s)]	ELBO: 1570.275, 1638.051, 1680.123, 1704.008, 1717.584 (1682.287)	Log prob: 1578.323, 1643.173, 1684.916, 1707.595, 1720.288 (1706.718)	KLD: 8.048, 5.121, 4.793, 3.587, 2.705 (24.431)	Grad: 0.113, 0.054, 0.053, 0.043, 0.042
[Epoch  18 (142.57s)]	ELBO: 1571.769, 1639.410, 1681.161, 1705.157, 1718.678 (1685.210)	Log prob: 1579.801, 1644.544, 1685.966, 1708.736, 1721.356 (1709.211)	KLD: 8.032, 5.135, 4.805, 3.579, 2.677 (24.001)	Grad: 0.114, 0.054, 0.053, 0.043, 0.042
[Epoch  19 (152.11s)]	ELBO: 1572.787, 1641.097, 1682.290, 1706.262, 1719.595 (1688.861)	Log prob: 1580.822, 1646.259, 1687.051, 1709.822, 1722.264 (1713.319)	KLD: 8.035, 5.163, 4.761, 3.560, 2.669 (24.458)	Grad: 0.118, 0.055, 0.051, 0.044, 0.042
[Epoch  20 (144.88s)]	ELBO: 1573.777, 1642.350, 1683.542, 1707.329, 1720.766 (1687.172)	Log prob: 1581.826, 1647.509, 1688.311, 1710.854, 1723.431 (1711.026)	KLD: 8.048, 5.159, 4.769, 3.525, 2.666 (23.854)	Grad: 0.119, 0.055, 0.051, 0.043, 0.042
[Epoch  21 (146.01s)]	ELBO: 1574.811, 1643.650, 1684.775, 1708.429, 1721.788 (1688.649)	Log prob: 1582.826, 1648.822, 1689.534, 1711.938, 1724.418 (1712.574)	KLD: 8.017, 5.174, 4.760, 3.510, 2.631 (23.925)	Grad: 0.119, 0.055, 0.051, 0.043, 0.041
[Epoch  22 (149.51s)]	ELBO: 1575.986, 1644.823, 1685.849, 1709.381, 1722.672 (1690.617)	Log prob: 1584.061, 1649.983, 1690.599, 1712.872, 1725.299 (1714.406)	KLD: 8.074, 5.160, 4.750, 3.493, 2.628 (23.789)	Grad: 0.119, 0.055, 0.052, 0.043, 0.042
[Epoch  23 (147.16s)]	ELBO: 1576.687, 1645.726, 1686.567, 1710.112, 1723.239 (1691.245)	Log prob: 1584.689, 1650.927, 1691.312, 1713.572, 1725.847 (1715.399)	KLD: 8.003, 5.201, 4.744, 3.460, 2.609 (24.154)	Grad: 0.120, 0.054, 0.051, 0.042, 0.040
[Epoch  24 (145.65s)]	ELBO: 1576.944, 1646.066, 1686.561, 1710.170, 1723.328 (1688.815)	Log prob: 1584.974, 1651.285, 1691.281, 1713.632, 1725.951 (1713.477)	KLD: 8.030, 5.218, 4.720, 3.463, 2.623 (24.661)	Grad: 0.121, 0.055, 0.051, 0.042, 0.041
[Epoch  25 (152.71s)]	ELBO: 1577.908, 1646.817, 1687.135, 1710.795, 1723.974 (1691.435)	Log prob: 1585.925, 1652.031, 1691.873, 1714.210, 1726.591 (1715.303)	KLD: 8.018, 5.214, 4.740, 3.415, 2.618 (23.869)	Grad: 0.122, 0.055, 0.052, 0.042, 0.041
[Epoch  26 (142.90s)]	ELBO: 1578.947, 1647.739, 1687.658, 1711.465, 1724.458 (1685.165)	Log prob: 1586.936, 1652.948, 1692.421, 1714.864, 1727.023 (1708.422)	KLD: 7.989, 5.209, 4.762, 3.399, 2.566 (23.257)	Grad: 0.123, 0.055, 0.051, 0.042, 0.040
[Epoch  27 (141.45s)]	ELBO: 1579.353, 1648.371, 1687.920, 1711.737, 1724.716 (1694.533)	Log prob: 1587.370, 1653.624, 1692.585, 1715.150, 1727.274 (1718.223)	KLD: 8.016, 5.252, 4.666, 3.413, 2.558 (23.690)	Grad: 0.126, 0.055, 0.051, 0.042, 0.041
[Epoch  28 (146.12s)]	ELBO: 1580.310, 1649.360, 1689.495, 1713.154, 1726.016 (1694.678)	Log prob: 1588.333, 1654.599, 1694.188, 1716.536, 1728.553 (1717.461)	KLD: 8.023, 5.239, 4.693, 3.382, 2.537 (22.784)	Grad: 0.127, 0.055, 0.050, 0.042, 0.040
[Epoch  29 (142.23s)]	ELBO: 1580.491, 1649.717, 1689.780, 1713.258, 1726.248 (1695.077)	Log prob: 1588.513, 1654.973, 1694.433, 1716.636, 1728.783 (1719.132)	KLD: 8.021, 5.258, 4.653, 3.378, 2.535 (24.055)	Grad: 0.127, 0.056, 0.050, 0.042, 0.040
[Epoch  30 (140.96s)]	ELBO: 1581.211, 1650.049, 1690.153, 1713.789, 1726.679 (1691.335)	Log prob: 1589.211, 1655.322, 1694.813, 1717.147, 1729.224 (1715.316)	KLD: 8.000, 5.272, 4.659, 3.358, 2.546 (23.980)	Grad: 0.126, 0.056, 0.050, 0.042, 0.040
[Epoch  31 (142.13s)]	ELBO: 1581.104, 1650.168, 1689.978, 1713.545, 1726.192 (1693.102)	Log prob: 1589.113, 1655.485, 1694.666, 1716.881, 1728.700 (1716.684)	KLD: 8.009, 5.316, 4.690, 3.336, 2.509 (23.582)	Grad: 0.128, 0.056, 0.052, 0.042, 0.040
[Epoch  32 (147.22s)]	ELBO: 1581.621, 1650.633, 1690.757, 1714.409, 1727.231 (1685.299)	Log prob: 1589.616, 1655.941, 1695.444, 1717.759, 1729.742 (1708.913)	KLD: 7.994, 5.307, 4.685, 3.349, 2.511 (23.614)	Grad: 0.129, 0.056, 0.051, 0.042, 0.040
[Epoch  33 (137.34s)]	ELBO: 1581.807, 1650.817, 1690.873, 1714.193, 1727.045 (1693.005)	Log prob: 1589.818, 1656.124, 1695.513, 1717.524, 1729.517 (1717.319)	KLD: 8.011, 5.306, 4.641, 3.331, 2.474 (24.314)	Grad: 0.127, 0.058, 0.050, 0.043, 0.040
[Epoch  34 (128.46s)]	ELBO: 1582.172, 1651.175, 1691.277, 1714.636, 1727.325 (1684.588)	Log prob: 1590.217, 1656.502, 1695.890, 1717.951, 1729.826 (1707.553)	KLD: 8.044, 5.327, 4.613, 3.313, 2.500 (22.965)	Grad: 0.128, 0.058, 0.050, 0.043, 0.040
[Epoch  35 (136.58s)]	ELBO: 1582.539, 1651.849, 1691.706, 1714.810, 1727.636 (1692.538)	Log prob: 1590.565, 1657.175, 1696.296, 1718.123, 1730.149 (1715.995)	KLD: 8.025, 5.326, 4.591, 3.314, 2.515 (23.457)	Grad: 0.130, 0.058, 0.049, 0.043, 0.040
[Epoch  36 (134.39s)]	ELBO: 1583.250, 1652.117, 1692.122, 1715.089, 1727.831 (1691.300)	Log prob: 1591.292, 1657.448, 1696.728, 1718.392, 1730.326 (1714.657)	KLD: 8.042, 5.330, 4.606, 3.303, 2.494 (23.357)	Grad: 0.128, 0.057, 0.050, 0.043, 0.040
[Epoch  37 (131.84s)]	ELBO: 1583.756, 1652.769, 1692.765, 1715.526, 1728.398 (1696.589)	Log prob: 1591.807, 1658.105, 1697.324, 1718.825, 1730.895 (1720.350)	KLD: 8.051, 5.337, 4.558, 3.299, 2.494 (23.760)	Grad: 0.131, 0.058, 0.048, 0.043, 0.040
[Epoch  38 (138.20s)]	ELBO: 1584.287, 1653.380, 1693.168, 1715.930, 1728.735 (1693.448)	Log prob: 1592.333, 1658.717, 1697.732, 1719.216, 1731.240 (1717.173)	KLD: 8.045, 5.338, 4.564, 3.285, 2.505 (23.725)	Grad: 0.129, 0.059, 0.049, 0.042, 0.040
[Epoch  39 (137.34s)]	ELBO: 1584.309, 1653.525, 1692.977, 1715.705, 1728.623 (1694.349)	Log prob: 1592.387, 1658.885, 1697.490, 1719.000, 1731.135 (1718.460)	KLD: 8.078, 5.361, 4.512, 3.294, 2.513 (24.111)	Grad: 0.133, 0.059, 0.048, 0.043, 0.040
[Epoch  40 (135.39s)]	ELBO: 1585.083, 1654.409, 1692.681, 1715.630, 1728.399 (1694.622)	Log prob: 1593.169, 1659.767, 1697.065, 1718.949, 1730.913 (1718.175)	KLD: 8.086, 5.358, 4.384, 3.319, 2.512 (23.553)	Grad: 0.131, 0.058, 0.047, 0.042, 0.040
[Epoch  41 (111.03s)]	ELBO: 1584.349, 1653.983, 1692.645, 1715.413, 1728.154 (1691.982)	Log prob: 1592.422, 1659.362, 1697.026, 1718.711, 1730.662 (1716.145)	KLD: 8.075, 5.379, 4.381, 3.297, 2.507 (24.163)	Grad: 0.137, 0.059, 0.048, 0.043, 0.040
[Epoch  42 (109.50s)]	ELBO: 1584.885, 1654.521, 1693.943, 1716.503, 1729.207 (1696.071)	Log prob: 1592.991, 1659.875, 1698.380, 1719.814, 1731.688 (1719.941)	KLD: 8.107, 5.354, 4.437, 3.311, 2.482 (23.870)	Grad: 0.136, 0.059, 0.048, 0.043, 0.040
[Epoch  43 (123.93s)]	ELBO: 1585.484, 1655.007, 1694.180, 1716.700, 1729.219 (1695.050)	Log prob: 1593.599, 1660.388, 1698.588, 1719.983, 1731.683 (1718.551)	KLD: 8.115, 5.381, 4.409, 3.282, 2.466 (23.501)	Grad: 0.137, 0.058, 0.047, 0.043, 0.040
[Epoch  44 (105.49s)]	ELBO: 1584.913, 1654.468, 1693.687, 1716.189, 1728.688 (1693.982)	Log prob: 1593.038, 1659.800, 1698.124, 1719.469, 1731.172 (1717.560)	KLD: 8.124, 5.332, 4.438, 3.281, 2.483 (23.577)	Grad: 0.137, 0.059, 0.049, 0.043, 0.040
[Epoch  45 (106.95s)]	ELBO: 1586.045, 1655.559, 1695.099, 1717.267, 1729.796 (1693.574)	Log prob: 1594.226, 1660.922, 1699.549, 1720.524, 1732.254 (1717.476)	KLD: 8.181, 5.363, 4.451, 3.256, 2.460 (23.902)	Grad: 0.139, 0.060, 0.048, 0.043, 0.040
[Epoch  46 (103.42s)]	ELBO: 1586.352, 1655.759, 1695.306, 1717.687, 1729.994 (1696.442)	Log prob: 1594.518, 1661.120, 1699.802, 1720.948, 1732.466 (1720.014)	KLD: 8.166, 5.362, 4.495, 3.262, 2.473 (23.572)	Grad: 0.144, 0.061, 0.049, 0.043, 0.041
No improvement after 10 epochs...
Best epoch(s): [37]	Training time(s): 6397.65s (6397.65s)	Best ELBO: 1729.994 (1696.589)	Best log prob: 1732.466 (1720.350)
Avg. mu: -0.348, 0.431, -0.219, 0.147, 0.185, 0.116, 0.137, -0.017, -0.023, -0.001
Avg. var: 0.000, 0.000, 0.003, 0.006, 0.006, 0.012, 0.038, 0.021, 0.097, 0.088
Max. mu: 2.495, 2.908, 3.036, 3.599, 2.375, 2.904, 3.702, 2.759, 3.661, 3.265
Max. var: 0.004, 0.006, 0.021, 0.052, 0.053, 0.097, 0.261, 0.152, 0.537, 0.968
Min. mu: -3.264, -2.258, -2.418, -3.056, -1.713, -3.564, -3.092, -4.060, -3.609, -3.593
Min. var: 0.000, 0.000, 0.000, 0.000, 0.000, 0.001, 0.006, 0.004, 0.020, 0.020
Cov. mu:
[[0.900 0.131 -0.093 0.115 -0.094 -0.006 -0.090 0.043 -0.066 -0.083]
 [0.131 0.741 0.139 0.160 0.065 0.022 -0.071 0.027 -0.094 0.129]
 [-0.093 0.139 0.499 -0.015 0.069 0.001 -0.026 0.011 0.019 0.071]
 [0.115 0.160 -0.015 0.588 -0.038 0.040 -0.022 -0.035 -0.032 0.080]
 [-0.094 0.065 0.069 -0.038 0.451 -0.097 0.019 0.060 0.021 0.022]
 [-0.006 0.022 0.001 0.040 -0.097 0.430 0.001 0.033 0.010 -0.008]
 [-0.090 -0.071 -0.026 -0.022 0.019 0.001 0.642 -0.071 0.062 -0.039]
 [0.043 0.027 0.011 -0.035 0.060 0.033 -0.071 0.572 0.001 0.006]
 [-0.066 -0.094 0.019 -0.032 0.021 0.010 0.062 0.001 0.718 -0.007]
 [-0.083 0.129 0.071 0.080 0.022 -0.008 -0.039 0.006 -0.007 0.763]]
