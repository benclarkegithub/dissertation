Encoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Encoder                                  --
├─Linear: 1-1                            76,930
├─Linear: 1-2                            4,851
=================================================================
Total params: 81,781
Trainable params: 81,781
Non-trainable params: 0
=================================================================
Encoder to Latents 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 4
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 5
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 6
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 7
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 8
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 9
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Latents to Decoder 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 4
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 5
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 6
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 7
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 8
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 9
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Decoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Decoder                                  --
├─Linear: 1-1                            4,900
├─Linear: 1-2                            77,616
=================================================================
Total params: 82,516
Trainable params: 82,516
Non-trainable params: 0
=================================================================
[Epoch   1 (41.94s)]	ELBO: 1308.397, 1398.347, 1443.419, 1469.609, 1485.102, 1489.934, 1494.342, 1495.936, 1497.761, 1499.526 (1587.537)	Log prob: 1323.397, 1404.056, 1445.967, 1471.399, 1486.518, 1490.808, 1495.407, 1496.642, 1498.436, 1499.958 (1608.561)	KLD: 15.000, 5.709, 2.548, 1.790, 1.416, 0.875, 1.065, 0.707, 0.675, 0.431 (21.025)	Grad: 0.087, 0.079, 0.060, 0.050, 0.051, 0.052, 0.060, 0.061, 0.064, 0.063
[Epoch   2 (46.56s)]	ELBO: 1398.172, 1467.495, 1526.422, 1567.371, 1593.151, 1612.350, 1619.858, 1623.489, 1626.241, 1630.092 (1626.199)	Log prob: 1401.661, 1470.911, 1529.510, 1570.010, 1595.486, 1614.423, 1621.527, 1624.898, 1627.781, 1631.024 (1650.516)	KLD: 3.488, 3.416, 3.089, 2.639, 2.335, 2.074, 1.669, 1.408, 1.540, 0.931 (24.317)	Grad: 0.077, 0.058, 0.050, 0.047, 0.055, 0.053, 0.055, 0.061, 0.069, 0.055
[Epoch   3 (48.37s)]	ELBO: 1412.950, 1490.492, 1544.932, 1584.870, 1612.400, 1633.188, 1644.753, 1649.425, 1654.329, 1659.454 (1645.169)	Log prob: 1416.802, 1494.010, 1548.154, 1587.707, 1614.985, 1635.702, 1646.698, 1651.186, 1656.275, 1660.727 (1670.715)	KLD: 3.851, 3.520, 3.223, 2.838, 2.585, 2.515, 1.945, 1.762, 1.947, 1.273 (25.546)	Grad: 0.068, 0.053, 0.053, 0.049, 0.055, 0.063, 0.060, 0.064, 0.076, 0.056
[Epoch   4 (48.51s)]	ELBO: 1421.814, 1504.573, 1551.335, 1591.097, 1618.577, 1639.685, 1654.580, 1662.024, 1668.687, 1675.080 (1649.577)	Log prob: 1425.727, 1508.143, 1554.639, 1594.037, 1621.302, 1642.297, 1656.689, 1663.945, 1670.742, 1676.423 (1676.011)	KLD: 3.913, 3.569, 3.304, 2.940, 2.725, 2.613, 2.108, 1.920, 2.055, 1.343 (26.434)	Grad: 0.063, 0.049, 0.057, 0.056, 0.063, 0.070, 0.068, 0.070, 0.075, 0.056
[Epoch   5 (46.34s)]	ELBO: 1427.530, 1512.915, 1556.021, 1595.084, 1622.583, 1644.090, 1660.549, 1670.002, 1676.774, 1683.328 (1656.872)	Log prob: 1431.517, 1516.504, 1559.319, 1598.103, 1625.387, 1646.729, 1662.732, 1672.004, 1678.813, 1684.742 (1684.188)	KLD: 3.988, 3.588, 3.298, 3.019, 2.803, 2.638, 2.183, 2.002, 2.039, 1.415 (27.316)	Grad: 0.061, 0.054, 0.053, 0.056, 0.062, 0.070, 0.067, 0.068, 0.069, 0.057
[Epoch   6 (55.03s)]	ELBO: 1434.014, 1517.141, 1559.638, 1597.561, 1624.965, 1646.253, 1663.282, 1674.611, 1681.952, 1688.323 (1656.736)	Log prob: 1438.056, 1520.787, 1562.925, 1600.591, 1627.743, 1648.904, 1665.496, 1676.657, 1683.926, 1689.789 (1683.229)	KLD: 4.042, 3.646, 3.287, 3.031, 2.778, 2.651, 2.213, 2.046, 1.974, 1.466 (26.493)	Grad: 0.066, 0.057, 0.052, 0.058, 0.060, 0.073, 0.069, 0.071, 0.068, 0.059
[Epoch   7 (49.39s)]	ELBO: 1441.050, 1520.896, 1562.605, 1599.741, 1627.500, 1648.424, 1664.861, 1676.899, 1685.066, 1691.515 (1658.929)	Log prob: 1445.117, 1524.586, 1565.828, 1602.770, 1630.250, 1651.080, 1667.109, 1679.013, 1686.992, 1693.005 (1684.524)	KLD: 4.066, 3.690, 3.223, 3.031, 2.751, 2.657, 2.249, 2.115, 1.926, 1.491 (25.595)	Grad: 0.066, 0.060, 0.050, 0.055, 0.057, 0.069, 0.071, 0.072, 0.069, 0.061
[Epoch   8 (51.86s)]	ELBO: 1448.255, 1524.756, 1564.688, 1600.879, 1628.470, 1650.206, 1666.324, 1678.914, 1688.014, 1694.324 (1659.762)	Log prob: 1452.314, 1528.413, 1567.827, 1603.851, 1631.203, 1652.856, 1668.587, 1681.045, 1689.943, 1695.835 (1686.998)	KLD: 4.059, 3.657, 3.139, 2.973, 2.733, 2.649, 2.261, 2.131, 1.929, 1.512 (27.236)	Grad: 0.068, 0.061, 0.047, 0.053, 0.055, 0.066, 0.068, 0.068, 0.065, 0.060
[Epoch   9 (59.27s)]	ELBO: 1455.051, 1528.711, 1567.807, 1603.968, 1630.453, 1652.504, 1667.918, 1680.272, 1690.229, 1696.573 (1662.379)	Log prob: 1459.147, 1532.335, 1570.866, 1606.870, 1633.186, 1655.137, 1670.185, 1682.425, 1692.148, 1698.076 (1689.147)	KLD: 4.096, 3.624, 3.059, 2.902, 2.735, 2.632, 2.266, 2.153, 1.920, 1.501 (26.768)	Grad: 0.071, 0.060, 0.049, 0.052, 0.056, 0.066, 0.070, 0.069, 0.066, 0.060
[Epoch  10 (49.78s)]	ELBO: 1459.720, 1531.155, 1570.324, 1606.514, 1631.785, 1653.978, 1669.307, 1681.363, 1692.120, 1698.277 (1662.370)	Log prob: 1463.819, 1534.741, 1573.320, 1609.336, 1634.516, 1656.587, 1671.551, 1683.550, 1694.022, 1699.790 (1687.838)	KLD: 4.100, 3.587, 2.995, 2.822, 2.730, 2.610, 2.245, 2.187, 1.904, 1.513 (25.469)	Grad: 0.075, 0.059, 0.048, 0.051, 0.056, 0.064, 0.068, 0.069, 0.065, 0.060
[Epoch  11 (49.65s)]	ELBO: 1463.564, 1534.309, 1573.774, 1608.698, 1632.965, 1655.061, 1670.822, 1683.035, 1693.882, 1700.173 (1668.547)	Log prob: 1467.742, 1537.855, 1576.761, 1611.492, 1635.695, 1657.705, 1673.098, 1685.239, 1695.808, 1701.694 (1695.488)	KLD: 4.176, 3.546, 2.986, 2.794, 2.730, 2.644, 2.275, 2.203, 1.927, 1.521 (26.941)	Grad: 0.078, 0.057, 0.049, 0.050, 0.058, 0.067, 0.068, 0.069, 0.064, 0.058
[Epoch  12 (47.27s)]	ELBO: 1466.269, 1536.862, 1577.141, 1611.075, 1634.469, 1656.350, 1671.988, 1683.936, 1694.834, 1701.311 (1666.679)	Log prob: 1470.508, 1540.412, 1580.159, 1613.825, 1637.216, 1659.000, 1674.249, 1686.132, 1696.750, 1702.840 (1694.275)	KLD: 4.239, 3.551, 3.017, 2.751, 2.747, 2.650, 2.260, 2.196, 1.915, 1.528 (27.596)	Grad: 0.081, 0.057, 0.051, 0.050, 0.060, 0.068, 0.070, 0.070, 0.066, 0.060
[Epoch  13 (55.32s)]	ELBO: 1468.481, 1538.582, 1579.098, 1612.389, 1635.450, 1657.105, 1673.252, 1685.322, 1696.156, 1702.750 (1657.171)	Log prob: 1472.770, 1542.119, 1582.094, 1615.116, 1638.208, 1659.779, 1675.512, 1687.533, 1698.069, 1704.304 (1683.311)	KLD: 4.288, 3.538, 2.996, 2.727, 2.757, 2.673, 2.261, 2.212, 1.913, 1.553 (26.140)	Grad: 0.082, 0.059, 0.052, 0.052, 0.060, 0.068, 0.070, 0.070, 0.065, 0.061
[Epoch  14 (51.77s)]	ELBO: 1470.756, 1540.082, 1581.330, 1614.593, 1637.507, 1659.170, 1675.369, 1687.379, 1697.717, 1704.383 (1664.912)	Log prob: 1475.081, 1543.610, 1584.342, 1617.289, 1640.280, 1661.850, 1677.623, 1689.563, 1699.622, 1705.939 (1690.573)	KLD: 4.326, 3.527, 3.011, 2.697, 2.773, 2.680, 2.253, 2.183, 1.905, 1.557 (25.661)	Grad: 0.086, 0.059, 0.052, 0.051, 0.060, 0.067, 0.069, 0.070, 0.065, 0.061
[Epoch  15 (54.25s)]	ELBO: 1472.896, 1541.309, 1582.670, 1616.101, 1638.516, 1659.927, 1676.032, 1687.994, 1698.535, 1705.382 (1658.280)	Log prob: 1477.289, 1544.840, 1585.675, 1618.791, 1641.295, 1662.613, 1678.267, 1690.163, 1700.421, 1706.960 (1684.230)	KLD: 4.393, 3.530, 3.004, 2.690, 2.780, 2.687, 2.235, 2.169, 1.885, 1.579 (25.950)	Grad: 0.088, 0.060, 0.052, 0.051, 0.062, 0.067, 0.070, 0.070, 0.066, 0.062
[Epoch  16 (53.95s)]	ELBO: 1474.756, 1543.331, 1584.480, 1617.659, 1639.603, 1660.411, 1676.591, 1688.469, 1698.945, 1706.027 (1669.964)	Log prob: 1479.210, 1546.845, 1587.475, 1620.334, 1642.372, 1663.117, 1678.811, 1690.650, 1700.855, 1707.621 (1697.116)	KLD: 4.454, 3.514, 2.995, 2.674, 2.771, 2.706, 2.220, 2.181, 1.909, 1.592 (27.153)	Grad: 0.091, 0.058, 0.052, 0.050, 0.061, 0.067, 0.070, 0.070, 0.066, 0.062
[Epoch  17 (59.68s)]	ELBO: 1475.198, 1543.996, 1585.798, 1618.501, 1640.041, 1660.738, 1676.960, 1688.778, 1699.208, 1706.334 (1671.309)	Log prob: 1479.706, 1547.522, 1588.779, 1621.158, 1642.833, 1663.445, 1679.188, 1690.939, 1701.076, 1707.912 (1698.233)	KLD: 4.508, 3.526, 2.981, 2.658, 2.793, 2.706, 2.227, 2.160, 1.868, 1.578 (26.924)	Grad: 0.100, 0.060, 0.054, 0.053, 0.063, 0.070, 0.072, 0.072, 0.067, 0.063
[Epoch  18 (54.59s)]	ELBO: 1477.585, 1545.497, 1587.425, 1620.422, 1641.741, 1662.278, 1678.185, 1690.305, 1700.272, 1707.371 (1673.795)	Log prob: 1482.157, 1549.047, 1590.395, 1623.063, 1644.562, 1664.961, 1680.432, 1692.483, 1702.124, 1708.958 (1700.739)	KLD: 4.572, 3.550, 2.969, 2.641, 2.821, 2.684, 2.246, 2.178, 1.851, 1.587 (26.943)	Grad: 0.098, 0.060, 0.053, 0.050, 0.060, 0.066, 0.070, 0.069, 0.066, 0.062
[Epoch  19 (58.47s)]	ELBO: 1479.348, 1546.274, 1588.777, 1621.594, 1642.916, 1663.014, 1678.501, 1690.442, 1700.381, 1707.371 (1674.847)	Log prob: 1483.979, 1549.822, 1591.744, 1624.208, 1645.709, 1665.686, 1680.716, 1692.607, 1702.208, 1708.927 (1702.337)	KLD: 4.632, 3.549, 2.967, 2.613, 2.793, 2.670, 2.217, 2.165, 1.825, 1.556 (27.491)	Grad: 0.104, 0.061, 0.053, 0.051, 0.061, 0.066, 0.069, 0.072, 0.066, 0.064
[Epoch  20 (60.77s)]	ELBO: 1479.181, 1545.693, 1588.043, 1620.613, 1642.443, 1662.118, 1677.361, 1689.208, 1699.393, 1706.532 (1662.288)	Log prob: 1483.887, 1549.251, 1590.995, 1623.214, 1645.243, 1664.759, 1679.575, 1691.367, 1701.188, 1708.082 (1689.089)	KLD: 4.706, 3.558, 2.951, 2.602, 2.800, 2.641, 2.212, 2.160, 1.793, 1.550 (26.801)	Grad: 0.111, 0.061, 0.053, 0.052, 0.059, 0.067, 0.071, 0.073, 0.067, 0.065
[Epoch  21 (53.53s)]	ELBO: 1478.747, 1544.759, 1587.858, 1619.937, 1641.371, 1661.252, 1676.770, 1689.251, 1699.010, 1706.337 (1658.677)	Log prob: 1483.460, 1548.349, 1590.819, 1622.513, 1644.167, 1663.866, 1678.998, 1691.432, 1700.812, 1707.889 (1683.967)	KLD: 4.713, 3.591, 2.960, 2.575, 2.795, 2.612, 2.229, 2.179, 1.801, 1.553 (25.290)	Grad: 0.117, 0.062, 0.054, 0.052, 0.061, 0.067, 0.071, 0.071, 0.066, 0.064
[Epoch  22 (53.02s)]	ELBO: 1478.908, 1544.035, 1586.634, 1619.428, 1642.189, 1661.523, 1676.707, 1688.476, 1698.449, 1705.811 (1662.935)	Log prob: 1483.677, 1547.603, 1589.589, 1622.002, 1644.986, 1664.115, 1678.929, 1690.639, 1700.217, 1707.354 (1690.083)	KLD: 4.770, 3.569, 2.953, 2.574, 2.797, 2.591, 2.221, 2.164, 1.769, 1.543 (27.148)	Grad: 0.128, 0.060, 0.055, 0.052, 0.060, 0.067, 0.069, 0.071, 0.066, 0.065
[Epoch  23 (58.54s)]	ELBO: 1481.559, 1546.567, 1588.993, 1621.164, 1643.068, 1662.177, 1677.140, 1689.344, 1699.442, 1706.881 (1668.407)	Log prob: 1486.396, 1550.155, 1591.942, 1623.707, 1645.882, 1664.740, 1679.377, 1691.516, 1701.202, 1708.441 (1695.433)	KLD: 4.835, 3.588, 2.949, 2.542, 2.812, 2.562, 2.238, 2.171, 1.759, 1.559 (27.027)	Grad: 0.128, 0.060, 0.054, 0.053, 0.062, 0.067, 0.072, 0.074, 0.068, 0.065
[Epoch  24 (53.89s)]	ELBO: 1482.652, 1548.001, 1590.672, 1622.834, 1644.363, 1663.253, 1678.285, 1690.653, 1700.445, 1707.628 (1668.058)	Log prob: 1487.488, 1551.591, 1593.625, 1625.372, 1647.151, 1665.803, 1680.506, 1692.837, 1702.170, 1709.172 (1696.026)	KLD: 4.835, 3.590, 2.953, 2.539, 2.789, 2.552, 2.221, 2.185, 1.727, 1.544 (27.968)	Grad: 0.133, 0.061, 0.055, 0.052, 0.061, 0.066, 0.070, 0.071, 0.066, 0.065
[Epoch  25 (57.40s)]	ELBO: 1483.451, 1549.357, 1591.357, 1623.852, 1645.378, 1663.582, 1678.573, 1690.968, 1700.966, 1708.101 (1669.584)	Log prob: 1488.347, 1552.975, 1594.330, 1626.371, 1648.175, 1666.121, 1680.824, 1693.135, 1702.682, 1709.659 (1696.126)	KLD: 4.894, 3.617, 2.973, 2.520, 2.797, 2.539, 2.252, 2.167, 1.716, 1.558 (26.542)	Grad: 0.140, 0.060, 0.056, 0.054, 0.061, 0.069, 0.072, 0.076, 0.068, 0.067
[Epoch  26 (56.72s)]	ELBO: 1485.431, 1551.018, 1592.935, 1624.871, 1645.648, 1663.166, 1678.502, 1690.985, 1701.127, 1708.195 (1668.154)	Log prob: 1490.349, 1554.644, 1595.877, 1627.380, 1648.416, 1665.706, 1680.758, 1693.164, 1702.860, 1709.714 (1694.726)	KLD: 4.918, 3.626, 2.943, 2.508, 2.766, 2.540, 2.255, 2.178, 1.732, 1.518 (26.572)	Grad: 0.134, 0.061, 0.056, 0.054, 0.062, 0.069, 0.072, 0.074, 0.068, 0.067
[Epoch  27 (58.14s)]	ELBO: 1486.275, 1551.418, 1593.537, 1625.961, 1646.134, 1663.453, 1678.388, 1691.036, 1701.001, 1707.859 (1670.966)	Log prob: 1491.243, 1555.096, 1596.503, 1628.464, 1648.908, 1665.989, 1680.616, 1693.212, 1702.686, 1709.383 (1697.974)	KLD: 4.968, 3.677, 2.967, 2.504, 2.774, 2.537, 2.228, 2.177, 1.685, 1.524 (27.008)	Grad: 0.136, 0.064, 0.057, 0.053, 0.061, 0.067, 0.072, 0.074, 0.068, 0.068
[Epoch  28 (51.18s)]	ELBO: 1485.658, 1550.009, 1591.957, 1624.376, 1644.389, 1661.593, 1677.011, 1690.329, 1700.108, 1706.822 (1663.204)	Log prob: 1490.641, 1553.683, 1594.971, 1626.870, 1647.126, 1664.123, 1679.266, 1692.495, 1701.800, 1708.327 (1690.709)	KLD: 4.982, 3.675, 3.014, 2.494, 2.738, 2.532, 2.255, 2.166, 1.692, 1.505 (27.506)	Grad: 0.136, 0.066, 0.059, 0.055, 0.061, 0.067, 0.069, 0.071, 0.067, 0.065
No improvement after 10 epochs...
Best epoch: 19	Training time: 1485.20s	Best ELBO: 1708.195 (1674.847)	Best log prob: 1709.714 (1702.337)
Avg. mu: 0.620, 0.045, 0.466, 0.142, 0.300, 0.337, -0.231, -0.296, -0.006, -0.213
Avg. var: 0.000, 0.001, 0.002, 0.004, 0.002, 0.002, 0.007, 0.006, 0.015, 0.024
Max. mu: 4.741, 2.323, 3.230, 1.962, 1.698, 1.617, 1.935, 2.069, 2.361, 1.760
Max. var: 0.061, 0.007, 0.041, 0.021, 0.015, 0.012, 0.044, 0.035, 0.112, 0.160
Min. mu: -0.315, -1.876, -2.966, -2.696, -0.851, -1.300, -2.219, -1.870, -2.183, -1.934
Min. var: 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.001, 0.001, 0.001, 0.003
Cov. mu:
[[0.693 0.135 -0.066 0.116 0.016 -0.018 0.022 0.009 -0.012 0.019]
 [0.135 0.408 0.039 0.043 0.013 0.003 0.010 -0.022 0.020 -0.024]
 [-0.066 0.039 0.415 -0.020 -0.010 -0.008 -0.004 -0.011 0.013 -0.070]
 [0.116 0.043 -0.020 0.389 -0.001 0.003 0.024 0.004 -0.028 -0.014]
 [0.016 0.013 -0.010 -0.001 0.101 -0.011 0.015 0.009 -0.004 0.026]
 [-0.018 0.003 -0.008 0.003 -0.011 0.109 0.011 -0.002 0.001 0.007]
 [0.022 0.010 -0.004 0.024 0.015 0.011 0.242 0.016 -0.017 0.006]
 [0.009 -0.022 -0.011 0.004 0.009 -0.002 0.016 0.170 -0.013 0.015]
 [-0.012 0.020 0.013 -0.028 -0.004 0.001 -0.017 -0.013 0.277 -0.007]
 [0.019 -0.024 -0.070 -0.014 0.026 0.007 0.006 0.015 -0.007 0.246]]
Encoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Encoder                                  --
├─Linear: 1-1                            76,930
├─Linear: 1-2                            4,851
=================================================================
Total params: 81,781
Trainable params: 81,781
Non-trainable params: 0
=================================================================
Encoder to Latents 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 4
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 5
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 6
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 7
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 8
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Encoder to Latents 9
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            50
├─Linear: 1-2                            50
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
=================================================================
Latents to Decoder 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 4
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 5
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 6
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 7
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 8
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Latents to Decoder 9
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            98
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
=================================================================
Decoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Decoder                                  --
├─Linear: 1-1                            4,900
├─Linear: 1-2                            77,616
=================================================================
Total params: 82,516
Trainable params: 82,516
Non-trainable params: 0
=================================================================
[Epoch  28 (33.09s)]	ELBO: 1485.333, 1549.569, 1591.881, 1624.578, 1644.565, 1661.688, 1676.787, 1690.403, 1700.282, 1707.243 (1669.342)	Log prob: 1490.296, 1553.256, 1594.914, 1627.079, 1647.333, 1664.228, 1679.035, 1692.555, 1701.974, 1708.766 (1696.108)	KLD: 4.963, 3.685, 3.031, 2.501, 2.767, 2.540, 2.249, 2.154, 1.692, 1.521 (26.767)	Grad: 0.133, 0.066, 0.059, 0.056, 0.063, 0.070, 0.073, 0.075, 0.069, 0.067
[Epoch  29 (34.78s)]	ELBO: 1487.871, 1553.038, 1595.526, 1627.712, 1648.226, 1665.074, 1679.579, 1691.904, 1701.744, 1708.392 (1668.960)	Log prob: 1492.911, 1556.742, 1598.552, 1630.200, 1650.976, 1667.640, 1681.836, 1694.013, 1703.431, 1709.896 (1696.161)	KLD: 5.039, 3.706, 3.025, 2.487, 2.751, 2.566, 2.258, 2.110, 1.688, 1.503 (27.200)	Grad: 0.148, 0.065, 0.060, 0.055, 0.062, 0.068, 0.070, 0.072, 0.068, 0.067
[Epoch  30 (34.94s)]	ELBO: 1489.416, 1553.893, 1596.339, 1628.896, 1649.524, 1665.852, 1680.538, 1692.772, 1702.675, 1709.448 (1669.920)	Log prob: 1494.468, 1557.593, 1599.371, 1631.400, 1652.224, 1668.408, 1682.771, 1694.891, 1704.373, 1710.954 (1696.335)	KLD: 5.053, 3.701, 3.033, 2.503, 2.701, 2.555, 2.234, 2.120, 1.698, 1.505 (26.416)	Grad: 0.149, 0.067, 0.059, 0.054, 0.060, 0.068, 0.071, 0.072, 0.068, 0.066
[Epoch  31 (30.20s)]	ELBO: 1489.936, 1553.949, 1595.844, 1627.369, 1648.085, 1664.300, 1679.338, 1691.825, 1701.995, 1708.433 (1669.060)	Log prob: 1495.005, 1557.656, 1598.860, 1629.862, 1650.800, 1666.851, 1681.565, 1693.925, 1703.678, 1709.931 (1696.424)	KLD: 5.069, 3.708, 3.016, 2.494, 2.715, 2.552, 2.228, 2.101, 1.681, 1.500 (27.365)	Grad: 0.144, 0.068, 0.060, 0.056, 0.062, 0.068, 0.071, 0.071, 0.067, 0.067
[Epoch  32 (33.64s)]	ELBO: 1490.406, 1553.983, 1596.464, 1628.209, 1648.881, 1664.713, 1679.587, 1691.839, 1702.200, 1708.588 (1671.444)	Log prob: 1495.493, 1557.709, 1599.544, 1630.695, 1651.586, 1667.273, 1681.836, 1693.935, 1703.878, 1710.068 (1698.394)	KLD: 5.087, 3.725, 3.080, 2.485, 2.706, 2.560, 2.249, 2.097, 1.679, 1.479 (26.950)	Grad: 0.149, 0.069, 0.061, 0.056, 0.062, 0.068, 0.073, 0.073, 0.069, 0.067
[Epoch  33 (31.66s)]	ELBO: 1490.140, 1554.232, 1596.861, 1628.112, 1648.904, 1664.331, 1679.157, 1690.822, 1701.135, 1707.408 (1663.384)	Log prob: 1495.243, 1557.972, 1599.916, 1630.599, 1651.600, 1666.898, 1681.370, 1692.895, 1702.819, 1708.893 (1690.601)	KLD: 5.102, 3.740, 3.054, 2.488, 2.695, 2.566, 2.214, 2.074, 1.684, 1.486 (27.217)	Grad: 0.153, 0.072, 0.060, 0.056, 0.061, 0.067, 0.070, 0.071, 0.068, 0.068
[Epoch  34 (35.90s)]	ELBO: 1492.485, 1555.969, 1598.338, 1629.352, 1650.063, 1665.096, 1679.742, 1691.603, 1701.746, 1707.946 (1675.086)	Log prob: 1497.631, 1559.726, 1601.405, 1631.854, 1652.761, 1667.676, 1681.947, 1693.688, 1703.398, 1709.448 (1702.536)	KLD: 5.146, 3.757, 3.068, 2.502, 2.697, 2.579, 2.204, 2.086, 1.652, 1.500 (27.450)	Grad: 0.152, 0.072, 0.060, 0.056, 0.061, 0.067, 0.072, 0.074, 0.068, 0.069
[Epoch  35 (30.90s)]	ELBO: 1493.386, 1557.124, 1599.414, 1630.720, 1651.502, 1666.485, 1680.787, 1692.622, 1702.596, 1709.037 (1667.902)	Log prob: 1498.537, 1560.870, 1602.499, 1633.238, 1654.181, 1669.066, 1682.962, 1694.695, 1704.224, 1710.552 (1694.515)	KLD: 5.151, 3.746, 3.084, 2.518, 2.679, 2.581, 2.175, 2.073, 1.627, 1.515 (26.613)	Grad: 0.156, 0.072, 0.060, 0.054, 0.061, 0.066, 0.070, 0.072, 0.066, 0.066
[Epoch  36 (38.14s)]	ELBO: 1494.672, 1558.383, 1601.377, 1632.436, 1653.286, 1667.913, 1682.230, 1693.945, 1703.804, 1709.908 (1673.493)	Log prob: 1499.837, 1562.168, 1604.472, 1634.960, 1655.966, 1670.487, 1684.402, 1696.011, 1705.431, 1711.413 (1701.653)	KLD: 5.165, 3.785, 3.096, 2.523, 2.680, 2.575, 2.171, 2.067, 1.627, 1.503 (28.160)	Grad: 0.158, 0.074, 0.060, 0.055, 0.060, 0.066, 0.070, 0.072, 0.067, 0.068
[Epoch  37 (34.42s)]	ELBO: 1495.174, 1559.208, 1601.730, 1632.920, 1653.953, 1668.282, 1682.435, 1693.721, 1703.591, 1709.818 (1668.317)	Log prob: 1500.352, 1562.963, 1604.836, 1635.449, 1656.631, 1670.819, 1684.595, 1695.774, 1705.225, 1711.311 (1694.787)	KLD: 5.178, 3.754, 3.105, 2.529, 2.679, 2.536, 2.160, 2.053, 1.634, 1.493 (26.470)	Grad: 0.164, 0.074, 0.061, 0.054, 0.060, 0.066, 0.070, 0.072, 0.067, 0.068
[Epoch  38 (33.10s)]	ELBO: 1495.660, 1560.009, 1602.467, 1632.834, 1654.029, 1668.213, 1682.490, 1693.850, 1703.407, 1709.418 (1667.106)	Log prob: 1500.858, 1563.797, 1605.563, 1635.387, 1656.690, 1670.749, 1684.676, 1695.898, 1705.019, 1710.894 (1694.552)	KLD: 5.199, 3.788, 3.094, 2.552, 2.663, 2.536, 2.185, 2.049, 1.612, 1.474 (27.446)	Grad: 0.153, 0.074, 0.060, 0.055, 0.060, 0.066, 0.070, 0.073, 0.067, 0.068
[Epoch  39 (34.04s)]	ELBO: 1496.501, 1560.145, 1602.685, 1633.495, 1654.728, 1669.168, 1683.372, 1694.656, 1704.087, 1710.214 (1670.283)	Log prob: 1501.673, 1563.956, 1605.813, 1636.057, 1657.415, 1671.673, 1685.541, 1696.713, 1705.714, 1711.689 (1697.443)	KLD: 5.172, 3.812, 3.128, 2.562, 2.688, 2.505, 2.168, 2.055, 1.627, 1.475 (27.160)	Grad: 0.151, 0.074, 0.061, 0.054, 0.059, 0.064, 0.068, 0.071, 0.066, 0.066
[Epoch  40 (34.37s)]	ELBO: 1496.511, 1560.267, 1603.259, 1633.447, 1654.740, 1668.917, 1683.049, 1694.226, 1704.182, 1710.326 (1663.041)	Log prob: 1501.725, 1564.087, 1606.380, 1636.001, 1657.442, 1671.413, 1685.223, 1696.283, 1705.788, 1711.740 (1690.634)	KLD: 5.214, 3.821, 3.122, 2.557, 2.703, 2.496, 2.173, 2.057, 1.607, 1.415 (27.593)	Grad: 0.167, 0.075, 0.062, 0.055, 0.059, 0.064, 0.068, 0.071, 0.066, 0.065
[Epoch  41 (35.84s)]	ELBO: 1497.636, 1561.409, 1604.627, 1634.965, 1656.353, 1670.372, 1684.221, 1695.354, 1704.819, 1710.960 (1670.988)	Log prob: 1502.821, 1565.223, 1607.756, 1637.520, 1659.056, 1672.851, 1686.390, 1697.412, 1706.439, 1712.394 (1697.395)	KLD: 5.185, 3.815, 3.129, 2.554, 2.703, 2.480, 2.169, 2.057, 1.620, 1.434 (26.406)	Grad: 0.165, 0.075, 0.060, 0.055, 0.059, 0.064, 0.069, 0.072, 0.066, 0.066
[Epoch  42 (32.89s)]	ELBO: 1498.629, 1562.768, 1605.766, 1636.262, 1657.794, 1672.091, 1685.955, 1697.036, 1706.485, 1712.569 (1662.958)	Log prob: 1503.849, 1566.583, 1608.913, 1638.826, 1660.474, 1674.574, 1688.149, 1699.091, 1708.093, 1713.964 (1689.917)	KLD: 5.219, 3.815, 3.148, 2.564, 2.680, 2.484, 2.194, 2.056, 1.607, 1.395 (26.959)	Grad: 0.163, 0.075, 0.061, 0.054, 0.058, 0.062, 0.067, 0.069, 0.064, 0.062
[Epoch  43 (35.57s)]	ELBO: 1498.185, 1562.572, 1605.567, 1636.008, 1657.585, 1671.965, 1685.599, 1696.345, 1705.812, 1711.725 (1671.433)	Log prob: 1503.398, 1566.388, 1608.763, 1638.601, 1660.264, 1674.435, 1687.778, 1698.400, 1707.430, 1713.093 (1698.575)	KLD: 5.212, 3.815, 3.195, 2.594, 2.679, 2.470, 2.179, 2.056, 1.619, 1.368 (27.142)	Grad: 0.172, 0.076, 0.061, 0.054, 0.059, 0.063, 0.068, 0.070, 0.066, 0.064
[Epoch  44 (38.15s)]	ELBO: 1498.937, 1563.172, 1606.089, 1636.118, 1657.946, 1672.521, 1686.811, 1697.553, 1706.551, 1712.175 (1662.639)	Log prob: 1504.167, 1566.994, 1609.302, 1638.701, 1660.637, 1674.988, 1689.008, 1699.624, 1708.123, 1713.528 (1689.647)	KLD: 5.230, 3.821, 3.216, 2.581, 2.690, 2.466, 2.196, 2.070, 1.572, 1.354 (27.008)	Grad: 0.164, 0.076, 0.063, 0.055, 0.058, 0.063, 0.067, 0.068, 0.064, 0.063
[Epoch  45 (33.29s)]	ELBO: 1496.192, 1561.899, 1605.262, 1634.307, 1656.374, 1671.065, 1685.272, 1696.000, 1705.155, 1710.975 (1673.340)	Log prob: 1501.451, 1565.751, 1608.411, 1636.892, 1659.033, 1673.524, 1687.490, 1698.062, 1706.738, 1712.319 (1700.561)	KLD: 5.259, 3.852, 3.150, 2.585, 2.659, 2.458, 2.217, 2.061, 1.583, 1.344 (27.221)	Grad: 0.159, 0.078, 0.063, 0.055, 0.057, 0.062, 0.066, 0.067, 0.064, 0.064
[Epoch  46 (33.16s)]	ELBO: 1498.183, 1564.002, 1606.947, 1635.738, 1657.792, 1672.285, 1686.049, 1696.753, 1705.854, 1711.537 (1673.220)	Log prob: 1503.454, 1567.828, 1610.134, 1638.338, 1660.421, 1674.759, 1688.248, 1698.812, 1707.460, 1712.885 (1700.115)	KLD: 5.272, 3.826, 3.186, 2.599, 2.630, 2.475, 2.199, 2.059, 1.607, 1.346 (26.895)	Grad: 0.176, 0.073, 0.062, 0.054, 0.057, 0.062, 0.065, 0.068, 0.064, 0.064
[Epoch  47 (36.02s)]	ELBO: 1500.073, 1564.786, 1607.548, 1636.652, 1658.719, 1673.189, 1687.434, 1697.996, 1706.889, 1712.561 (1672.121)	Log prob: 1505.336, 1568.588, 1610.739, 1639.275, 1661.343, 1675.657, 1689.623, 1700.054, 1708.470, 1713.901 (1699.536)	KLD: 5.264, 3.800, 3.190, 2.623, 2.623, 2.470, 2.190, 2.058, 1.581, 1.340 (27.415)	Grad: 0.183, 0.076, 0.063, 0.054, 0.057, 0.062, 0.065, 0.068, 0.064, 0.064
[Epoch  48 (35.52s)]	ELBO: 1499.885, 1565.146, 1607.664, 1635.825, 1657.884, 1672.498, 1686.819, 1697.173, 1705.862, 1711.376 (1673.736)	Log prob: 1505.167, 1568.991, 1610.812, 1638.449, 1660.515, 1674.968, 1689.015, 1699.195, 1707.448, 1712.715 (1700.736)	KLD: 5.280, 3.847, 3.149, 2.622, 2.630, 2.470, 2.196, 2.023, 1.586, 1.341 (27.000)	Grad: 0.177, 0.076, 0.064, 0.055, 0.058, 0.064, 0.066, 0.068, 0.065, 0.066
[Epoch  49 (35.67s)]	ELBO: 1500.091, 1565.298, 1608.963, 1636.957, 1658.712, 1673.311, 1687.885, 1698.543, 1707.220, 1712.710 (1666.088)	Log prob: 1505.338, 1569.159, 1612.131, 1639.587, 1661.305, 1675.792, 1690.088, 1700.548, 1708.797, 1714.014 (1693.041)	KLD: 5.246, 3.860, 3.167, 2.628, 2.594, 2.481, 2.203, 2.005, 1.576, 1.305 (26.952)	Grad: 0.179, 0.077, 0.063, 0.054, 0.057, 0.062, 0.065, 0.067, 0.064, 0.064
[Epoch  50 (33.88s)]	ELBO: 1499.120, 1565.674, 1607.798, 1635.220, 1657.153, 1671.926, 1686.188, 1696.799, 1705.944, 1711.608 (1670.582)	Log prob: 1504.401, 1569.524, 1610.908, 1637.874, 1659.754, 1674.414, 1688.397, 1698.794, 1707.527, 1712.900 (1697.382)	KLD: 5.280, 3.850, 3.110, 2.653, 2.601, 2.487, 2.210, 1.995, 1.583, 1.291 (26.800)	Grad: 0.188, 0.075, 0.063, 0.054, 0.057, 0.062, 0.065, 0.066, 0.063, 0.062
[Epoch  51 (38.89s)]	ELBO: 1499.999, 1566.560, 1609.545, 1637.067, 1658.844, 1673.519, 1687.903, 1698.651, 1707.238, 1712.448 (1675.640)	Log prob: 1505.279, 1570.398, 1612.696, 1639.724, 1661.432, 1676.016, 1690.108, 1700.621, 1708.785, 1713.744 (1701.851)	KLD: 5.278, 3.839, 3.152, 2.657, 2.588, 2.498, 2.204, 1.970, 1.548, 1.294 (26.211)	Grad: 0.188, 0.077, 0.063, 0.054, 0.057, 0.062, 0.064, 0.066, 0.062, 0.061
[Epoch  52 (35.05s)]	ELBO: 1500.850, 1567.215, 1609.673, 1637.267, 1658.624, 1673.281, 1687.863, 1698.672, 1707.420, 1712.816 (1662.573)	Log prob: 1506.130, 1571.071, 1612.799, 1639.941, 1661.214, 1675.780, 1690.076, 1700.648, 1708.970, 1714.091 (1689.268)	KLD: 5.280, 3.855, 3.126, 2.673, 2.593, 2.499, 2.214, 1.976, 1.552, 1.274 (26.695)	Grad: 0.191, 0.076, 0.063, 0.054, 0.056, 0.062, 0.065, 0.067, 0.062, 0.062
[Epoch  53 (36.02s)]	ELBO: 1499.725, 1566.264, 1609.052, 1636.615, 1657.908, 1672.259, 1687.104, 1698.107, 1706.721, 1711.498 (1667.663)	Log prob: 1505.003, 1570.130, 1612.153, 1639.320, 1660.503, 1674.751, 1689.319, 1700.058, 1708.243, 1712.755 (1694.268)	KLD: 5.279, 3.867, 3.101, 2.705, 2.595, 2.491, 2.216, 1.951, 1.521, 1.257 (26.605)	Grad: 0.203, 0.077, 0.064, 0.056, 0.058, 0.066, 0.066, 0.068, 0.064, 0.066
[Epoch  54 (34.05s)]	ELBO: 1501.715, 1568.377, 1611.619, 1639.313, 1660.525, 1674.886, 1689.242, 1700.389, 1708.875, 1713.813 (1671.866)	Log prob: 1506.989, 1572.239, 1614.788, 1642.028, 1663.113, 1677.397, 1691.453, 1702.337, 1710.393, 1715.026 (1699.650)	KLD: 5.274, 3.861, 3.166, 2.715, 2.588, 2.509, 2.212, 1.946, 1.517, 1.212 (27.784)	Grad: 0.199, 0.078, 0.063, 0.054, 0.056, 0.063, 0.064, 0.066, 0.061, 0.062
[Epoch  55 (36.83s)]	ELBO: 1499.858, 1567.447, 1609.644, 1636.986, 1658.261, 1672.996, 1687.631, 1698.743, 1707.224, 1712.600 (1669.434)	Log prob: 1505.160, 1571.326, 1612.751, 1639.722, 1660.849, 1675.515, 1689.849, 1700.681, 1708.729, 1713.834 (1696.152)	KLD: 5.302, 3.879, 3.108, 2.737, 2.587, 2.520, 2.219, 1.938, 1.506, 1.236 (26.719)	Grad: 0.203, 0.078, 0.065, 0.054, 0.057, 0.062, 0.063, 0.065, 0.061, 0.060
[Epoch  56 (36.56s)]	ELBO: 1497.706, 1565.147, 1609.014, 1635.687, 1656.496, 1671.075, 1686.144, 1697.834, 1706.215, 1711.063 (1674.096)	Log prob: 1502.962, 1569.053, 1612.201, 1638.429, 1659.055, 1673.586, 1688.341, 1699.765, 1707.697, 1712.302 (1700.273)	KLD: 5.255, 3.907, 3.187, 2.742, 2.559, 2.511, 2.196, 1.931, 1.480, 1.239 (26.177)	Grad: 0.192, 0.082, 0.066, 0.055, 0.057, 0.066, 0.064, 0.066, 0.063, 0.064
[Epoch  57 (34.66s)]	ELBO: 1490.689, 1561.533, 1606.444, 1633.393, 1654.292, 1669.412, 1684.103, 1696.410, 1704.590, 1709.724 (1664.886)	Log prob: 1495.959, 1565.461, 1609.625, 1636.130, 1656.865, 1671.960, 1686.283, 1698.345, 1706.040, 1710.945 (1691.762)	KLD: 5.270, 3.928, 3.180, 2.738, 2.572, 2.548, 2.180, 1.935, 1.451, 1.222 (26.875)	Grad: 0.197, 0.083, 0.067, 0.056, 0.058, 0.067, 0.066, 0.068, 0.064, 0.064
[Epoch  58 (34.71s)]	ELBO: 1491.116, 1561.610, 1605.780, 1632.524, 1653.558, 1668.908, 1683.328, 1695.117, 1703.280, 1708.433 (1674.533)	Log prob: 1496.395, 1565.528, 1608.980, 1635.271, 1656.121, 1671.453, 1685.484, 1697.017, 1704.694, 1709.655 (1701.279)	KLD: 5.280, 3.918, 3.200, 2.747, 2.563, 2.544, 2.155, 1.899, 1.413, 1.222 (26.746)	Grad: 0.198, 0.084, 0.066, 0.055, 0.057, 0.066, 0.065, 0.067, 0.062, 0.062
[Epoch  59 (37.41s)]	ELBO: 1490.110, 1560.081, 1605.945, 1632.115, 1652.745, 1668.149, 1682.657, 1694.614, 1702.630, 1708.092 (1662.091)	Log prob: 1495.391, 1564.024, 1609.109, 1634.843, 1655.289, 1670.708, 1684.800, 1696.491, 1704.022, 1709.361 (1688.658)	KLD: 5.282, 3.943, 3.163, 2.729, 2.544, 2.559, 2.143, 1.878, 1.392, 1.268 (26.567)	Grad: 0.192, 0.084, 0.066, 0.055, 0.057, 0.065, 0.064, 0.066, 0.061, 0.060
[Epoch  60 (37.92s)]	ELBO: 1486.821, 1556.252, 1602.985, 1628.818, 1649.573, 1664.622, 1679.322, 1691.346, 1699.606, 1705.008 (1665.577)	Log prob: 1492.056, 1560.196, 1606.163, 1631.556, 1652.119, 1667.179, 1681.464, 1693.194, 1701.002, 1706.223 (1692.446)	KLD: 5.236, 3.945, 3.177, 2.738, 2.546, 2.558, 2.142, 1.848, 1.397, 1.214 (26.869)	Grad: 0.190, 0.087, 0.069, 0.056, 0.058, 0.069, 0.066, 0.069, 0.062, 0.062
[Epoch  61 (38.28s)]	ELBO: 1489.320, 1558.072, 1604.043, 1629.824, 1650.657, 1666.073, 1680.134, 1691.950, 1700.050, 1705.811 (1664.062)	Log prob: 1494.566, 1562.013, 1607.183, 1632.550, 1653.171, 1668.643, 1682.277, 1693.796, 1701.416, 1706.989 (1690.874)	KLD: 5.246, 3.940, 3.140, 2.726, 2.514, 2.570, 2.145, 1.845, 1.367, 1.177 (26.812)	Grad: 0.195, 0.088, 0.066, 0.054, 0.055, 0.064, 0.064, 0.065, 0.060, 0.058
[Epoch  62 (35.62s)]	ELBO: 1493.046, 1561.127, 1606.673, 1632.202, 1653.022, 1668.381, 1682.574, 1694.119, 1701.917, 1707.199 (1667.287)	Log prob: 1498.290, 1565.075, 1609.889, 1634.917, 1655.514, 1670.966, 1684.714, 1695.951, 1703.256, 1708.367 (1693.726)	KLD: 5.245, 3.947, 3.215, 2.715, 2.492, 2.585, 2.140, 1.832, 1.339, 1.167 (26.439)	Grad: 0.196, 0.086, 0.067, 0.053, 0.054, 0.064, 0.062, 0.062, 0.058, 0.057
[Epoch  63 (33.51s)]	ELBO: 1491.237, 1559.985, 1606.222, 1631.490, 1652.135, 1667.120, 1681.755, 1693.078, 1700.804, 1705.882 (1667.078)	Log prob: 1496.483, 1563.952, 1609.447, 1634.223, 1654.574, 1669.714, 1683.869, 1694.890, 1702.143, 1707.047 (1693.128)	KLD: 5.247, 3.967, 3.224, 2.732, 2.439, 2.593, 2.114, 1.812, 1.339, 1.164 (26.050)	Grad: 0.200, 0.088, 0.068, 0.055, 0.055, 0.067, 0.063, 0.064, 0.059, 0.060
[Epoch  64 (34.66s)]	ELBO: 1488.431, 1556.429, 1604.337, 1629.501, 1650.449, 1665.809, 1680.779, 1691.999, 1699.570, 1704.849 (1653.974)	Log prob: 1493.666, 1560.407, 1607.593, 1632.232, 1652.884, 1668.422, 1682.903, 1693.800, 1700.884, 1706.033 (1680.848)	KLD: 5.234, 3.978, 3.255, 2.730, 2.435, 2.614, 2.124, 1.803, 1.315, 1.184 (26.874)	Grad: 0.188, 0.090, 0.069, 0.053, 0.053, 0.063, 0.061, 0.061, 0.057, 0.056
[Epoch  65 (33.04s)]	ELBO: 1493.177, 1562.158, 1608.582, 1633.234, 1653.800, 1668.902, 1683.345, 1694.006, 1701.592, 1706.476 (1653.210)	Log prob: 1498.391, 1566.124, 1611.803, 1635.939, 1656.179, 1671.533, 1685.450, 1695.795, 1702.917, 1707.603 (1679.049)	KLD: 5.213, 3.965, 3.223, 2.705, 2.378, 2.631, 2.105, 1.790, 1.325, 1.127 (25.839)	Grad: 0.194, 0.086, 0.069, 0.052, 0.052, 0.064, 0.060, 0.062, 0.058, 0.057
[Epoch  66 (38.77s)]	ELBO: 1491.246, 1559.642, 1606.187, 1631.205, 1651.529, 1666.723, 1681.641, 1692.186, 1699.905, 1704.681 (1654.210)	Log prob: 1496.461, 1563.584, 1609.355, 1633.916, 1653.883, 1669.346, 1683.751, 1693.955, 1701.248, 1705.806 (1680.458)	KLD: 5.216, 3.942, 3.168, 2.710, 2.353, 2.625, 2.109, 1.770, 1.343, 1.125 (26.248)	Grad: 0.195, 0.088, 0.068, 0.053, 0.052, 0.063, 0.059, 0.060, 0.057, 0.057
[Epoch  67 (34.66s)]	ELBO: 1491.540, 1559.009, 1606.768, 1631.785, 1652.303, 1667.673, 1682.112, 1692.466, 1700.216, 1705.209 (1670.752)	Log prob: 1496.777, 1562.950, 1609.977, 1634.498, 1654.611, 1670.312, 1684.211, 1694.231, 1701.557, 1706.366 (1697.150)	KLD: 5.238, 3.940, 3.208, 2.711, 2.307, 2.641, 2.099, 1.764, 1.339, 1.158 (26.398)	Grad: 0.201, 0.084, 0.068, 0.052, 0.051, 0.062, 0.059, 0.061, 0.057, 0.055
[Epoch  68 (34.52s)]	ELBO: 1493.075, 1561.014, 1608.448, 1633.392, 1653.805, 1669.616, 1684.028, 1694.147, 1701.778, 1706.668 (1672.462)	Log prob: 1498.323, 1564.947, 1611.661, 1636.103, 1656.107, 1672.273, 1686.117, 1695.906, 1703.106, 1707.768 (1698.450)	KLD: 5.247, 3.933, 3.213, 2.711, 2.301, 2.656, 2.090, 1.759, 1.327, 1.102 (25.987)	Grad: 0.202, 0.083, 0.067, 0.051, 0.050, 0.060, 0.057, 0.059, 0.054, 0.052
[Epoch  69 (34.20s)]	ELBO: 1494.413, 1561.824, 1610.060, 1635.121, 1655.525, 1671.371, 1685.894, 1696.328, 1703.959, 1708.681 (1671.728)	Log prob: 1499.641, 1565.766, 1613.241, 1637.812, 1657.816, 1674.017, 1687.993, 1698.063, 1705.291, 1709.774 (1697.285)	KLD: 5.229, 3.942, 3.180, 2.690, 2.292, 2.646, 2.100, 1.735, 1.333, 1.092 (25.557)	Grad: 0.197, 0.085, 0.066, 0.051, 0.049, 0.059, 0.056, 0.057, 0.053, 0.051
[Epoch  70 (34.19s)]	ELBO: 1493.698, 1561.172, 1609.761, 1634.488, 1654.389, 1670.230, 1684.824, 1695.032, 1702.979, 1707.604 (1675.669)	Log prob: 1498.926, 1565.130, 1612.974, 1637.176, 1656.616, 1672.869, 1686.922, 1696.775, 1704.309, 1708.713 (1702.040)	KLD: 5.228, 3.958, 3.214, 2.688, 2.228, 2.639, 2.098, 1.742, 1.329, 1.109 (26.371)	Grad: 0.197, 0.086, 0.067, 0.051, 0.049, 0.061, 0.057, 0.058, 0.054, 0.052
[Epoch  71 (35.17s)]	ELBO: 1495.403, 1562.753, 1610.496, 1634.745, 1655.033, 1670.620, 1685.295, 1695.739, 1703.128, 1707.956 (1672.155)	Log prob: 1500.661, 1566.714, 1613.698, 1637.433, 1657.300, 1673.250, 1687.381, 1697.468, 1704.435, 1709.078 (1697.331)	KLD: 5.258, 3.960, 3.202, 2.689, 2.267, 2.631, 2.086, 1.730, 1.308, 1.123 (25.176)	Grad: 0.211, 0.084, 0.065, 0.050, 0.048, 0.057, 0.054, 0.056, 0.053, 0.051
[Epoch  72 (33.39s)]	ELBO: 1496.375, 1563.258, 1611.872, 1636.620, 1657.138, 1673.140, 1687.588, 1698.053, 1705.227, 1710.305 (1671.794)	Log prob: 1501.623, 1567.201, 1615.149, 1639.311, 1659.410, 1675.775, 1689.669, 1699.756, 1706.519, 1711.433 (1698.592)	KLD: 5.249, 3.944, 3.277, 2.691, 2.272, 2.635, 2.081, 1.703, 1.291, 1.128 (26.798)	Grad: 0.205, 0.082, 0.065, 0.050, 0.048, 0.056, 0.053, 0.055, 0.050, 0.049
[Epoch  73 (35.78s)]	ELBO: 1496.568, 1563.422, 1612.508, 1636.682, 1656.940, 1672.662, 1687.079, 1697.400, 1704.639, 1709.382 (1668.857)	Log prob: 1501.813, 1567.397, 1615.780, 1639.367, 1659.189, 1675.272, 1689.138, 1699.095, 1705.931, 1710.508 (1695.122)	KLD: 5.245, 3.973, 3.272, 2.684, 2.249, 2.611, 2.059, 1.694, 1.292, 1.125 (26.265)	Grad: 0.205, 0.088, 0.066, 0.050, 0.047, 0.056, 0.054, 0.056, 0.051, 0.050
[Epoch  74 (36.22s)]	ELBO: 1495.099, 1560.452, 1611.351, 1635.589, 1656.132, 1672.408, 1687.327, 1698.081, 1705.228, 1709.893 (1675.530)	Log prob: 1500.279, 1564.442, 1614.700, 1638.261, 1658.404, 1675.010, 1689.391, 1699.765, 1706.474, 1711.009 (1701.481)	KLD: 5.179, 3.991, 3.350, 2.672, 2.272, 2.603, 2.064, 1.683, 1.246, 1.116 (25.951)	Grad: 0.203, 0.084, 0.066, 0.049, 0.046, 0.055, 0.052, 0.054, 0.050, 0.049
[Epoch  75 (32.80s)]	ELBO: 1495.507, 1558.954, 1609.004, 1633.171, 1653.556, 1669.932, 1684.957, 1695.850, 1702.995, 1707.459 (1670.780)	Log prob: 1500.708, 1562.930, 1612.306, 1635.824, 1655.810, 1672.514, 1686.989, 1697.531, 1704.255, 1708.548 (1696.924)	KLD: 5.200, 3.974, 3.301, 2.652, 2.256, 2.581, 2.032, 1.680, 1.260, 1.089 (26.145)	Grad: 0.205, 0.087, 0.066, 0.049, 0.046, 0.055, 0.052, 0.054, 0.050, 0.050
[Epoch  76 (40.40s)]	ELBO: 1494.781, 1556.834, 1607.695, 1632.155, 1652.498, 1669.375, 1684.133, 1694.950, 1702.385, 1707.044 (1676.793)	Log prob: 1499.963, 1560.796, 1611.071, 1634.767, 1654.755, 1671.954, 1686.146, 1696.616, 1703.647, 1708.152 (1702.859)	KLD: 5.180, 3.962, 3.376, 2.612, 2.257, 2.578, 2.013, 1.666, 1.262, 1.108 (26.066)	Grad: 0.212, 0.087, 0.069, 0.049, 0.047, 0.055, 0.053, 0.055, 0.051, 0.048
[Epoch  77 (36.12s)]	ELBO: 1496.039, 1557.990, 1608.698, 1633.238, 1653.757, 1670.601, 1685.261, 1696.075, 1703.426, 1708.052 (1670.181)	Log prob: 1501.247, 1561.967, 1612.036, 1635.815, 1655.988, 1673.175, 1687.255, 1697.703, 1704.660, 1709.143 (1695.965)	KLD: 5.207, 3.976, 3.338, 2.578, 2.231, 2.573, 1.995, 1.627, 1.234, 1.091 (25.785)	Grad: 0.207, 0.088, 0.067, 0.048, 0.045, 0.053, 0.051, 0.054, 0.049, 0.047
[Epoch  78 (36.01s)]	ELBO: 1495.659, 1557.066, 1607.974, 1632.955, 1653.025, 1669.867, 1684.410, 1695.246, 1702.628, 1707.214 (1675.183)	Log prob: 1500.850, 1561.046, 1611.329, 1635.511, 1655.255, 1672.407, 1686.396, 1696.859, 1703.861, 1708.315 (1701.201)	KLD: 5.192, 3.979, 3.355, 2.555, 2.231, 2.541, 1.986, 1.613, 1.232, 1.100 (26.019)	Grad: 0.207, 0.088, 0.067, 0.047, 0.045, 0.053, 0.051, 0.053, 0.049, 0.047
[Epoch  79 (37.57s)]	ELBO: 1498.224, 1560.149, 1610.064, 1634.795, 1655.183, 1671.899, 1686.262, 1696.976, 1703.966, 1708.311 (1676.428)	Log prob: 1503.418, 1564.097, 1613.424, 1637.316, 1657.420, 1674.455, 1688.220, 1698.604, 1705.173, 1709.495 (1701.919)	KLD: 5.194, 3.949, 3.361, 2.521, 2.237, 2.556, 1.957, 1.630, 1.207, 1.183 (25.491)	Grad: 0.217, 0.085, 0.068, 0.047, 0.044, 0.051, 0.049, 0.051, 0.047, 0.046
[Epoch  80 (35.73s)]	ELBO: 1499.650, 1561.947, 1611.394, 1635.673, 1655.704, 1672.219, 1686.673, 1697.412, 1704.484, 1708.917 (1670.240)	Log prob: 1504.914, 1565.910, 1614.746, 1638.191, 1657.926, 1674.745, 1688.623, 1699.029, 1705.707, 1709.988 (1696.012)	KLD: 5.263, 3.962, 3.352, 2.519, 2.222, 2.526, 1.949, 1.619, 1.223, 1.070 (25.772)	Grad: 0.216, 0.084, 0.069, 0.046, 0.045, 0.052, 0.049, 0.051, 0.047, 0.046
[Epoch  81 (37.14s)]	ELBO: 1498.564, 1561.006, 1611.422, 1635.159, 1655.612, 1672.010, 1686.410, 1697.325, 1704.546, 1709.016 (1650.406)	Log prob: 1503.786, 1564.978, 1614.795, 1637.645, 1657.821, 1674.522, 1688.361, 1698.944, 1705.763, 1710.093 (1676.350)	KLD: 5.222, 3.971, 3.374, 2.485, 2.210, 2.513, 1.951, 1.619, 1.217, 1.079 (25.944)	Grad: 0.210, 0.084, 0.069, 0.046, 0.045, 0.052, 0.049, 0.051, 0.047, 0.046
[Epoch  82 (33.19s)]	ELBO: 1501.833, 1563.860, 1611.966, 1635.954, 1656.227, 1672.788, 1687.340, 1697.845, 1705.049, 1709.575 (1674.543)	Log prob: 1507.047, 1567.800, 1615.301, 1638.426, 1658.424, 1675.310, 1689.285, 1699.438, 1706.285, 1710.630 (1699.311)	KLD: 5.214, 3.942, 3.335, 2.472, 2.197, 2.523, 1.943, 1.593, 1.236, 1.057 (24.768)	Grad: 0.215, 0.084, 0.069, 0.045, 0.044, 0.051, 0.047, 0.050, 0.045, 0.044
[Epoch  83 (33.31s)]	ELBO: 1501.740, 1563.838, 1611.688, 1635.521, 1655.851, 1672.441, 1687.236, 1697.673, 1705.019, 1709.502 (1675.556)	Log prob: 1506.956, 1567.786, 1615.006, 1637.996, 1658.060, 1674.959, 1689.158, 1699.264, 1706.232, 1710.617 (1701.206)	KLD: 5.216, 3.948, 3.318, 2.475, 2.209, 2.518, 1.923, 1.591, 1.213, 1.115 (25.650)	Grad: 0.214, 0.084, 0.070, 0.045, 0.043, 0.051, 0.048, 0.050, 0.045, 0.045
[Epoch  84 (34.53s)]	ELBO: 1503.113, 1565.123, 1612.422, 1636.256, 1656.290, 1673.043, 1687.387, 1697.997, 1705.192, 1709.664 (1668.945)	Log prob: 1508.352, 1569.069, 1615.763, 1638.731, 1658.476, 1675.553, 1689.294, 1699.570, 1706.392, 1710.726 (1693.700)	KLD: 5.240, 3.947, 3.341, 2.475, 2.187, 2.510, 1.905, 1.574, 1.201, 1.061 (24.755)	Grad: 0.220, 0.085, 0.070, 0.046, 0.044, 0.051, 0.047, 0.049, 0.044, 0.044
[Epoch  85 (37.02s)]	ELBO: 1503.553, 1565.013, 1611.555, 1635.948, 1655.773, 1672.514, 1687.035, 1697.703, 1705.001, 1709.378 (1674.660)	Log prob: 1508.800, 1568.937, 1614.887, 1638.409, 1657.954, 1675.021, 1688.934, 1699.311, 1706.206, 1710.452 (1699.752)	KLD: 5.248, 3.924, 3.333, 2.461, 2.182, 2.507, 1.898, 1.609, 1.205, 1.074 (25.092)	Grad: 0.222, 0.084, 0.071, 0.045, 0.044, 0.051, 0.047, 0.049, 0.044, 0.044
[Epoch  86 (36.87s)]	ELBO: 1504.632, 1565.920, 1611.453, 1636.085, 1655.943, 1672.331, 1686.904, 1697.610, 1704.746, 1709.166 (1670.518)	Log prob: 1509.906, 1569.801, 1614.809, 1638.560, 1658.141, 1674.838, 1688.803, 1699.182, 1705.959, 1710.243 (1695.600)	KLD: 5.275, 3.881, 3.356, 2.474, 2.198, 2.506, 1.899, 1.572, 1.214, 1.076 (25.083)	Grad: 0.222, 0.084, 0.071, 0.045, 0.044, 0.050, 0.046, 0.048, 0.043, 0.044
[Epoch  87 (34.32s)]	ELBO: 1504.462, 1566.838, 1611.456, 1635.954, 1655.859, 1672.169, 1686.711, 1697.283, 1704.514, 1709.025 (1661.975)	Log prob: 1509.750, 1570.729, 1614.753, 1638.437, 1658.062, 1674.663, 1688.607, 1698.864, 1705.713, 1710.103 (1687.586)	KLD: 5.289, 3.890, 3.297, 2.484, 2.204, 2.493, 1.895, 1.583, 1.198, 1.077 (25.611)	Grad: 0.226, 0.083, 0.070, 0.046, 0.044, 0.050, 0.046, 0.047, 0.043, 0.044
[Epoch  88 (50.21s)]	ELBO: 1504.999, 1567.613, 1612.461, 1636.912, 1656.860, 1673.129, 1687.357, 1697.700, 1704.885, 1709.370 (1664.237)	Log prob: 1510.284, 1571.508, 1615.766, 1639.390, 1659.060, 1675.590, 1689.226, 1699.274, 1706.103, 1710.482 (1689.140)	KLD: 5.285, 3.895, 3.303, 2.479, 2.201, 2.462, 1.868, 1.575, 1.218, 1.113 (24.904)	Grad: 0.224, 0.084, 0.070, 0.045, 0.043, 0.050, 0.046, 0.046, 0.042, 0.044
[Epoch  89 (39.32s)]	ELBO: 1506.827, 1568.402, 1614.172, 1638.883, 1658.536, 1674.676, 1688.722, 1699.185, 1706.380, 1710.849 (1673.699)	Log prob: 1512.113, 1572.312, 1617.482, 1641.366, 1660.740, 1677.119, 1690.600, 1700.753, 1707.591, 1711.925 (1698.616)	KLD: 5.286, 3.910, 3.311, 2.484, 2.206, 2.444, 1.879, 1.568, 1.211, 1.075 (24.917)	Grad: 0.220, 0.084, 0.070, 0.045, 0.043, 0.049, 0.046, 0.045, 0.042, 0.043
[Epoch  90 (38.09s)]	ELBO: 1503.556, 1565.155, 1612.810, 1637.050, 1656.886, 1673.136, 1687.735, 1698.111, 1705.398, 1709.773 (1640.335)	Log prob: 1508.769, 1569.091, 1616.123, 1639.526, 1659.083, 1675.557, 1689.608, 1699.659, 1706.615, 1710.875 (1664.783)	KLD: 5.214, 3.934, 3.313, 2.477, 2.197, 2.421, 1.872, 1.548, 1.217, 1.102 (24.448)	Grad: 0.215, 0.086, 0.069, 0.045, 0.043, 0.048, 0.046, 0.044, 0.041, 0.042
[Epoch  91 (39.68s)]	ELBO: 1502.409, 1563.960, 1612.260, 1636.218, 1656.215, 1672.530, 1687.302, 1697.894, 1705.227, 1709.570 (1673.671)	Log prob: 1507.640, 1567.936, 1615.568, 1638.685, 1658.396, 1674.952, 1689.184, 1699.450, 1706.447, 1710.670 (1699.491)	KLD: 5.231, 3.976, 3.308, 2.466, 2.180, 2.422, 1.880, 1.557, 1.220, 1.101 (25.820)	Grad: 0.217, 0.090, 0.069, 0.045, 0.043, 0.049, 0.046, 0.044, 0.042, 0.043
[Epoch  92 (40.29s)]	ELBO: 1505.292, 1566.623, 1614.166, 1638.255, 1658.093, 1674.146, 1688.294, 1698.888, 1705.969, 1710.150 (1672.351)	Log prob: 1510.552, 1570.565, 1617.492, 1640.710, 1660.275, 1676.554, 1690.159, 1700.459, 1707.188, 1711.238 (1698.193)	KLD: 5.259, 3.943, 3.327, 2.455, 2.182, 2.408, 1.865, 1.571, 1.219, 1.088 (25.842)	Grad: 0.231, 0.088, 0.070, 0.046, 0.043, 0.048, 0.046, 0.044, 0.041, 0.043
[Epoch  93 (37.91s)]	ELBO: 1508.417, 1569.042, 1614.343, 1639.056, 1658.748, 1674.749, 1688.501, 1698.909, 1705.921, 1710.395 (1676.853)	Log prob: 1513.719, 1572.969, 1617.638, 1641.520, 1660.950, 1677.137, 1690.354, 1700.468, 1707.157, 1711.496 (1702.247)	KLD: 5.302, 3.927, 3.296, 2.464, 2.200, 2.387, 1.853, 1.559, 1.235, 1.102 (25.393)	Grad: 0.231, 0.087, 0.069, 0.045, 0.043, 0.047, 0.044, 0.043, 0.041, 0.042
[Epoch  94 (32.44s)]	ELBO: 1508.076, 1569.202, 1614.227, 1639.106, 1658.658, 1674.655, 1688.704, 1698.949, 1706.589, 1710.593 (1671.896)	Log prob: 1513.369, 1573.140, 1617.528, 1641.588, 1660.864, 1677.020, 1690.551, 1700.510, 1707.818, 1711.702 (1697.864)	KLD: 5.293, 3.940, 3.301, 2.480, 2.205, 2.366, 1.846, 1.560, 1.230, 1.109 (25.969)	Grad: 0.234, 0.087, 0.069, 0.045, 0.043, 0.047, 0.044, 0.043, 0.040, 0.042
[Epoch  95 (34.72s)]	ELBO: 1507.493, 1569.031, 1613.270, 1638.264, 1657.681, 1673.755, 1687.505, 1697.624, 1704.989, 1709.421 (1677.218)	Log prob: 1512.827, 1572.937, 1616.536, 1640.706, 1659.901, 1676.114, 1689.335, 1699.153, 1706.228, 1710.534 (1701.643)	KLD: 5.335, 3.907, 3.265, 2.444, 2.221, 2.360, 1.830, 1.530, 1.239, 1.114 (24.425)	Grad: 0.236, 0.086, 0.068, 0.045, 0.043, 0.046, 0.044, 0.042, 0.040, 0.041
[Epoch  96 (36.14s)]	ELBO: 1509.596, 1570.100, 1614.313, 1639.141, 1659.127, 1674.958, 1688.637, 1698.783, 1706.152, 1710.356 (1672.109)	Log prob: 1514.934, 1574.012, 1617.567, 1641.577, 1661.357, 1677.333, 1690.427, 1700.305, 1707.392, 1711.458 (1697.145)	KLD: 5.337, 3.912, 3.252, 2.437, 2.230, 2.373, 1.789, 1.523, 1.240, 1.101 (25.036)	Grad: 0.226, 0.088, 0.068, 0.045, 0.042, 0.045, 0.043, 0.041, 0.039, 0.041
[Epoch  97 (33.43s)]	ELBO: 1509.099, 1571.280, 1615.842, 1640.492, 1660.569, 1675.834, 1689.401, 1699.298, 1706.630, 1710.929 (1670.659)	Log prob: 1514.436, 1575.220, 1619.128, 1642.933, 1662.802, 1678.196, 1691.204, 1700.812, 1707.877, 1712.040 (1695.281)	KLD: 5.338, 3.940, 3.285, 2.441, 2.233, 2.360, 1.804, 1.514, 1.246, 1.112 (24.622)	Grad: 0.226, 0.087, 0.067, 0.044, 0.042, 0.046, 0.043, 0.041, 0.039, 0.040
[Epoch  98 (33.50s)]	ELBO: 1508.838, 1570.500, 1614.797, 1639.745, 1660.119, 1675.229, 1688.911, 1698.979, 1706.564, 1710.582 (1668.817)	Log prob: 1514.215, 1574.439, 1618.126, 1642.197, 1662.350, 1677.565, 1690.751, 1700.498, 1707.809, 1711.682 (1693.998)	KLD: 5.378, 3.939, 3.329, 2.451, 2.230, 2.336, 1.840, 1.520, 1.246, 1.100 (25.181)	Grad: 0.226, 0.088, 0.067, 0.045, 0.042, 0.045, 0.042, 0.041, 0.038, 0.039
[Epoch  99 (34.80s)]	ELBO: 1510.413, 1572.231, 1617.001, 1641.961, 1662.206, 1677.505, 1691.066, 1700.919, 1708.438, 1712.388 (1674.948)	Log prob: 1515.758, 1576.170, 1620.342, 1644.402, 1664.455, 1679.817, 1692.902, 1702.449, 1709.696, 1713.484 (1700.292)	KLD: 5.344, 3.940, 3.340, 2.440, 2.250, 2.314, 1.835, 1.530, 1.257, 1.096 (25.344)	Grad: 0.226, 0.087, 0.069, 0.044, 0.041, 0.044, 0.042, 0.040, 0.038, 0.038
[Epoch 100 (33.83s)]	ELBO: 1510.418, 1572.294, 1616.762, 1641.536, 1662.173, 1677.555, 1691.083, 1700.757, 1708.350, 1712.205 (1673.737)	Log prob: 1515.774, 1576.247, 1620.084, 1643.957, 1664.430, 1679.858, 1692.907, 1702.260, 1709.610, 1713.271 (1699.376)	KLD: 5.356, 3.953, 3.321, 2.420, 2.257, 2.303, 1.824, 1.502, 1.261, 1.066 (25.639)	Grad: 0.241, 0.086, 0.067, 0.044, 0.041, 0.045, 0.041, 0.039, 0.037, 0.037
Best epoch: 95	Training time: 4026.67s	Best ELBO: 1713.813 (1677.218)	Best log prob: 1715.026 (1702.859)
Avg. mu: 0.826, -0.384, 0.152, 0.493, 0.413, 0.484, -0.277, -0.127, -0.110, 0.150
Avg. var: 0.000, 0.001, 0.002, 0.014, 0.011, 0.008, 0.029, 0.056, 0.088, 0.096
Max. mu: 6.013, 0.828, 2.549, 3.566, 2.042, 2.131, 2.559, 4.163, 3.314, 3.433
Max. var: 0.003, 0.025, 0.020, 0.179, 0.111, 0.096, 0.412, 0.544, 0.359, 0.578
Min. mu: -0.236, -3.435, -2.276, -1.502, -3.907, -1.279, -2.682, -4.505, -3.621, -2.843
Min. var: 0.000, 0.000, 0.000, 0.000, 0.002, 0.001, 0.004, 0.012, 0.016, 0.027
Cov. mu:
[[0.863 -0.016 -0.048 0.140 0.026 0.042 0.096 0.100 0.082 -0.032]
 [-0.016 0.390 0.059 -0.015 0.002 -0.022 0.056 -0.032 0.035 0.015]
 [-0.048 0.059 0.425 -0.032 -0.008 -0.011 -0.002 0.039 0.014 -0.005]
 [0.140 -0.015 -0.032 0.616 0.031 0.039 0.039 0.024 0.040 -0.019]
 [0.026 0.002 -0.008 0.031 0.379 -0.032 0.023 0.020 0.024 0.020]
 [0.042 -0.022 -0.011 0.039 -0.032 0.171 -0.001 0.044 -0.003 -0.006]
 [0.096 0.056 -0.002 0.039 0.023 -0.001 0.460 0.019 -0.009 -0.021]
 [0.100 -0.032 0.039 0.024 0.020 0.044 0.019 0.645 0.035 0.006]
 [0.082 0.035 0.014 0.040 0.024 -0.003 -0.009 0.035 0.793 0.032]
 [-0.032 0.015 -0.005 -0.019 0.020 -0.006 -0.021 0.006 0.032 0.514]]
