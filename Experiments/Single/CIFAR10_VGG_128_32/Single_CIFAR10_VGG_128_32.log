Encoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Encoder                                  --
├─Conv2d: 1-1                            448
├─Conv2d: 1-2                            2,080
├─Conv2d: 1-3                            9,248
├─Conv2d: 1-4                            8,256
├─Conv2d: 1-5                            36,928
├─Conv2d: 1-6                            32,896
├─Linear: 1-7                            1,049,088
├─Linear: 1-8                            262,656
=================================================================
Total params: 1,401,600
Trainable params: 1,401,600
Non-trainable params: 0
=================================================================
Encoder to Latents 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            16,416
├─Linear: 1-2                            16,416
=================================================================
Total params: 32,832
Trainable params: 32,832
Non-trainable params: 0
=================================================================
Encoder to Latents 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            16,416
├─Linear: 1-2                            16,416
=================================================================
Total params: 32,832
Trainable params: 32,832
Non-trainable params: 0
=================================================================
Encoder to Latents 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            16,416
├─Linear: 1-2                            16,416
=================================================================
Total params: 32,832
Trainable params: 32,832
Non-trainable params: 0
=================================================================
Encoder to Latents 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            16,416
├─Linear: 1-2                            16,416
=================================================================
Total params: 32,832
Trainable params: 32,832
Non-trainable params: 0
=================================================================
Latents to Decoder 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            16,896
=================================================================
Total params: 16,896
Trainable params: 16,896
Non-trainable params: 0
=================================================================
Latents to Decoder 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            16,896
=================================================================
Total params: 16,896
Trainable params: 16,896
Non-trainable params: 0
=================================================================
Latents to Decoder 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            16,896
=================================================================
Total params: 16,896
Trainable params: 16,896
Non-trainable params: 0
=================================================================
Latents to Decoder 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            16,896
=================================================================
Total params: 16,896
Trainable params: 16,896
Non-trainable params: 0
=================================================================
Decoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Decoder                                  --
├─Linear: 1-1                            262,656
├─Linear: 1-2                            1,050,624
├─ConvTranspose2d: 1-3                   32,832
├─ConvTranspose2d: 1-4                   36,928
├─ConvTranspose2d: 1-5                   8,224
├─ConvTranspose2d: 1-6                   9,248
├─ConvTranspose2d: 1-7                   2,064
├─ConvTranspose2d: 1-8                   435
=================================================================
Total params: 1,403,011
Trainable params: 1,403,011
Non-trainable params: 0
=================================================================
[Epoch   1 (507.97s)]	ELBO: -17800.168, -17057.221, -17028.553, -17246.547 (-14142.120)	Log prob: -17626.969, -17033.123, -17013.355, -17231.523 (-14039.500)	KLD: 173.195, 24.099, 15.201, 15.014 (102.621)
[Epoch   2 (543.79s)]	ELBO: -12696.449, -12083.231, -12035.547, -12193.027 (-11252.149)	Log prob: -12603.547, -12064.146, -12021.918, -12178.854 (-11110.809)	KLD: 92.901, 19.086, 13.625, 14.180 (141.339)
[Epoch   3 (521.84s)]	ELBO: -10178.671, -9611.182, -9553.652, -9685.927 (-9037.115)	Log prob: -10080.565, -9587.472, -9538.939, -9670.160 (-8860.662)	KLD: 98.103, 23.705, 14.718, 15.766 (176.453)
[Epoch   4 (529.87s)]	ELBO: -8231.431, -7751.048, -7686.383, -7797.276 (-7270.522)	Log prob: -8128.556, -7725.866, -7670.720, -7781.217 (-7078.186)	KLD: 102.877, 25.178, 15.669, 16.061 (192.336)
[Epoch   5 (522.18s)]	ELBO: -6583.795, -6119.729, -6072.875, -6200.227 (-6434.808)	Log prob: -6474.532, -6094.575, -6057.971, -6184.605 (-6263.065)	KLD: 109.263, 25.155, 14.899, 15.623 (171.743)
[Epoch   6 (532.57s)]	ELBO: -6034.659, -5644.952, -5587.003, -5664.193 (-6030.108)	Log prob: -5928.328, -5625.011, -5573.485, -5650.007 (-5881.571)	KLD: 106.327, 19.941, 13.517, 14.183 (148.536)
[Epoch   7 (533.59s)]	ELBO: -5640.486, -5236.522, -5180.133, -5244.659 (-5936.644)	Log prob: -5529.878, -5217.568, -5167.437, -5231.203 (-5780.728)	KLD: 110.609, 18.956, 12.700, 13.453 (155.916)
[Epoch   8 (540.19s)]	ELBO: -5004.827, -4595.129, -4535.693, -4601.117 (-4558.164)	Log prob: -4892.602, -4577.875, -4523.720, -4588.501 (-4393.024)	KLD: 112.224, 17.254, 11.976, 12.616 (165.140)
[Epoch   9 (543.15s)]	ELBO: -4317.523, -3909.600, -3857.737, -3924.577 (-4151.074)	Log prob: -4201.924, -3893.710, -3846.554, -3912.696 (-3992.445)	KLD: 115.603, 15.891, 11.184, 11.882 (158.629)
[Epoch  10 (541.59s)]	ELBO: -4000.191, -3598.595, -3540.745, -3597.681 (-3972.320)	Log prob: -3883.909, -3583.969, -3530.521, -3586.783 (-3814.364)	KLD: 116.280, 14.623, 10.223, 10.901 (157.956)
[Epoch  11 (422.04s)]	ELBO: -3768.582, -3383.729, -3326.969, -3373.166 (-4031.799)	Log prob: -3651.779, -3371.545, -3317.853, -3363.010 (-3887.052)	KLD: 116.804, 12.186, 9.116, 10.156 (144.747)
[Epoch  12 (400.96s)]	ELBO: -3582.017, -3203.701, -3142.335, -3173.739 (-3788.035)	Log prob: -3464.287, -3192.468, -3133.738, -3164.097 (-3639.949)	KLD: 117.730, 11.231, 8.597, 9.638 (148.086)
[Epoch  13 (397.71s)]	ELBO: -3365.148, -2975.180, -2914.862, -2949.118 (-3648.393)	Log prob: -3246.481, -2964.760, -2906.069, -2939.846 (-3502.301)	KLD: 118.668, 10.420, 8.792, 9.271 (146.092)
[Epoch  14 (397.42s)]	ELBO: -3061.735, -2696.738, -2628.168, -2641.518 (-3316.812)	Log prob: -2941.029, -2686.738, -2620.337, -2632.451 (-3174.791)	KLD: 120.707, 10.000, 7.832, 9.068 (142.022)
[Epoch  15 (396.99s)]	ELBO: -2821.660, -2436.727, -2371.277, -2395.859 (-3148.329)	Log prob: -2699.627, -2427.331, -2363.850, -2387.291 (-2999.059)	KLD: 122.033, 9.397, 7.427, 8.568 (149.270)
[Epoch  16 (331.73s)]	ELBO: -2633.557, -2262.881, -2195.214, -2208.232 (-3000.341)	Log prob: -2510.908, -2254.041, -2187.799, -2199.634 (-2852.691)	KLD: 122.650, 8.840, 7.415, 8.597 (147.650)
[Epoch  17 (390.31s)]	ELBO: -2508.145, -2133.451, -2062.097, -2070.548 (-3169.865)	Log prob: -2384.073, -2124.567, -2054.237, -2062.289 (-3021.654)	KLD: 124.072, 8.884, 7.859, 8.259 (148.211)
[Epoch  18 (394.49s)]	ELBO: -2368.992, -1982.075, -1911.012, -1922.625 (-3087.761)	Log prob: -2243.272, -1972.859, -1903.278, -1914.562 (-2931.527)	KLD: 125.717, 9.215, 7.735, 8.065 (156.234)
[Epoch  19 (401.64s)]	ELBO: -2178.403, -1806.427, -1734.942, -1737.282 (-2805.829)	Log prob: -2051.285, -1797.898, -1727.273, -1729.151 (-2649.983)	KLD: 127.118, 8.529, 7.669, 8.132 (155.846)
[Epoch  20 (402.66s)]	ELBO: -2048.067, -1666.489, -1596.251, -1601.412 (-2978.727)	Log prob: -1920.124, -1657.515, -1588.359, -1593.680 (-2832.556)	KLD: 127.942, 8.974, 7.892, 7.731 (146.172)
[Epoch  21 (403.24s)]	ELBO: -1920.240, -1549.126, -1475.301, -1471.745 (-2651.535)	Log prob: -1791.504, -1540.726, -1466.965, -1462.050 (-2503.106)	KLD: 128.737, 8.400, 8.336, 9.695 (148.429)
[Epoch  22 (438.90s)]	ELBO: -1816.665, -1438.361, -1365.673, -1368.330 (-3190.066)	Log prob: -1687.724, -1430.030, -1358.741, -1360.762 (-3042.523)	KLD: 128.942, 8.331, 6.932, 7.569 (147.543)
[Epoch  23 (558.66s)]	ELBO: -1711.706, -1334.903, -1260.553, -1254.550 (-2972.548)	Log prob: -1581.538, -1326.969, -1253.248, -1247.339 (-2824.958)	KLD: 130.167, 7.934, 7.304, 7.212 (147.590)
[Epoch  24 (559.20s)]	ELBO: -1613.408, -1231.370, -1158.069, -1157.268 (-2732.213)	Log prob: -1482.277, -1223.173, -1151.662, -1149.775 (-2585.218)	KLD: 131.129, 8.197, 6.407, 7.493 (146.995)
[Epoch  25 (571.99s)]	ELBO: -1504.326, -1133.975, -1059.644, -1048.006 (-2638.249)	Log prob: -1372.189, -1126.123, -1051.730, -1040.542 (-2485.435)	KLD: 132.137, 7.853, 7.914, 7.465 (152.814)
[Epoch  26 (573.32s)]	ELBO: -1428.845, -1042.311, -970.824, -969.041 (-2667.083)	Log prob: -1295.783, -1033.958, -963.403, -962.103 (-2517.995)	KLD: 133.063, 8.353, 7.421, 6.938 (149.088)
[Epoch  27 (553.28s)]	ELBO: -1323.885, -947.309, -869.264, -863.183 (-2623.743)	Log prob: -1190.173, -937.062, -862.699, -856.075 (-2464.972)	KLD: 133.712, 10.247, 6.565, 7.109 (158.770)
[Epoch  28 (570.45s)]	ELBO: -1238.802, -860.733, -785.144, -779.106 (-2463.355)	Log prob: -1104.190, -853.035, -778.432, -770.990 (-2304.893)	KLD: 134.613, 7.698, 6.712, 8.116 (158.462)
[Epoch  29 (595.65s)]	ELBO: -1152.645, -774.217, -699.577, -692.400 (-2691.801)	Log prob: -1017.752, -767.020, -693.264, -685.433 (-2531.614)	KLD: 134.892, 7.197, 6.313, 6.967 (160.187)
[Epoch  30 (653.55s)]	ELBO: -1083.857, -707.942, -634.024, -628.467 (-2525.762)	Log prob: -948.781, -697.240, -626.374, -621.154 (-2366.408)	KLD: 135.076, 10.701, 7.650, 7.312 (159.353)
[Epoch  31 (645.49s)]	ELBO: -1003.106, -631.061, -555.755, -545.224 (-2262.448)	Log prob: -867.012, -621.678, -548.759, -538.358 (-2109.740)	KLD: 136.094, 9.383, 6.997, 6.866 (152.708)
[Epoch  32 (601.88s)]	ELBO: -941.522, -565.974, -496.335, -483.751 (-2285.261)	Log prob: -805.160, -558.614, -488.903, -477.284 (-2127.726)	KLD: 136.362, 7.360, 7.432, 6.467 (157.535)
[Epoch  33 (649.87s)]	ELBO: -882.403, -504.095, -430.930, -422.839 (-2436.095)	Log prob: -745.319, -495.454, -424.385, -416.320 (-2277.478)	KLD: 137.084, 8.641, 6.545, 6.519 (158.616)
[Epoch  34 (586.45s)]	ELBO: -823.965, -446.207, -373.288, -363.023 (-2393.169)	Log prob: -686.398, -438.552, -366.869, -356.078 (-2232.937)	KLD: 137.567, 7.655, 6.419, 6.945 (160.232)
[Epoch  35 (583.52s)]	ELBO: -752.791, -387.247, -315.330, -296.830 (-2429.306)	Log prob: -614.715, -378.181, -306.398, -289.646 (-2267.628)	KLD: 138.076, 9.066, 8.933, 7.184 (161.678)
[Epoch  36 (564.49s)]	ELBO: -742.415, -350.534, -278.730, -276.756 (-2512.759)	Log prob: -603.718, -342.733, -271.883, -269.399 (-2351.554)	KLD: 138.697, 7.801, 6.846, 7.357 (161.205)
[Epoch  37 (466.42s)]	ELBO: -669.708, -296.100, -222.639, -212.059 (-2755.855)	Log prob: -529.923, -286.989, -216.443, -204.440 (-2591.131)	KLD: 139.785, 9.111, 6.196, 7.619 (164.724)
[Epoch  38 (507.25s)]	ELBO: -624.188, -246.933, -173.936, -164.011 (-2763.269)	Log prob: -483.821, -238.908, -167.610, -157.250 (-2601.188)	KLD: 140.367, 8.025, 6.326, 6.761 (162.081)
[Epoch  39 (463.35s)]	ELBO: -594.074, -210.158, -138.288, -131.977 (-2666.534)	Log prob: -453.215, -202.733, -132.142, -124.966 (-2513.078)	KLD: 140.860, 7.425, 6.145, 7.012 (153.455)
[Epoch  40 (464.49s)]	ELBO: -538.643, -160.347, -91.029, -81.212 (-2311.649)	Log prob: -397.130, -152.120, -84.131, -73.846 (-2150.771)	KLD: 141.513, 8.228, 6.898, 7.366 (160.877)
[Epoch  41 (486.11s)]	ELBO: -486.456, -113.793, -42.681, -31.837 (-2255.069)	Log prob: -344.021, -104.455, -36.119, -25.407 (-2092.775)	KLD: 142.436, 9.339, 6.562, 6.431 (162.294)
[Epoch  42 (540.41s)]	ELBO: -463.335, -81.935, -14.053, -7.232 (-2347.824)	Log prob: -320.509, -73.920, -8.091, -0.865 (-2189.623)	KLD: 142.826, 8.015, 5.962, 6.367 (158.201)
[Epoch  43 (558.52s)]	ELBO: -430.978, -50.896, 19.906, 21.915 (-2304.845)	Log prob: -287.312, -42.011, 25.647, 30.734 (-2143.782)	KLD: 143.666, 8.885, 5.741, 8.818 (161.064)
[Epoch  44 (541.09s)]	ELBO: -392.533, -11.720, 57.970, 63.827 (-2283.248)	Log prob: -248.405, -2.509, 64.360, 70.646 (-2121.035)	KLD: 144.128, 9.211, 6.390, 6.819 (162.213)
[Epoch  45 (548.53s)]	ELBO: -351.546, 24.585, 94.564, 104.007 (-2366.945)	Log prob: -206.630, 33.073, 100.713, 110.969 (-2194.919)	KLD: 144.916, 8.488, 6.148, 6.962 (172.026)
[Epoch  46 (591.05s)]	ELBO: -328.551, 53.672, 122.100, 128.748 (-2441.414)	Log prob: -183.165, 62.616, 128.901, 135.389 (-2275.009)	KLD: 145.386, 8.943, 6.801, 6.641 (166.406)
[Epoch  47 (517.12s)]	ELBO: -297.722, 87.696, 156.392, 160.859 (-2252.732)	Log prob: -152.034, 95.946, 162.530, 167.054 (-2089.117)	KLD: 145.687, 8.250, 6.138, 6.195 (163.615)
[Epoch  48 (500.59s)]	ELBO: -268.632, 115.287, 183.037, 193.531 (-2554.124)	Log prob: -122.181, 121.964, 189.791, 199.990 (-2383.731)	KLD: 146.452, 6.676, 6.754, 6.459 (170.393)
[Epoch  49 (511.07s)]	ELBO: -248.980, 136.353, 202.216, 206.897 (-2406.425)	Log prob: -102.216, 144.753, 208.304, 213.687 (-2230.668)	KLD: 146.764, 8.399, 6.089, 6.790 (175.758)
[Epoch  50 (508.02s)]	ELBO: -207.159, 170.507, 239.186, 245.412 (-2490.060)	Log prob: -59.900, 180.429, 244.768, 251.445 (-2329.027)	KLD: 147.259, 9.922, 5.581, 6.033 (161.034)
[Epoch  51 (505.81s)]	ELBO: -192.831, 190.471, 260.434, 266.175 (-2424.580)	Log prob: -45.358, 199.354, 266.411, 272.584 (-2255.490)	KLD: 147.473, 8.883, 5.978, 6.409 (169.089)
[Epoch  52 (507.34s)]	ELBO: -162.543, 214.179, 284.217, 290.903 (-2434.516)	Log prob: -14.752, 224.839, 290.534, 297.502 (-2262.249)	KLD: 147.790, 10.659, 6.316, 6.599 (172.268)
[Epoch  53 (508.09s)]	ELBO: -144.535, 242.997, 310.641, 312.833 (-2407.198)	Log prob: 3.361, 251.722, 316.213, 318.827 (-2237.935)	KLD: 147.896, 8.726, 5.572, 5.994 (169.264)
[Epoch  54 (502.95s)]	ELBO: -105.685, 275.640, 341.758, 347.810 (-2297.035)	Log prob: 42.663, 283.201, 347.097, 354.077 (-2134.376)	KLD: 148.347, 7.561, 5.339, 6.267 (162.659)
[Epoch  55 (515.00s)]	ELBO: -84.970, 297.125, 365.442, 373.409 (-2252.493)	Log prob: 63.967, 304.700, 370.920, 379.120 (-2087.458)	KLD: 148.937, 7.575, 5.478, 5.711 (165.035)
[Epoch  56 (511.16s)]	ELBO: -75.133, 313.080, 376.331, 379.780 (-2357.632)	Log prob: 74.046, 320.619, 382.190, 386.491 (-2188.956)	KLD: 149.179, 7.539, 5.860, 6.711 (168.676)
[Epoch  57 (510.66s)]	ELBO: -59.406, 328.512, 394.181, 390.660 (-2522.972)	Log prob: 90.497, 337.395, 399.605, 400.712 (-2347.156)	KLD: 149.904, 8.884, 5.424, 10.052 (175.816)
[Epoch  58 (505.11s)]	ELBO: -35.254, 351.152, 413.597, 420.114 (-2581.699)	Log prob: 114.956, 358.564, 419.796, 426.569 (-2410.461)	KLD: 150.210, 7.412, 6.200, 6.455 (171.238)
[Epoch  59 (462.30s)]	ELBO: -20.062, 350.121, 414.225, 424.802 (-2370.049)	Log prob: 130.272, 357.643, 419.523, 430.785 (-2194.103)	KLD: 150.334, 7.522, 5.299, 5.984 (175.946)
[Epoch  60 (401.85s)]	ELBO: 18.979, 398.444, 462.874, 471.892 (-2393.229)	Log prob: 169.830, 406.292, 468.507, 477.899 (-2224.671)	KLD: 150.851, 7.849, 5.633, 6.007 (168.558)
[Epoch  61 (346.40s)]	ELBO: 10.693, 401.294, 463.544, 464.934 (-2393.495)	Log prob: 162.212, 409.694, 469.569, 471.629 (-2221.451)	KLD: 151.519, 8.400, 6.026, 6.695 (172.044)
[Epoch  62 (389.89s)]	ELBO: 52.532, 435.011, 497.486, 505.439 (-2519.028)	Log prob: 203.968, 442.991, 503.905, 511.100 (-2349.221)	KLD: 151.437, 7.980, 6.419, 5.661 (169.807)
[Epoch  63 (389.09s)]	ELBO: 58.139, 447.664, 508.930, 512.409 (-2471.896)	Log prob: 209.656, 455.615, 514.575, 518.265 (-2302.665)	KLD: 151.517, 7.951, 5.645, 5.856 (169.231)
[Epoch  64 (331.81s)]	ELBO: 80.006, 463.025, 525.541, 535.516 (-2582.325)	Log prob: 232.003, 470.371, 531.894, 541.105 (-2407.694)	KLD: 151.997, 7.346, 6.352, 5.589 (174.632)
[Epoch  65 (384.27s)]	ELBO: 88.531, 477.724, 538.666, 537.937 (-2526.884)	Log prob: 240.778, 486.307, 544.739, 543.826 (-2356.097)	KLD: 152.247, 8.584, 6.072, 5.889 (170.787)
[Epoch  66 (389.06s)]	ELBO: 110.257, 494.771, 558.318, 561.916 (-2404.911)	Log prob: 262.837, 503.652, 563.544, 568.289 (-2236.698)	KLD: 152.581, 8.881, 5.226, 6.374 (168.212)
[Epoch  67 (394.92s)]	ELBO: 132.593, 514.903, 577.892, 583.348 (-2298.625)	Log prob: 285.329, 523.397, 583.533, 589.745 (-2127.166)	KLD: 152.736, 8.494, 5.641, 6.398 (171.459)
[Epoch  68 (330.81s)]	ELBO: 143.427, 532.367, 595.637, 598.392 (-2492.618)	Log prob: 296.280, 540.761, 600.493, 603.549 (-2320.402)	KLD: 152.853, 8.394, 4.856, 5.157 (172.216)
[Epoch  69 (384.68s)]	ELBO: 153.871, 539.715, 605.357, 608.264 (-2788.633)	Log prob: 306.750, 548.321, 610.197, 614.073 (-2611.988)	KLD: 152.879, 8.606, 4.840, 5.809 (176.645)
[Epoch  70 (391.79s)]	ELBO: 167.560, 555.225, 617.416, 619.988 (-2530.322)	Log prob: 320.790, 563.575, 622.363, 625.866 (-2357.645)	KLD: 153.230, 8.350, 4.946, 5.878 (172.676)
[Epoch  71 (392.65s)]	ELBO: 187.144, 576.805, 638.906, 640.729 (-2477.789)	Log prob: 340.787, 584.987, 643.517, 645.766 (-2304.523)	KLD: 153.643, 8.183, 4.611, 5.037 (173.266)
[Epoch  72 (332.18s)]	ELBO: 191.598, 582.605, 645.566, 646.554 (-2367.161)	Log prob: 345.327, 591.880, 650.634, 651.777 (-2198.241)	KLD: 153.729, 9.274, 5.068, 5.223 (168.920)
[Epoch  73 (382.51s)]	ELBO: 219.453, 604.317, 668.134, 673.888 (-2494.720)	Log prob: 373.582, 611.944, 672.675, 679.225 (-2322.534)	KLD: 154.129, 7.628, 4.541, 5.336 (172.186)
[Epoch  74 (386.27s)]	ELBO: 237.477, 618.129, 679.764, 686.756 (-2599.552)	Log prob: 391.607, 625.633, 684.697, 693.109 (-2424.589)	KLD: 154.130, 7.505, 4.933, 6.354 (174.963)
[Epoch  75 (391.27s)]	ELBO: 244.899, 632.926, 693.703, 694.909 (-2529.660)	Log prob: 399.447, 641.429, 698.146, 700.324 (-2364.004)	KLD: 154.548, 8.504, 4.443, 5.415 (165.656)
[Epoch  76 (379.15s)]	ELBO: 250.186, 639.891, 700.384, 699.275 (-2597.074)	Log prob: 405.088, 649.499, 704.736, 704.628 (-2421.821)	KLD: 154.902, 9.608, 4.352, 5.353 (175.253)
[Epoch  77 (330.53s)]	ELBO: 237.635, 622.748, 686.982, 686.922 (-2649.369)	Log prob: 392.628, 634.234, 691.639, 692.172 (-2466.757)	KLD: 154.993, 11.485, 4.658, 5.250 (182.612)
[Epoch  78 (383.79s)]	ELBO: 280.108, 662.262, 724.623, 728.093 (-2598.717)	Log prob: 435.254, 671.860, 729.137, 733.325 (-2421.444)	KLD: 155.146, 9.597, 4.514, 5.232 (177.273)
[Epoch  79 (386.64s)]	ELBO: 288.615, 677.038, 737.412, 740.499 (-2505.747)	Log prob: 443.905, 684.267, 742.314, 745.551 (-2339.279)	KLD: 155.290, 7.229, 4.901, 5.052 (166.468)
No improvement after 25 epochs...
Best epoch(s): [55]	Training time(s): 37594.65s (37594.65s)	Best ELBO: 740.499 (-2252.493)	Best log prob: 745.551 (-2087.458)
Avg. mu: 0.111, 0.027, 0.058, -0.101, 0.011, -0.041, -0.212, 0.036, -0.069, 0.053, 0.083, 0.106, -0.050, -0.009, 0.248, -0.050, 0.143, 0.078, 0.114, -0.108, -0.010, -0.040, 0.154, 0.299, -0.185, -0.317, 0.032, 0.008, 0.006, -0.041, 0.026, -0.097, 0.464, 0.593, 0.593, 0.788, -0.150, -0.607, -0.116, -0.474, -0.583, 0.086, -0.252, 0.080, -0.683, 0.433, 0.005, -0.015, -0.423, -0.316, -0.097, 0.092, 0.511, -0.638, -0.692, -0.794, 0.762, -0.479, 0.142, -0.518, 0.554, -0.396, 0.374, -0.110, 0.236, 0.372, -0.960, 0.024, -0.026, 0.779, -0.456, -0.150, 0.043, -0.368, -0.116, -0.268, -0.305, 0.386, 0.167, 0.315, 0.092, 0.661, -0.216, -0.129, 0.319, -0.456, -0.217, -0.058, -0.147, -0.879, 0.557, 0.263, -0.754, 0.671, -0.059, 0.308, 0.130, -0.628, 0.405, -0.172, -0.057, -0.241, 0.362, -0.406, 0.146, -0.639, 0.182, -0.035, 0.538, -0.077, -0.585, 0.472, -0.010, 0.608, -0.256, -0.239, 0.277, 0.086, 0.163, -0.537, -0.259, -0.380, 0.069, -0.146, -0.019, 0.403, -0.372, -0.399
Avg. var: 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.486, 0.493, 0.577, 0.350, 0.619, 0.361, 0.616, 0.415, 0.428, 0.805, 0.754, 0.671, 0.291, 0.632, 0.656, 0.732, 0.496, 0.419, 0.649, 0.761, 0.303, 0.516, 0.279, 0.524, 0.530, 0.412, 0.578, 0.510, 0.449, 0.510, 0.428, 0.788, 0.800, 0.587, 0.219, 0.818, 0.737, 0.246, 0.588, 0.897, 0.712, 0.352, 0.953, 0.436, 0.806, 0.533, 0.626, 0.693, 0.850, 0.318, 0.580, 0.842, 0.552, 0.438, 0.786, 0.764, 0.841, 0.371, 0.428, 0.646, 0.211, 0.254, 0.795, 0.569, 0.577, 0.397, 0.395, 0.451, 0.735, 0.936, 0.487, 0.536, 0.642, 0.392, 0.668, 0.755, 0.438, 0.751, 0.376, 0.420, 0.789, 0.433, 0.646, 0.714, 0.524, 0.686, 0.714, 0.361, 0.427, 0.502, 0.669, 0.772, 0.709, 0.493, 0.414, 0.461
Max. mu: 1.340, 0.983, 1.116, 0.915, 2.183, 1.211, 1.102, 2.149, 1.007, 1.270, 1.141, 1.087, 0.801, 0.878, 1.402, 1.060, 1.245, 1.569, 1.696, 2.025, 1.015, 1.124, 1.528, 2.171, 0.958, 1.279, 1.113, 1.761, 0.753, 1.202, 0.931, 0.910, 1.748, 1.463, 1.129, 1.656, 0.204, -0.283, 0.237, -0.080, -0.257, 0.635, 0.127, 0.381, -0.331, 1.086, 0.407, 0.435, -0.192, 0.200, 0.240, 0.631, 1.127, -0.306, -0.286, -0.303, 1.744, -0.054, 0.591, -0.163, 1.820, 0.003, 1.097, 0.537, 0.685, 0.883, -0.565, 0.469, 0.282, 1.661, -0.030, 0.129, 0.406, -0.087, 0.181, 0.099, 0.008, 0.949, 0.623, 0.823, 0.570, 1.340, 0.112, 0.199, 0.779, -0.043, 0.082, 0.190, 0.095, -0.558, 1.117, 0.980, -0.433, 1.235, 0.296, 0.945, 0.397, -0.363, 0.701, 0.047, 0.308, 0.069, 0.605, -0.071, 0.411, -0.420, 0.388, 0.236, 0.787, 0.283, -0.304, 0.806, 0.272, 0.940, 0.006, 0.138, 0.497, 0.543, 0.518, -0.278, 0.170, -0.036, 0.389, 0.208, 0.317, 0.656, 0.003, -0.136
Max. var: 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.001, 0.000, 0.001, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.001, 0.000, 1.285, 6.283, 1.488, 1.104, 0.888, 0.758, 1.224, 1.111, 0.905, 1.542, 3.004, 2.836, 0.554, 1.141, 1.015, 1.370, 0.958, 3.501, 1.200, 1.371, 0.770, 1.399, 0.638, 3.917, 1.413, 1.006, 1.052, 0.998, 0.889, 0.894, 0.741, 2.180, 1.241, 1.047, 0.397, 1.978, 1.150, 0.562, 1.331, 1.527, 1.694, 0.610, 2.333, 0.691, 1.432, 1.295, 0.997, 1.647, 2.132, 0.556, 0.947, 1.373, 0.786, 0.936, 1.922, 1.350, 1.368, 0.654, 1.219, 1.573, 0.345, 0.421, 1.621, 0.882, 0.994, 0.856, 0.874, 0.621, 2.159, 2.020, 1.255, 1.857, 2.664, 0.771, 1.991, 1.402, 0.964, 1.172, 0.659, 0.851, 1.557, 1.596, 1.104, 2.216, 1.161, 1.253, 1.229, 1.306, 0.939, 1.699, 1.144, 1.419, 1.273, 1.011, 1.035, 1.042
Min. mu: -1.521, -0.854, -1.129, -1.488, -1.261, -1.191, -1.492, -1.844, -1.047, -0.999, -0.865, -1.009, -1.351, -0.848, -0.864, -1.484, -0.946, -1.219, -0.971, -2.337, -0.684, -0.977, -0.943, -0.793, -1.485, -1.627, -1.023, -2.393, -0.755, -1.630, -1.124, -1.135, 0.004, 0.234, 0.181, 0.247, -0.596, -1.506, -0.648, -0.969, -1.522, -0.408, -0.599, -0.295, -1.588, -0.036, -0.346, -0.430, -0.865, -0.775, -0.467, -0.337, 0.034, -1.703, -1.216, -1.568, 0.415, -1.396, -0.243, -1.563, 0.147, -0.987, -0.113, -0.466, -0.234, 0.041, -1.801, -0.480, -0.423, 0.395, -1.198, -0.833, -0.273, -0.827, -0.397, -0.979, -0.743, 0.015, -0.098, 0.036, -0.200, 0.291, -0.477, -0.740, 0.045, -1.056, -0.834, -0.444, -0.544, -1.775, 0.251, -0.287, -1.351, 0.309, -0.441, -0.002, -0.108, -0.922, 0.052, -0.405, -0.730, -0.626, 0.066, -0.641, -0.208, -1.119, -0.175, -0.315, 0.304, -0.490, -0.897, 0.115, -0.367, 0.323, -0.601, -0.577, -0.040, -0.252, -0.057, -0.998, -0.578, -0.643, -0.216, -0.492, -0.328, 0.156, -0.609, -0.601
Min. var: 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.146, 0.154, 0.322, 0.104, 0.329, 0.067, 0.285, 0.195, 0.108, 0.378, 0.361, 0.378, 0.073, 0.332, 0.359, 0.427, 0.142, 0.143, 0.315, 0.416, 0.091, 0.230, 0.098, 0.228, 0.184, 0.172, 0.253, 0.162, 0.191, 0.272, 0.128, 0.468, 0.517, 0.335, 0.065, 0.464, 0.477, 0.068, 0.306, 0.574, 0.471, 0.117, 0.512, 0.204, 0.464, 0.220, 0.330, 0.413, 0.509, 0.139, 0.329, 0.539, 0.310, 0.196, 0.523, 0.322, 0.483, 0.153, 0.153, 0.334, 0.085, 0.090, 0.449, 0.196, 0.312, 0.167, 0.138, 0.221, 0.437, 0.439, 0.178, 0.293, 0.316, 0.159, 0.338, 0.457, 0.161, 0.491, 0.163, 0.190, 0.465, 0.167, 0.332, 0.430, 0.236, 0.380, 0.428, 0.155, 0.180, 0.297, 0.423, 0.496, 0.408, 0.217, 0.197, 0.139
Cov. mu:
[[0.069 0.000 0.003 ... 0.003 -0.003 -0.000]
 [0.000 0.045 -0.002 ... 0.002 -0.003 -0.002]
 [0.003 -0.002 0.066 ... 0.000 0.001 -0.003]
 ...
 [0.003 0.002 0.000 ... 0.003 -0.000 -0.001]
 [-0.003 -0.003 0.001 ... -0.000 0.003 0.002]
 [-0.000 -0.002 -0.003 ... -0.001 0.002 0.003]]
