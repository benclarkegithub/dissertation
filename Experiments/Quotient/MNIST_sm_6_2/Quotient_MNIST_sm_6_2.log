Encoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Encoder                                  --
├─Linear: 1-1                            76,930
├─Linear: 1-2                            4,851
=================================================================
Total params: 81,781
Trainable params: 81,781
Non-trainable params: 0
=================================================================
Encoder to Latents 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            100
├─Linear: 1-2                            100
=================================================================
Total params: 200
Trainable params: 200
Non-trainable params: 0
=================================================================
Encoder to Latents 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            100
├─Linear: 1-2                            100
=================================================================
Total params: 200
Trainable params: 200
Non-trainable params: 0
=================================================================
Encoder to Latents 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            100
├─Linear: 1-2                            100
=================================================================
Total params: 200
Trainable params: 200
Non-trainable params: 0
=================================================================
Latents to Decoder 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            147
=================================================================
Total params: 147
Trainable params: 147
Non-trainable params: 0
=================================================================
Latents to Decoder 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            147
=================================================================
Total params: 147
Trainable params: 147
Non-trainable params: 0
=================================================================
Latents to Decoder 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            147
=================================================================
Total params: 147
Trainable params: 147
Non-trainable params: 0
=================================================================
Decoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Decoder                                  --
├─Linear: 1-1                            4,900
├─Linear: 1-2                            77,616
=================================================================
Total params: 82,516
Trainable params: 82,516
Non-trainable params: 0
=================================================================
[Epoch   1 (41.19s)]	ELBO: 1195.126, 1297.919, 1303.858 (1422.053)	Log prob: 1201.791, 1314.388, 1321.902 (1433.288)	KLD: 6.665, 16.468, 18.044 (11.235)	Grad: 0.114, 0.172, 0.235
[Epoch   2 (44.50s)]	ELBO: 1428.923, 1463.479, 1462.624 (1494.574)	Log prob: 1436.373, 1474.954, 1475.157 (1507.547)	KLD: 7.449, 11.475, 12.534 (12.973)	Grad: 0.063, 0.104, 0.154
[Epoch   3 (41.60s)]	ELBO: 1460.574, 1518.662, 1518.438 (1550.224)	Log prob: 1468.125, 1531.354, 1531.965 (1563.947)	KLD: 7.551, 12.692, 13.527 (13.723)	Grad: 0.075, 0.128, 0.193
[Epoch   4 (40.96s)]	ELBO: 1476.881, 1561.749, 1570.131 (1596.422)	Log prob: 1484.272, 1574.857, 1584.809 (1612.144)	KLD: 7.391, 13.106, 14.678 (15.722)	Grad: 0.080, 0.137, 0.202
[Epoch   5 (41.68s)]	ELBO: 1488.334, 1581.400, 1604.881 (1619.352)	Log prob: 1495.702, 1594.602, 1620.962 (1635.708)	KLD: 7.369, 13.202, 16.080 (16.356)	Grad: 0.087, 0.147, 0.210
[Epoch   6 (39.99s)]	ELBO: 1497.151, 1596.656, 1624.805 (1635.493)	Log prob: 1504.678, 1610.042, 1641.440 (1652.256)	KLD: 7.526, 13.387, 16.635 (16.763)	Grad: 0.090, 0.153, 0.221
[Epoch   7 (39.75s)]	ELBO: 1503.073, 1606.472, 1637.176 (1643.847)	Log prob: 1510.580, 1619.719, 1653.875 (1660.212)	KLD: 7.508, 13.247, 16.700 (16.365)	Grad: 0.086, 0.145, 0.211
[Epoch   8 (41.40s)]	ELBO: 1508.158, 1613.083, 1644.248 (1650.677)	Log prob: 1515.647, 1626.204, 1660.844 (1667.270)	KLD: 7.490, 13.120, 16.596 (16.593)	Grad: 0.087, 0.148, 0.215
[Epoch   9 (40.98s)]	ELBO: 1512.661, 1617.962, 1649.699 (1654.667)	Log prob: 1520.160, 1631.051, 1666.290 (1671.142)	KLD: 7.499, 13.088, 16.590 (16.475)	Grad: 0.088, 0.152, 0.222
[Epoch  10 (41.63s)]	ELBO: 1517.453, 1622.064, 1654.125 (1658.895)	Log prob: 1525.021, 1635.179, 1670.780 (1675.369)	KLD: 7.568, 13.115, 16.656 (16.475)	Grad: 0.089, 0.151, 0.221
[Epoch  11 (44.15s)]	ELBO: 1522.399, 1625.637, 1657.994 (1661.642)	Log prob: 1530.016, 1638.763, 1674.688 (1678.357)	KLD: 7.617, 13.125, 16.693 (16.715)	Grad: 0.089, 0.151, 0.221
[Epoch  12 (42.98s)]	ELBO: 1526.654, 1628.253, 1661.012 (1664.743)	Log prob: 1534.324, 1641.393, 1677.730 (1681.534)	KLD: 7.670, 13.140, 16.718 (16.791)	Grad: 0.093, 0.157, 0.230
[Epoch  13 (44.34s)]	ELBO: 1530.802, 1631.013, 1664.016 (1667.754)	Log prob: 1538.526, 1644.221, 1680.833 (1684.776)	KLD: 7.724, 13.207, 16.817 (17.022)	Grad: 0.092, 0.153, 0.223
[Epoch  14 (43.43s)]	ELBO: 1534.316, 1633.275, 1666.694 (1669.335)	Log prob: 1542.077, 1646.511, 1683.542 (1686.446)	KLD: 7.761, 13.238, 16.850 (17.111)	Grad: 0.094, 0.157, 0.229
[Epoch  15 (44.23s)]	ELBO: 1537.551, 1635.389, 1669.258 (1672.283)	Log prob: 1545.334, 1648.635, 1686.137 (1689.203)	KLD: 7.782, 13.247, 16.879 (16.920)	Grad: 0.096, 0.159, 0.232
[Epoch  16 (42.96s)]	ELBO: 1540.453, 1637.303, 1671.635 (1673.525)	Log prob: 1548.257, 1650.570, 1688.527 (1690.307)	KLD: 7.803, 13.267, 16.893 (16.782)	Grad: 0.099, 0.164, 0.239
[Epoch  17 (42.34s)]	ELBO: 1542.901, 1639.176, 1673.763 (1676.304)	Log prob: 1550.735, 1652.462, 1690.705 (1693.265)	KLD: 7.835, 13.286, 16.942 (16.962)	Grad: 0.099, 0.164, 0.240
[Epoch  18 (43.44s)]	ELBO: 1545.397, 1640.795, 1675.703 (1677.685)	Log prob: 1553.270, 1654.147, 1692.719 (1694.823)	KLD: 7.871, 13.351, 17.017 (17.138)	Grad: 0.098, 0.162, 0.236
[Epoch  19 (44.09s)]	ELBO: 1547.768, 1642.363, 1677.464 (1679.732)	Log prob: 1555.659, 1655.709, 1694.483 (1696.617)	KLD: 7.889, 13.346, 17.019 (16.885)	Grad: 0.102, 0.169, 0.246
[Epoch  20 (42.62s)]	ELBO: 1549.543, 1643.557, 1679.026 (1680.508)	Log prob: 1557.431, 1656.908, 1696.041 (1697.200)	KLD: 7.887, 13.352, 17.014 (16.693)	Grad: 0.102, 0.167, 0.243
[Epoch  21 (43.43s)]	ELBO: 1551.452, 1644.812, 1680.530 (1682.023)	Log prob: 1559.366, 1658.197, 1697.591 (1699.182)	KLD: 7.914, 13.384, 17.060 (17.159)	Grad: 0.103, 0.169, 0.246
[Epoch  22 (44.76s)]	ELBO: 1553.183, 1646.023, 1681.955 (1683.172)	Log prob: 1561.091, 1659.395, 1699.005 (1700.481)	KLD: 7.908, 13.373, 17.051 (17.309)	Grad: 0.103, 0.169, 0.247
[Epoch  23 (45.17s)]	ELBO: 1554.715, 1647.206, 1683.358 (1684.107)	Log prob: 1562.625, 1660.587, 1700.430 (1701.040)	KLD: 7.910, 13.380, 17.072 (16.933)	Grad: 0.103, 0.168, 0.243
[Epoch  24 (47.13s)]	ELBO: 1556.432, 1648.232, 1684.417 (1685.473)	Log prob: 1564.370, 1661.646, 1701.507 (1702.738)	KLD: 7.937, 13.413, 17.089 (17.265)	Grad: 0.102, 0.167, 0.244
[Epoch  25 (48.83s)]	ELBO: 1557.837, 1649.110, 1685.422 (1686.183)	Log prob: 1565.770, 1662.524, 1702.535 (1703.058)	KLD: 7.934, 13.414, 17.115 (16.875)	Grad: 0.103, 0.170, 0.247
[Epoch  26 (46.10s)]	ELBO: 1558.917, 1649.950, 1686.469 (1687.289)	Log prob: 1566.839, 1663.330, 1703.559 (1704.566)	KLD: 7.922, 13.381, 17.089 (17.276)	Grad: 0.104, 0.171, 0.248
[Epoch  27 (46.12s)]	ELBO: 1560.314, 1650.978, 1687.439 (1688.328)	Log prob: 1568.259, 1664.389, 1704.557 (1705.046)	KLD: 7.945, 13.411, 17.119 (16.718)	Grad: 0.104, 0.171, 0.249
[Epoch  28 (44.67s)]	ELBO: 1561.541, 1651.841, 1688.399 (1688.572)	Log prob: 1569.490, 1665.265, 1705.503 (1705.819)	KLD: 7.947, 13.424, 17.105 (17.247)	Grad: 0.105, 0.173, 0.252
[Epoch  29 (46.45s)]	ELBO: 1562.708, 1652.610, 1689.264 (1688.585)	Log prob: 1570.666, 1666.043, 1706.389 (1705.599)	KLD: 7.958, 13.433, 17.124 (17.014)	Grad: 0.105, 0.171, 0.250
[Epoch  30 (45.73s)]	ELBO: 1563.522, 1653.186, 1689.854 (1689.430)	Log prob: 1571.478, 1666.615, 1706.991 (1706.441)	KLD: 7.956, 13.430, 17.136 (17.011)	Grad: 0.106, 0.175, 0.255
[Epoch  31 (46.56s)]	ELBO: 1564.434, 1653.860, 1690.507 (1689.782)	Log prob: 1572.384, 1667.290, 1707.646 (1707.077)	KLD: 7.951, 13.431, 17.138 (17.296)	Grad: 0.106, 0.174, 0.254
[Epoch  32 (44.52s)]	ELBO: 1565.390, 1654.636, 1691.439 (1691.052)	Log prob: 1573.341, 1668.052, 1708.560 (1707.783)	KLD: 7.952, 13.417, 17.121 (16.731)	Grad: 0.106, 0.175, 0.254
[Epoch  33 (45.85s)]	ELBO: 1566.264, 1655.444, 1692.217 (1690.508)	Log prob: 1574.220, 1668.879, 1709.358 (1707.816)	KLD: 7.956, 13.434, 17.141 (17.308)	Grad: 0.106, 0.173, 0.252
[Epoch  34 (46.14s)]	ELBO: 1567.256, 1655.904, 1692.838 (1692.142)	Log prob: 1575.215, 1669.341, 1709.992 (1708.859)	KLD: 7.958, 13.436, 17.153 (16.718)	Grad: 0.106, 0.174, 0.252
[Epoch  35 (43.99s)]	ELBO: 1567.859, 1656.418, 1693.354 (1691.361)	Log prob: 1575.812, 1669.854, 1710.475 (1708.322)	KLD: 7.952, 13.436, 17.121 (16.961)	Grad: 0.107, 0.177, 0.257
[Epoch  36 (44.22s)]	ELBO: 1568.531, 1656.867, 1693.878 (1691.908)	Log prob: 1576.482, 1670.310, 1711.013 (1709.265)	KLD: 7.952, 13.443, 17.135 (17.357)	Grad: 0.106, 0.175, 0.254
[Epoch  37 (42.29s)]	ELBO: 1569.555, 1657.588, 1694.529 (1693.424)	Log prob: 1577.524, 1671.035, 1711.676 (1710.234)	KLD: 7.969, 13.448, 17.146 (16.810)	Grad: 0.106, 0.175, 0.255
[Epoch  38 (43.46s)]	ELBO: 1570.064, 1657.872, 1694.939 (1693.161)	Log prob: 1578.029, 1671.314, 1712.082 (1710.289)	KLD: 7.964, 13.442, 17.143 (17.127)	Grad: 0.107, 0.177, 0.257
[Epoch  39 (41.98s)]	ELBO: 1570.598, 1658.353, 1695.499 (1693.791)	Log prob: 1578.562, 1671.793, 1712.646 (1710.610)	KLD: 7.966, 13.439, 17.148 (16.819)	Grad: 0.107, 0.177, 0.257
[Epoch  40 (41.25s)]	ELBO: 1571.471, 1659.065, 1696.241 (1693.212)	Log prob: 1579.429, 1672.501, 1713.405 (1710.290)	KLD: 7.958, 13.437, 17.164 (17.078)	Grad: 0.105, 0.173, 0.251
[Epoch  41 (42.11s)]	ELBO: 1572.207, 1659.403, 1696.574 (1693.696)	Log prob: 1580.174, 1672.878, 1713.751 (1710.684)	KLD: 7.966, 13.474, 17.177 (16.988)	Grad: 0.107, 0.177, 0.257
[Epoch  42 (41.91s)]	ELBO: 1573.013, 1660.012, 1697.237 (1694.377)	Log prob: 1580.990, 1673.484, 1714.392 (1711.634)	KLD: 7.977, 13.471, 17.155 (17.257)	Grad: 0.105, 0.174, 0.252
[Epoch  43 (41.39s)]	ELBO: 1573.427, 1660.308, 1697.537 (1695.224)	Log prob: 1581.390, 1673.775, 1714.696 (1712.252)	KLD: 7.962, 13.467, 17.159 (17.027)	Grad: 0.106, 0.176, 0.256
[Epoch  44 (42.61s)]	ELBO: 1573.924, 1660.749, 1697.981 (1695.065)	Log prob: 1581.909, 1674.220, 1715.152 (1712.213)	KLD: 7.986, 13.471, 17.171 (17.149)	Grad: 0.107, 0.176, 0.255
[Epoch  45 (43.61s)]	ELBO: 1574.403, 1661.050, 1698.248 (1695.374)	Log prob: 1582.375, 1674.520, 1715.418 (1712.291)	KLD: 7.972, 13.471, 17.170 (16.917)	Grad: 0.105, 0.175, 0.255
[Epoch  46 (44.57s)]	ELBO: 1575.021, 1661.512, 1698.790 (1695.712)	Log prob: 1582.999, 1674.989, 1715.965 (1712.791)	KLD: 7.979, 13.478, 17.175 (17.079)	Grad: 0.107, 0.176, 0.256
[Epoch  47 (43.97s)]	ELBO: 1575.560, 1661.849, 1699.121 (1695.872)	Log prob: 1583.540, 1675.334, 1716.292 (1713.225)	KLD: 7.979, 13.486, 17.172 (17.353)	Grad: 0.107, 0.176, 0.256
[Epoch  48 (42.92s)]	ELBO: 1576.021, 1662.195, 1699.595 (1696.283)	Log prob: 1584.007, 1675.685, 1716.789 (1713.446)	KLD: 7.987, 13.489, 17.194 (17.163)	Grad: 0.107, 0.175, 0.254
[Epoch  49 (41.26s)]	ELBO: 1576.604, 1662.597, 1699.885 (1696.978)	Log prob: 1584.579, 1676.051, 1717.036 (1713.884)	KLD: 7.974, 13.453, 17.152 (16.907)	Grad: 0.107, 0.177, 0.257
[Epoch  50 (40.40s)]	ELBO: 1577.176, 1663.025, 1700.327 (1697.030)	Log prob: 1585.159, 1676.502, 1717.500 (1714.018)	KLD: 7.983, 13.477, 17.173 (16.988)	Grad: 0.107, 0.175, 0.254
[Epoch  51 (40.85s)]	ELBO: 1577.369, 1663.227, 1700.557 (1697.004)	Log prob: 1585.343, 1676.703, 1717.714 (1713.492)	KLD: 7.973, 13.476, 17.159 (16.488)	Grad: 0.108, 0.178, 0.257
[Epoch  52 (39.42s)]	ELBO: 1577.979, 1663.510, 1700.846 (1696.893)	Log prob: 1585.948, 1676.992, 1718.021 (1714.021)	KLD: 7.968, 13.482, 17.175 (17.127)	Grad: 0.107, 0.177, 0.257
[Epoch  53 (41.25s)]	ELBO: 1578.111, 1663.679, 1700.977 (1697.447)	Log prob: 1586.074, 1677.133, 1718.126 (1714.565)	KLD: 7.962, 13.456, 17.151 (17.117)	Grad: 0.109, 0.179, 0.260
[Epoch  54 (40.25s)]	ELBO: 1578.898, 1664.296, 1701.619 (1698.501)	Log prob: 1586.875, 1677.776, 1718.788 (1715.319)	KLD: 7.975, 13.480, 17.170 (16.819)	Grad: 0.108, 0.177, 0.257
[Epoch  55 (45.02s)]	ELBO: 1579.145, 1664.365, 1701.690 (1698.133)	Log prob: 1587.107, 1677.826, 1718.844 (1715.009)	KLD: 7.963, 13.461, 17.155 (16.876)	Grad: 0.109, 0.179, 0.261
[Epoch  56 (44.45s)]	ELBO: 1579.488, 1664.717, 1701.987 (1697.073)	Log prob: 1587.456, 1678.200, 1719.167 (1714.362)	KLD: 7.969, 13.483, 17.179 (17.289)	Grad: 0.110, 0.179, 0.259
[Epoch  57 (45.51s)]	ELBO: 1579.813, 1664.929, 1702.162 (1698.367)	Log prob: 1587.778, 1678.401, 1719.323 (1715.636)	KLD: 7.966, 13.471, 17.160 (17.269)	Grad: 0.108, 0.177, 0.258
[Epoch  58 (43.99s)]	ELBO: 1580.124, 1665.164, 1702.516 (1698.413)	Log prob: 1588.083, 1678.627, 1719.681 (1715.482)	KLD: 7.960, 13.462, 17.166 (17.069)	Grad: 0.108, 0.177, 0.257
[Epoch  59 (40.33s)]	ELBO: 1580.634, 1665.468, 1702.786 (1698.730)	Log prob: 1588.595, 1678.943, 1719.948 (1715.700)	KLD: 7.962, 13.475, 17.163 (16.970)	Grad: 0.109, 0.179, 0.261
[Epoch  60 (41.02s)]	ELBO: 1581.085, 1665.843, 1703.089 (1698.595)	Log prob: 1589.060, 1679.330, 1720.272 (1715.962)	KLD: 7.974, 13.489, 17.183 (17.367)	Grad: 0.109, 0.178, 0.258
[Epoch  61 (41.25s)]	ELBO: 1581.081, 1665.759, 1703.009 (1699.532)	Log prob: 1589.045, 1679.226, 1720.177 (1716.737)	KLD: 7.964, 13.466, 17.168 (17.205)	Grad: 0.110, 0.180, 0.261
[Epoch  62 (40.67s)]	ELBO: 1581.195, 1665.747, 1703.053 (1699.174)	Log prob: 1589.164, 1679.233, 1720.235 (1716.285)	KLD: 7.970, 13.485, 17.182 (17.111)	Grad: 0.112, 0.182, 0.265
[Epoch  63 (40.68s)]	ELBO: 1581.641, 1666.221, 1703.442 (1698.921)	Log prob: 1589.603, 1679.693, 1720.611 (1715.870)	KLD: 7.962, 13.472, 17.169 (16.949)	Grad: 0.110, 0.181, 0.263
[Epoch  64 (40.24s)]	ELBO: 1582.093, 1666.578, 1703.790 (1698.521)	Log prob: 1590.062, 1680.056, 1720.958 (1715.854)	KLD: 7.969, 13.478, 17.169 (17.333)	Grad: 0.110, 0.180, 0.261
[Epoch  65 (40.61s)]	ELBO: 1582.418, 1666.920, 1704.113 (1699.209)	Log prob: 1590.409, 1680.423, 1721.289 (1716.407)	KLD: 7.991, 13.502, 17.177 (17.198)	Grad: 0.110, 0.180, 0.262
[Epoch  66 (43.28s)]	ELBO: 1583.051, 1667.354, 1704.578 (1699.942)	Log prob: 1591.034, 1680.851, 1721.763 (1717.118)	KLD: 7.983, 13.498, 17.186 (17.176)	Grad: 0.110, 0.181, 0.263
[Epoch  67 (42.08s)]	ELBO: 1583.276, 1667.510, 1704.783 (1700.120)	Log prob: 1591.259, 1681.010, 1721.995 (1717.292)	KLD: 7.983, 13.500, 17.211 (17.172)	Grad: 0.110, 0.179, 0.260
[Epoch  68 (42.08s)]	ELBO: 1583.677, 1667.758, 1704.940 (1699.724)	Log prob: 1591.647, 1681.243, 1722.107 (1717.152)	KLD: 7.971, 13.485, 17.167 (17.429)	Grad: 0.110, 0.179, 0.261
[Epoch  69 (40.54s)]	ELBO: 1583.793, 1667.840, 1705.055 (1699.924)	Log prob: 1591.776, 1681.334, 1722.245 (1716.824)	KLD: 7.984, 13.495, 17.188 (16.900)	Grad: 0.112, 0.182, 0.264
[Epoch  70 (40.55s)]	ELBO: 1584.159, 1668.106, 1705.342 (1699.488)	Log prob: 1592.162, 1681.622, 1722.541 (1716.544)	KLD: 8.003, 13.516, 17.199 (17.056)	Grad: 0.110, 0.180, 0.261
[Epoch  71 (40.05s)]	ELBO: 1583.838, 1667.942, 1705.148 (1701.007)	Log prob: 1591.842, 1681.458, 1722.360 (1718.170)	KLD: 8.003, 13.516, 17.212 (17.162)	Grad: 0.113, 0.183, 0.266
[Epoch  72 (39.84s)]	ELBO: 1584.456, 1668.330, 1705.540 (1699.923)	Log prob: 1592.442, 1681.827, 1722.745 (1717.037)	KLD: 7.986, 13.498, 17.203 (17.114)	Grad: 0.112, 0.183, 0.265
[Epoch  73 (40.42s)]	ELBO: 1584.747, 1668.508, 1705.657 (1701.119)	Log prob: 1592.733, 1682.013, 1722.860 (1718.081)	KLD: 7.986, 13.504, 17.204 (16.962)	Grad: 0.110, 0.180, 0.263
[Epoch  74 (39.95s)]	ELBO: 1585.180, 1668.767, 1705.827 (1700.616)	Log prob: 1593.173, 1682.268, 1723.018 (1717.640)	KLD: 7.994, 13.502, 17.191 (17.024)	Grad: 0.111, 0.181, 0.264
[Epoch  75 (40.14s)]	ELBO: 1585.510, 1669.091, 1706.373 (1700.200)	Log prob: 1593.500, 1682.584, 1723.549 (1717.424)	KLD: 7.990, 13.493, 17.177 (17.224)	Grad: 0.111, 0.181, 0.262
[Epoch  76 (39.16s)]	ELBO: 1585.566, 1669.044, 1706.188 (1700.926)	Log prob: 1593.554, 1682.545, 1723.387 (1718.301)	KLD: 7.989, 13.501, 17.199 (17.375)	Grad: 0.110, 0.179, 0.260
[Epoch  77 (41.11s)]	ELBO: 1585.992, 1669.362, 1706.521 (1700.099)	Log prob: 1593.970, 1682.856, 1723.717 (1716.933)	KLD: 7.978, 13.496, 17.195 (16.834)	Grad: 0.109, 0.179, 0.259
[Epoch  78 (42.05s)]	ELBO: 1585.994, 1669.214, 1706.354 (1699.708)	Log prob: 1593.997, 1682.747, 1723.577 (1716.882)	KLD: 8.004, 13.532, 17.224 (17.173)	Grad: 0.111, 0.180, 0.261
[Epoch  79 (40.69s)]	ELBO: 1586.455, 1669.720, 1706.861 (1700.477)	Log prob: 1594.455, 1683.231, 1724.070 (1717.462)	KLD: 7.999, 13.510, 17.208 (16.985)	Grad: 0.111, 0.181, 0.262
[Epoch  80 (36.21s)]	ELBO: 1586.252, 1669.533, 1706.668 (1700.663)	Log prob: 1594.248, 1683.042, 1723.882 (1717.761)	KLD: 7.997, 13.507, 17.215 (17.098)	Grad: 0.112, 0.182, 0.265
[Epoch  81 (35.98s)]	ELBO: 1586.756, 1670.009, 1707.098 (1700.742)	Log prob: 1594.765, 1683.521, 1724.296 (1718.000)	KLD: 8.008, 13.512, 17.199 (17.259)	Grad: 0.113, 0.183, 0.266
[Epoch  82 (35.73s)]	ELBO: 1587.098, 1670.168, 1707.245 (1701.374)	Log prob: 1595.106, 1683.695, 1724.466 (1718.543)	KLD: 8.008, 13.528, 17.222 (17.168)	Grad: 0.111, 0.181, 0.262
[Epoch  83 (37.44s)]	ELBO: 1587.419, 1670.368, 1707.486 (1699.512)	Log prob: 1595.439, 1683.907, 1724.727 (1716.815)	KLD: 8.020, 13.538, 17.242 (17.304)	Grad: 0.111, 0.181, 0.262
[Epoch  84 (34.92s)]	ELBO: 1587.523, 1670.499, 1707.512 (1701.562)	Log prob: 1595.526, 1684.022, 1724.722 (1718.928)	KLD: 8.002, 13.524, 17.210 (17.366)	Grad: 0.111, 0.180, 0.262
[Epoch  85 (35.46s)]	ELBO: 1587.766, 1670.718, 1707.779 (1701.059)	Log prob: 1595.780, 1684.245, 1725.011 (1718.279)	KLD: 8.015, 13.527, 17.233 (17.220)	Grad: 0.112, 0.182, 0.264
[Epoch  86 (34.67s)]	ELBO: 1587.600, 1670.417, 1707.511 (1701.014)	Log prob: 1595.615, 1683.956, 1724.745 (1718.486)	KLD: 8.016, 13.540, 17.233 (17.472)	Grad: 0.114, 0.185, 0.268
[Epoch  87 (34.09s)]	ELBO: 1588.225, 1671.061, 1708.046 (1700.383)	Log prob: 1596.235, 1684.580, 1725.267 (1717.701)	KLD: 8.010, 13.520, 17.221 (17.319)	Grad: 0.112, 0.181, 0.263
[Epoch  88 (37.43s)]	ELBO: 1588.442, 1671.106, 1708.168 (1700.218)	Log prob: 1596.448, 1684.633, 1725.385 (1717.680)	KLD: 8.008, 13.527, 17.217 (17.462)	Grad: 0.113, 0.183, 0.266
[Epoch  89 (36.17s)]	ELBO: 1588.180, 1670.827, 1707.915 (1701.249)	Log prob: 1596.192, 1684.367, 1725.143 (1718.467)	KLD: 8.012, 13.541, 17.229 (17.218)	Grad: 0.112, 0.181, 0.263
[Epoch  90 (34.37s)]	ELBO: 1588.838, 1671.346, 1708.412 (1702.056)	Log prob: 1596.869, 1684.900, 1725.653 (1719.240)	KLD: 8.030, 13.553, 17.241 (17.183)	Grad: 0.111, 0.180, 0.261
[Epoch  91 (32.13s)]	ELBO: 1588.771, 1671.319, 1708.244 (1701.825)	Log prob: 1596.771, 1684.831, 1725.446 (1718.876)	KLD: 8.000, 13.512, 17.202 (17.052)	Grad: 0.114, 0.185, 0.269
[Epoch  92 (30.49s)]	ELBO: 1589.227, 1671.709, 1708.729 (1699.898)	Log prob: 1597.259, 1685.273, 1725.986 (1716.698)	KLD: 8.033, 13.564, 17.256 (16.800)	Grad: 0.113, 0.181, 0.263
[Epoch  93 (30.69s)]	ELBO: 1589.349, 1671.715, 1708.680 (1700.941)	Log prob: 1597.379, 1685.260, 1725.911 (1718.058)	KLD: 8.028, 13.543, 17.232 (17.117)	Grad: 0.111, 0.180, 0.261
[Epoch  94 (30.94s)]	ELBO: 1589.304, 1671.713, 1708.627 (1701.443)	Log prob: 1597.335, 1685.267, 1725.868 (1718.390)	KLD: 8.031, 13.554, 17.241 (16.948)	Grad: 0.116, 0.187, 0.271
[Epoch  95 (31.05s)]	ELBO: 1589.123, 1671.378, 1708.231 (1702.001)	Log prob: 1597.142, 1684.895, 1725.419 (1719.173)	KLD: 8.020, 13.517, 17.188 (17.171)	Grad: 0.116, 0.189, 0.275
[Epoch  96 (32.04s)]	ELBO: 1589.823, 1672.029, 1708.960 (1701.512)	Log prob: 1597.850, 1685.566, 1726.198 (1718.507)	KLD: 8.027, 13.537, 17.237 (16.996)	Grad: 0.113, 0.183, 0.265
[Epoch  97 (34.63s)]	ELBO: 1590.067, 1672.298, 1709.270 (1701.849)	Log prob: 1598.101, 1685.846, 1726.511 (1718.990)	KLD: 8.036, 13.549, 17.241 (17.141)	Grad: 0.112, 0.181, 0.262
[Epoch  98 (33.87s)]	ELBO: 1590.083, 1672.203, 1709.119 (1701.370)	Log prob: 1598.113, 1685.763, 1726.374 (1718.481)	KLD: 8.030, 13.561, 17.256 (17.111)	Grad: 0.114, 0.185, 0.267
[Epoch  99 (30.63s)]	ELBO: 1590.404, 1672.411, 1709.297 (1701.337)	Log prob: 1598.424, 1685.943, 1726.522 (1718.589)	KLD: 8.020, 13.533, 17.224 (17.252)	Grad: 0.114, 0.184, 0.267
No improvement after 10 epochs...
Best epoch(s): [90]	Training time(s): 4048.09s (4048.09s)	Best ELBO: 1709.297 (1702.056)	Best log prob: 1726.522 (1719.240)
Avg. mu: -0.123, -0.043, 0.085, 0.048, -0.058, 0.063
Avg. var: 0.001, 0.001, 0.006, 0.006, 0.039, 0.034
Max. mu: 4.335, 5.525, 4.403, 4.405, 5.055, 4.691
Max. var: 0.023, 0.044, 0.130, 0.041, 0.353, 0.283
Min. mu: -5.216, -6.301, -4.175, -4.122, -4.626, -3.922
Min. var: 0.000, 0.000, 0.000, 0.001, 0.004, 0.006
Cov. mu:
[[1.906 0.013 -0.020 0.032 -0.047 0.001]
 [0.013 1.994 -0.004 -0.070 -0.062 0.017]
 [-0.020 -0.004 0.987 0.034 -0.052 0.058]
 [0.032 -0.070 0.034 0.970 0.026 0.018]
 [-0.047 -0.062 -0.052 0.026 1.268 -0.082]
 [0.001 0.017 0.058 0.018 -0.082 1.020]]
