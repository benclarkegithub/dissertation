Encoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Encoder                                  --
├─Linear: 1-1                            76,930
├─Linear: 1-2                            9,702
=================================================================
Total params: 86,632
Trainable params: 86,632
Non-trainable params: 0
=================================================================
Encoder to Latent
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            99
├─Linear: 1-2                            99
=================================================================
Total params: 198
Trainable params: 198
Non-trainable params: 0
=================================================================
Latents to Decoder 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            196
=================================================================
Total params: 196
Trainable params: 196
Non-trainable params: 0
=================================================================
Latents to Decoder 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            196
=================================================================
Total params: 196
Trainable params: 196
Non-trainable params: 0
=================================================================
Decoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Decoder                                  --
├─Linear: 1-1                            9,702
├─Linear: 1-2                            77,616
=================================================================
Total params: 87,318
Trainable params: 87,318
Non-trainable params: 0
=================================================================
[Epoch   1 (23.71s)]	ELBO: 2.751, -10128.842 (235.790)	Log prob: 2.802, -10128.741 (235.888)	KLD: 0.051, 0.048 (0.098)	Grad: 16801.061, 2601716217.058
[Epoch   2 (25.34s)]	ELBO: 234.732, 398.326 (587.928)	Log prob: 234.776, 398.414 (588.010)	KLD: 0.044, 0.044 (0.082)	Grad: 38481.402, 54254.042
[Epoch   3 (23.12s)]	ELBO: 523.498, 702.865 (762.610)	Log prob: 523.530, 702.933 (762.655)	KLD: 0.033, 0.035 (0.045)	Grad: 7120.238, 61095.438
[Epoch   4 (22.78s)]	ELBO: 736.412, 943.508 (1007.842)	Log prob: 736.436, 943.556 (1007.879)	KLD: 0.024, 0.024 (0.036)	Grad: 2659.111, 17193.013
[Epoch   5 (23.10s)]	ELBO: 834.735, 928.968 (-1691.700)	Log prob: 834.751, 929.004 (-1691.655)	KLD: 0.016, 0.019 (0.045)	Grad: 82078.405, 382894.813
[Epoch   6 (24.10s)]	ELBO: 931.139, 1051.622 (546.517)	Log prob: 931.154, 1051.657 (546.550)	KLD: 0.015, 0.020 (0.033)	Grad: 63274.864, 262991.699
[Epoch   7 (25.02s)]	ELBO: 896.105, 888.742 (1169.973)	Log prob: 896.118, 888.773 (1170.029)	KLD: 0.013, 0.017 (0.055)	Grad: 1374510.075, 5466501.265
[Epoch   8 (24.47s)]	ELBO: 1082.496, -999.231 (1015.266)	Log prob: 1082.515, -999.189 (1015.298)	KLD: 0.020, 0.022 (0.032)	Grad: 20214.345, 453290830.298
[Epoch   9 (24.44s)]	ELBO: 1019.253, 1027.025 (1141.851)	Log prob: 1019.268, 1027.060 (1141.884)	KLD: 0.015, 0.021 (0.033)	Grad: 631658.201, 939861.599
[Epoch  10 (24.57s)]	ELBO: 1180.939, 1199.588 (1085.666)	Log prob: 1180.955, 1199.621 (1085.688)	KLD: 0.016, 0.017 (0.022)	Grad: 5844.844, 14511.391
[Epoch  11 (25.91s)]	ELBO: 1142.064, 1234.754 (1256.284)	Log prob: 1142.076, 1234.778 (1256.307)	KLD: 0.011, 0.012 (0.023)	Grad: 5526699.047, 5425898.979
[Epoch  12 (25.58s)]	ELBO: 1230.588, 1218.766 (1266.316)	Log prob: 1230.600, 1218.789 (1266.343)	KLD: 0.012, 0.011 (0.027)	Grad: 33208.276, 318196.090
[Epoch  13 (25.17s)]	ELBO: 1256.371, 1171.240 (1238.062)	Log prob: 1256.383, 1171.266 (1238.082)	KLD: 0.012, 0.013 (0.020)	Grad: 33589.745, 1356070.713
[Epoch  14 (31.59s)]	ELBO: 1276.526, 1265.612 (1202.187)	Log prob: 1276.538, 1265.632 (1202.210)	KLD: 0.012, 0.008 (0.022)	Grad: 13101.154, 52466.806
[Epoch  15 (26.08s)]	ELBO: 1286.705, 1146.901 (1255.388)	Log prob: 1286.716, 1146.921 (1255.405)	KLD: 0.010, 0.010 (0.017)	Grad: 3886.765, 2570933.401
[Epoch  16 (29.28s)]	ELBO: 1295.182, 1288.286 (1297.035)	Log prob: 1295.197, 1288.311 (1297.066)	KLD: 0.016, 0.010 (0.031)	Grad: 1397.162, 12474.481
[Epoch  17 (27.71s)]	ELBO: 1299.099, 1295.708 (1283.064)	Log prob: 1299.120, 1295.740 (1283.102)	KLD: 0.021, 0.011 (0.038)	Grad: 2136.797, 8897.272
[Epoch  18 (26.50s)]	ELBO: 1303.171, 1297.305 (1309.523)	Log prob: 1303.209, 1297.355 (1309.586)	KLD: 0.038, 0.013 (0.063)	Grad: 8355.771, 29009.609
[Epoch  19 (25.08s)]	ELBO: 1308.289, 1286.940 (1312.082)	Log prob: 1308.357, 1287.023 (1312.186)	KLD: 0.068, 0.016 (0.105)	Grad: 18868.464, 90362.471
[Epoch  20 (24.52s)]	ELBO: 1216.363, 1230.833 (1310.246)	Log prob: 1216.467, 1230.949 (1310.374)	KLD: 0.104, 0.012 (0.128)	Grad: 6180702.823, 7358646.983
[Epoch  21 (25.09s)]	ELBO: 1317.273, 1309.038 (1310.299)	Log prob: 1317.417, 1309.190 (1310.480)	KLD: 0.144, 0.007 (0.181)	Grad: 650.232, 9264.712
[Epoch  22 (25.60s)]	ELBO: 1321.393, 1303.927 (1316.668)	Log prob: 1321.605, 1304.145 (1316.915)	KLD: 0.212, 0.006 (0.247)	Grad: 789.425, 573173.577
[Epoch  23 (26.87s)]	ELBO: 1323.260, 1316.214 (1302.947)	Log prob: 1323.540, 1316.499 (1303.315)	KLD: 0.280, 0.005 (0.368)	Grad: 309.204, 4118.693
[Epoch  24 (24.58s)]	ELBO: 1324.784, 1320.569 (1322.256)	Log prob: 1325.212, 1321.015 (1322.787)	KLD: 0.428, 0.019 (0.531)	Grad: 283.544, 1753.987
[Epoch  25 (25.58s)]	ELBO: 1325.828, 1316.066 (1324.596)	Log prob: 1326.363, 1316.612 (1325.223)	KLD: 0.535, 0.011 (0.628)	Grad: 208.362, 58293.532
[Epoch  26 (25.44s)]	ELBO: 1326.622, 1323.987 (1321.747)	Log prob: 1327.347, 1324.752 (1322.630)	KLD: 0.725, 0.039 (0.883)	Grad: 312.171, 1110.706
[Epoch  27 (25.89s)]	ELBO: 1327.252, 1321.624 (1326.136)	Log prob: 1328.034, 1322.452 (1327.055)	KLD: 0.782, 0.045 (0.919)	Grad: 720.039, 8336.250
[Epoch  28 (26.88s)]	ELBO: 1326.830, 1324.075 (1312.740)	Log prob: 1327.820, 1325.146 (1313.975)	KLD: 0.989, 0.082 (1.234)	Grad: 14376.473, 17261.199
[Epoch  29 (26.70s)]	ELBO: 1328.061, 1325.540 (1328.765)	Log prob: 1329.211, 1326.822 (1330.074)	KLD: 1.150, 0.131 (1.309)	Grad: 89.554, 1711.378
[Epoch  30 (25.34s)]	ELBO: 1328.695, 1319.765 (1314.825)	Log prob: 1329.666, 1320.883 (1315.941)	KLD: 0.971, 0.147 (1.116)	Grad: 43.421, 52848.281
[Epoch  31 (27.05s)]	ELBO: 1329.727, 1324.161 (1326.206)	Log prob: 1330.586, 1325.210 (1327.160)	KLD: 0.859, 0.190 (0.954)	Grad: 31.599, 6209.539
[Epoch  32 (26.32s)]	ELBO: 1331.135, 1332.010 (1330.483)	Log prob: 1331.858, 1333.016 (1331.590)	KLD: 0.723, 0.283 (1.108)	Grad: 495.185, 1631.383
[Epoch  33 (26.20s)]	ELBO: 1332.365, 1324.696 (1332.183)	Log prob: 1333.097, 1325.804 (1333.184)	KLD: 0.731, 0.377 (1.000)	Grad: 159.168, 102479.592
[Epoch  34 (26.52s)]	ELBO: 1331.436, 1327.169 (1229.002)	Log prob: 1332.128, 1328.301 (1230.044)	KLD: 0.692, 0.440 (1.042)	Grad: 643.085, 15673.385
[Epoch  35 (26.34s)]	ELBO: 1333.241, 1265.790 (1334.660)	Log prob: 1333.778, 1266.813 (1335.744)	KLD: 0.538, 0.485 (1.084)	Grad: 15554.211, 1941528.671
[Epoch  36 (26.70s)]	ELBO: 1334.452, 1322.900 (1334.170)	Log prob: 1335.175, 1324.166 (1335.471)	KLD: 0.723, 0.543 (1.301)	Grad: 3082.298, 12587.847
[Epoch  37 (26.07s)]	ELBO: 1337.901, 1330.692 (1332.136)	Log prob: 1338.642, 1332.082 (1333.372)	KLD: 0.741, 0.649 (1.236)	Grad: 428.088, 32281.808
[Epoch  38 (24.92s)]	ELBO: 1336.929, 1326.601 (1332.965)	Log prob: 1337.561, 1327.841 (1334.165)	KLD: 0.632, 0.609 (1.200)	Grad: 1537.007, 45034.225
[Epoch  39 (25.91s)]	ELBO: 1334.705, 1327.473 (1326.295)	Log prob: 1335.313, 1328.678 (1327.563)	KLD: 0.607, 0.599 (1.268)	Grad: 20477.550, 25396.764
[Epoch  40 (27.12s)]	ELBO: 1339.593, 1293.716 (1281.362)	Log prob: 1340.223, 1294.931 (1282.654)	KLD: 0.630, 0.585 (1.292)	Grad: 706.299, 47895.622
[Epoch  41 (24.92s)]	ELBO: 1341.045, 1332.700 (1339.638)	Log prob: 1341.663, 1333.978 (1340.745)	KLD: 0.618, 0.660 (1.107)	Grad: 596.012, 13644.264
[Epoch  42 (23.39s)]	ELBO: 1340.403, 1330.221 (1335.164)	Log prob: 1340.974, 1331.434 (1336.542)	KLD: 0.571, 0.643 (1.378)	Grad: 1243.890, 29783.516
[Epoch  43 (23.66s)]	ELBO: 1330.437, 1327.724 (1328.366)	Log prob: 1331.235, 1329.256 (1329.961)	KLD: 0.798, 0.733 (1.595)	Grad: 16440.693, 25372.593
[Epoch  44 (20.29s)]	ELBO: 1340.235, 1280.333 (1345.523)	Log prob: 1340.987, 1281.780 (1346.765)	KLD: 0.752, 0.694 (1.241)	Grad: 11862.422, 176346.060
[Epoch  45 (19.49s)]	ELBO: 1334.407, 1333.287 (1343.544)	Log prob: 1335.017, 1334.551 (1344.803)	KLD: 0.610, 0.653 (1.259)	Grad: 4389.296, 92488.172
[Epoch  46 (18.97s)]	ELBO: 1342.789, 1332.431 (1243.331)	Log prob: 1343.477, 1333.839 (1244.648)	KLD: 0.688, 0.720 (1.317)	Grad: 1038.816, 52199.416
[Epoch  47 (18.19s)]	ELBO: 1043.891, 1329.064 (1318.301)	Log prob: 1044.479, 1330.302 (1319.536)	KLD: 0.589, 0.650 (1.235)	Grad: 2856411.491, 2858719.658
[Epoch  48 (19.26s)]	ELBO: 1334.669, 882.740 (1344.368)	Log prob: 1335.264, 884.036 (1345.621)	KLD: 0.595, 0.701 (1.253)	Grad: 6665.793, 9043424.330
[Epoch  49 (19.62s)]	ELBO: 1341.309, 1273.170 (1276.750)	Log prob: 1341.918, 1274.487 (1277.970)	KLD: 0.609, 0.708 (1.219)	Grad: 1817.392, 7533673.147
[Epoch  50 (18.37s)]	ELBO: 1343.544, 1332.575 (1343.763)	Log prob: 1344.164, 1333.853 (1345.083)	KLD: 0.621, 0.657 (1.320)	Grad: 1362.049, 26545.245
Best epoch(s): [44]	Training time(s): 1235.36s (1235.36s)	Best ELBO: 1333.287 (1345.523)	Best log prob: 1334.551 (1346.765)
Avg. z: 1.507, -18.471
Max. z: 31737.645, 13587.554
Min. z: -36346.410, -178483.750
Cov. z:
[[387519.458 -2645.501]
 [-2645.501 3410825.510]]
