=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
VAE                                      --
├─Encoder: 1-1                           --
│    └─Conv2d: 2-1                       448
│    └─Conv2d: 2-2                       2,080
│    └─Conv2d: 2-3                       9,248
│    └─Conv2d: 2-4                       8,256
│    └─Conv2d: 2-5                       36,928
│    └─Conv2d: 2-6                       32,896
│    └─Linear: 2-7                       1,049,088
│    └─Linear: 2-8                       262,656
├─Decoder: 1-2                           --
│    └─Linear: 2-9                       262,656
│    └─Linear: 2-10                      1,050,624
│    └─ConvTranspose2d: 2-11             32,832
│    └─ConvTranspose2d: 2-12             36,928
│    └─ConvTranspose2d: 2-13             8,224
│    └─ConvTranspose2d: 2-14             9,248
│    └─ConvTranspose2d: 2-15             2,064
│    └─ConvTranspose2d: 2-16             435
=================================================================
Total params: 2,804,611
Trainable params: 2,804,611
Non-trainable params: 0
=================================================================
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
VAE                                      --
├─Encoder: 1-1                           --
│    └─Conv2d: 2-1                       448
│    └─Conv2d: 2-2                       2,080
│    └─Conv2d: 2-3                       9,248
│    └─Conv2d: 2-4                       8,256
│    └─Conv2d: 2-5                       36,928
│    └─Conv2d: 2-6                       32,896
│    └─Linear: 2-7                       1,049,088
│    └─Linear: 2-8                       262,656
├─Decoder: 1-2                           --
│    └─Linear: 2-9                       262,656
│    └─Linear: 2-10                      1,050,624
│    └─ConvTranspose2d: 2-11             32,832
│    └─ConvTranspose2d: 2-12             36,928
│    └─ConvTranspose2d: 2-13             8,224
│    └─ConvTranspose2d: 2-14             9,248
│    └─ConvTranspose2d: 2-15             2,064
│    └─ConvTranspose2d: 2-16             435
=================================================================
Total params: 2,804,611
Trainable params: 2,804,611
Non-trainable params: 0
=================================================================
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
VAE                                      --
├─Encoder: 1-1                           --
│    └─Conv2d: 2-1                       448
│    └─Conv2d: 2-2                       2,080
│    └─Conv2d: 2-3                       9,248
│    └─Conv2d: 2-4                       8,256
│    └─Conv2d: 2-5                       36,928
│    └─Conv2d: 2-6                       32,896
│    └─Linear: 2-7                       1,049,088
│    └─Linear: 2-8                       262,656
├─Decoder: 1-2                           --
│    └─Linear: 2-9                       262,656
│    └─Linear: 2-10                      1,050,624
│    └─ConvTranspose2d: 2-11             32,832
│    └─ConvTranspose2d: 2-12             36,928
│    └─ConvTranspose2d: 2-13             8,224
│    └─ConvTranspose2d: 2-14             9,248
│    └─ConvTranspose2d: 2-15             2,064
│    └─ConvTranspose2d: 2-16             435
=================================================================
Total params: 2,804,611
Trainable params: 2,804,611
Non-trainable params: 0
=================================================================
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
VAE                                      --
├─Encoder: 1-1                           --
│    └─Conv2d: 2-1                       448
│    └─Conv2d: 2-2                       2,080
│    └─Conv2d: 2-3                       9,248
│    └─Conv2d: 2-4                       8,256
│    └─Conv2d: 2-5                       36,928
│    └─Conv2d: 2-6                       32,896
│    └─Linear: 2-7                       1,049,088
│    └─Linear: 2-8                       262,656
├─Decoder: 1-2                           --
│    └─Linear: 2-9                       262,656
│    └─Linear: 2-10                      1,050,624
│    └─ConvTranspose2d: 2-11             32,832
│    └─ConvTranspose2d: 2-12             36,928
│    └─ConvTranspose2d: 2-13             8,224
│    └─ConvTranspose2d: 2-14             9,248
│    └─ConvTranspose2d: 2-15             2,064
│    └─ConvTranspose2d: 2-16             435
=================================================================
Total params: 2,804,611
Trainable params: 2,804,611
Non-trainable params: 0
=================================================================
[Epoch   1 (114.33s)]	ELBO: -23502.801 (-15877.589)	Log prob: -23308.625 (-15622.048)	KLD: 194.176 (255.542)
[Epoch   2 (121.49s)]	ELBO: -14676.817 (-13857.041)	Log prob: -14466.904 (-13681.820)	KLD: 209.913 (175.221)
[Epoch   3 (124.39s)]	ELBO: -13163.177 (-12337.258)	Log prob: -12975.974 (-12130.971)	KLD: 187.202 (206.287)
[Epoch   4 (131.24s)]	ELBO: -11619.058 (-11220.729)	Log prob: -11410.274 (-11013.667)	KLD: 208.784 (207.062)
[Epoch   5 (123.98s)]	ELBO: -10468.113 (-9260.604)	Log prob: -10236.133 (-9025.309)	KLD: 231.981 (235.295)
[Epoch   6 (126.13s)]	ELBO: -8831.700 (-8366.451)	Log prob: -8584.996 (-8117.577)	KLD: 246.704 (248.874)
[Epoch   7 (129.28s)]	ELBO: -7699.692 (-7708.456)	Log prob: -7446.836 (-7462.006)	KLD: 252.855 (246.450)
[Epoch   8 (131.24s)]	ELBO: -7387.481 (-7223.136)	Log prob: -7138.249 (-6991.095)	KLD: 249.232 (232.041)
[Epoch   9 (128.43s)]	ELBO: -7202.940 (-7154.507)	Log prob: -6957.892 (-6895.078)	KLD: 245.048 (259.429)
[Epoch  10 (128.24s)]	ELBO: -6732.899 (-6535.932)	Log prob: -6479.646 (-6284.849)	KLD: 253.252 (251.083)
[Epoch  11 (125.93s)]	ELBO: -6288.497 (-6508.934)	Log prob: -6031.118 (-6252.499)	KLD: 257.378 (256.435)
[Epoch  12 (129.77s)]	ELBO: -6135.933 (-6033.804)	Log prob: -5880.276 (-5778.977)	KLD: 255.657 (254.827)
[Epoch  13 (129.48s)]	ELBO: -6032.196 (-7128.305)	Log prob: -5781.839 (-6858.910)	KLD: 250.357 (269.395)
[Epoch  14 (128.77s)]	ELBO: -5961.988 (-5826.206)	Log prob: -5710.439 (-5575.931)	KLD: 251.549 (250.275)
[Epoch  15 (135.37s)]	ELBO: -5833.893 (-5763.734)	Log prob: -5579.712 (-5501.835)	KLD: 254.180 (261.899)
[Epoch  16 (123.73s)]	ELBO: -5584.386 (-5425.814)	Log prob: -5325.458 (-5166.269)	KLD: 258.928 (259.545)
[Epoch  17 (126.03s)]	ELBO: -5327.874 (-5581.593)	Log prob: -5060.004 (-5318.254)	KLD: 267.870 (263.338)
[Epoch  18 (133.00s)]	ELBO: -4907.477 (-5009.770)	Log prob: -4639.623 (-4741.505)	KLD: 267.853 (268.265)
[Epoch  19 (126.00s)]	ELBO: -4667.734 (-4685.963)	Log prob: -4397.167 (-4417.062)	KLD: 270.567 (268.901)
[Epoch  20 (123.58s)]	ELBO: -4529.451 (-4567.988)	Log prob: -4262.143 (-4305.277)	KLD: 267.308 (262.711)
[Epoch  21 (128.07s)]	ELBO: -4431.431 (-4309.227)	Log prob: -4161.147 (-4039.216)	KLD: 270.284 (270.011)
[Epoch  22 (126.42s)]	ELBO: -4151.323 (-4084.188)	Log prob: -3874.496 (-3797.976)	KLD: 276.827 (286.212)
[Epoch  23 (122.81s)]	ELBO: -3957.889 (-4815.167)	Log prob: -3683.170 (-4546.824)	KLD: 274.718 (268.343)
[Epoch  24 (126.73s)]	ELBO: -3930.288 (-4069.680)	Log prob: -3654.673 (-3793.377)	KLD: 275.614 (276.303)
[Epoch  25 (121.11s)]	ELBO: -3839.529 (-3901.270)	Log prob: -3566.069 (-3632.019)	KLD: 273.460 (269.251)
[Epoch  26 (120.09s)]	ELBO: -3779.147 (-3736.956)	Log prob: -3505.804 (-3468.856)	KLD: 273.343 (268.099)
[Epoch  27 (124.14s)]	ELBO: -3638.814 (-3814.231)	Log prob: -3362.843 (-3535.401)	KLD: 275.970 (278.830)
[Epoch  28 (122.15s)]	ELBO: -3487.164 (-3433.740)	Log prob: -3204.752 (-3153.906)	KLD: 282.412 (279.834)
[Epoch  29 (126.37s)]	ELBO: -3346.658 (-3382.978)	Log prob: -3067.130 (-3107.210)	KLD: 279.529 (275.768)
[Epoch  30 (124.51s)]	ELBO: -3298.589 (-3367.733)	Log prob: -3018.857 (-3085.723)	KLD: 279.732 (282.010)
[Epoch  31 (123.01s)]	ELBO: -3186.285 (-3304.284)	Log prob: -2904.549 (-3025.021)	KLD: 281.736 (279.263)
[Epoch  32 (122.04s)]	ELBO: -3089.326 (-3119.314)	Log prob: -2809.181 (-2839.235)	KLD: 280.146 (280.079)
[Epoch  33 (124.29s)]	ELBO: -3044.617 (-2990.840)	Log prob: -2764.546 (-2710.521)	KLD: 280.071 (280.319)
[Epoch  34 (125.29s)]	ELBO: -3003.225 (-3038.472)	Log prob: -2724.273 (-2759.592)	KLD: 278.952 (278.880)
[Epoch  35 (126.82s)]	ELBO: -2933.434 (-3283.207)	Log prob: -2654.020 (-3003.518)	KLD: 279.414 (279.689)
[Epoch  36 (124.06s)]	ELBO: -2877.365 (-2891.937)	Log prob: -2594.533 (-2614.849)	KLD: 282.833 (277.087)
[Epoch  37 (123.94s)]	ELBO: -2797.695 (-2843.647)	Log prob: -2516.360 (-2562.088)	KLD: 281.335 (281.559)
[Epoch  38 (124.39s)]	ELBO: -2772.620 (-2939.496)	Log prob: -2491.596 (-2645.637)	KLD: 281.024 (293.859)
[Epoch  39 (125.15s)]	ELBO: -2699.939 (-2977.694)	Log prob: -2419.322 (-2697.449)	KLD: 280.617 (280.244)
[Epoch  40 (122.20s)]	ELBO: -2647.006 (-2761.819)	Log prob: -2363.489 (-2474.672)	KLD: 283.517 (287.148)
[Epoch  41 (127.22s)]	ELBO: -2580.543 (-2720.966)	Log prob: -2296.449 (-2438.274)	KLD: 284.094 (282.692)
[Epoch  42 (130.51s)]	ELBO: -2503.926 (-2906.524)	Log prob: -2219.609 (-2622.315)	KLD: 284.317 (284.209)
[Epoch  43 (124.79s)]	ELBO: -2441.598 (-2630.070)	Log prob: -2157.214 (-2344.734)	KLD: 284.384 (285.335)
[Epoch  44 (123.34s)]	ELBO: -2410.810 (-2510.594)	Log prob: -2126.349 (-2226.246)	KLD: 284.460 (284.348)
[Epoch  45 (129.15s)]	ELBO: -2388.434 (-2727.693)	Log prob: -2104.725 (-2445.516)	KLD: 283.709 (282.177)
[Epoch  46 (121.47s)]	ELBO: -2337.766 (-2411.852)	Log prob: -2054.016 (-2127.448)	KLD: 283.750 (284.404)
[Epoch  47 (121.00s)]	ELBO: -2296.782 (-2427.491)	Log prob: -2011.524 (-2143.302)	KLD: 285.258 (284.189)
[Epoch  48 (126.41s)]	ELBO: -2237.275 (-2454.134)	Log prob: -1951.686 (-2168.212)	KLD: 285.589 (285.922)
[Epoch  49 (126.51s)]	ELBO: -2208.882 (-2690.820)	Log prob: -1923.437 (-2411.446)	KLD: 285.444 (279.374)
[Epoch  50 (128.58s)]	ELBO: -2175.407 (-2460.721)	Log prob: -1889.836 (-2172.975)	KLD: 285.571 (287.746)
[Epoch  51 (124.82s)]	ELBO: -2136.225 (-2329.498)	Log prob: -1851.472 (-2045.949)	KLD: 284.753 (283.549)
[Epoch  52 (126.05s)]	ELBO: -2090.773 (-2572.657)	Log prob: -1804.879 (-2278.586)	KLD: 285.894 (294.071)
[Epoch  53 (126.04s)]	ELBO: -2032.927 (-2016.172)	Log prob: -1745.004 (-1729.404)	KLD: 287.923 (286.768)
[Epoch  54 (126.34s)]	ELBO: -1968.963 (-2373.985)	Log prob: -1679.781 (-2086.463)	KLD: 289.182 (287.521)
[Epoch  55 (128.08s)]	ELBO: -1875.218 (-1976.688)	Log prob: -1585.071 (-1686.943)	KLD: 290.147 (289.745)
[Epoch  56 (130.87s)]	ELBO: -1808.877 (-1892.131)	Log prob: -1516.789 (-1606.479)	KLD: 292.088 (285.652)
[Epoch  57 (132.23s)]	ELBO: -1733.057 (-1911.854)	Log prob: -1443.277 (-1624.175)	KLD: 289.780 (287.679)
[Epoch  58 (129.40s)]	ELBO: -1731.585 (-2077.414)	Log prob: -1440.183 (-1791.999)	KLD: 291.402 (285.415)
[Epoch  59 (135.16s)]	ELBO: -1666.873 (-2171.851)	Log prob: -1377.514 (-1876.998)	KLD: 289.360 (294.853)
[Epoch  60 (129.32s)]	ELBO: -1651.113 (-1783.422)	Log prob: -1360.604 (-1490.608)	KLD: 290.509 (292.815)
[Epoch  61 (136.77s)]	ELBO: -1615.187 (-1879.517)	Log prob: -1323.803 (-1591.210)	KLD: 291.384 (288.308)
[Epoch  62 (138.95s)]	ELBO: -1567.759 (-1830.099)	Log prob: -1275.140 (-1537.022)	KLD: 292.619 (293.077)
[Epoch  63 (155.03s)]	ELBO: -1530.907 (-1687.579)	Log prob: -1238.326 (-1399.732)	KLD: 292.581 (287.848)
[Epoch  64 (165.42s)]	ELBO: -1511.267 (-1862.122)	Log prob: -1219.593 (-1569.727)	KLD: 291.674 (292.394)
[Epoch  65 (166.10s)]	ELBO: -1480.057 (-2247.215)	Log prob: -1188.777 (-1957.220)	KLD: 291.280 (289.995)
[Epoch  66 (172.86s)]	ELBO: -1480.919 (-1715.055)	Log prob: -1188.974 (-1420.548)	KLD: 291.945 (294.507)
[Epoch  67 (167.74s)]	ELBO: -1467.244 (-1931.221)	Log prob: -1175.939 (-1647.608)	KLD: 291.305 (283.614)
[Epoch  68 (163.20s)]	ELBO: -1432.440 (-1828.590)	Log prob: -1141.766 (-1535.399)	KLD: 290.673 (293.190)
[Epoch  69 (167.09s)]	ELBO: -1429.583 (-1675.565)	Log prob: -1138.419 (-1386.374)	KLD: 291.164 (289.191)
[Epoch  70 (164.77s)]	ELBO: -1416.596 (-1705.666)	Log prob: -1126.039 (-1411.519)	KLD: 290.557 (294.147)
[Epoch  71 (163.40s)]	ELBO: -1415.450 (-1700.462)	Log prob: -1124.161 (-1401.791)	KLD: 291.289 (298.671)
[Epoch  72 (163.36s)]	ELBO: -1407.146 (-2587.692)	Log prob: -1116.176 (-2295.589)	KLD: 290.970 (292.103)
[Epoch  73 (163.05s)]	ELBO: -1387.434 (-1648.116)	Log prob: -1096.864 (-1353.694)	KLD: 290.570 (294.422)
[Epoch  74 (162.19s)]	ELBO: -1374.967 (-1713.998)	Log prob: -1084.147 (-1425.126)	KLD: 290.819 (288.873)
[Epoch  75 (162.88s)]	ELBO: -1359.854 (-1562.681)	Log prob: -1068.773 (-1272.386)	KLD: 291.081 (290.295)
[Epoch  76 (161.38s)]	ELBO: -1346.069 (-1746.822)	Log prob: -1054.550 (-1455.132)	KLD: 291.520 (291.690)
[Epoch  77 (165.69s)]	ELBO: -1328.013 (-1858.773)	Log prob: -1035.544 (-1559.362)	KLD: 292.469 (299.411)
[Epoch  78 (166.36s)]	ELBO: -1260.756 (-1885.530)	Log prob: -968.637 (-1595.226)	KLD: 292.119 (290.304)
[Epoch  79 (160.06s)]	ELBO: -1248.348 (-1593.767)	Log prob: -954.970 (-1301.806)	KLD: 293.378 (291.960)
[Epoch  80 (166.12s)]	ELBO: -1209.981 (-1431.848)	Log prob: -916.577 (-1144.702)	KLD: 293.404 (287.146)
[Epoch  81 (163.42s)]	ELBO: -1180.721 (-1528.411)	Log prob: -887.054 (-1240.030)	KLD: 293.667 (288.381)
[Epoch  82 (162.35s)]	ELBO: -1167.845 (-1361.427)	Log prob: -874.624 (-1070.046)	KLD: 293.222 (291.381)
[Epoch  83 (165.89s)]	ELBO: -1151.441 (-1459.840)	Log prob: -857.848 (-1165.666)	KLD: 293.593 (294.174)
[Epoch  84 (161.17s)]	ELBO: -1130.932 (-1333.495)	Log prob: -837.619 (-1040.136)	KLD: 293.314 (293.359)
[Epoch  85 (162.77s)]	ELBO: -1101.605 (-1510.736)	Log prob: -808.173 (-1214.454)	KLD: 293.433 (296.282)
[Epoch  86 (165.01s)]	ELBO: -1075.038 (-1604.973)	Log prob: -781.227 (-1307.848)	KLD: 293.811 (297.124)
[Epoch  87 (162.03s)]	ELBO: -1048.376 (-1497.098)	Log prob: -753.223 (-1202.332)	KLD: 295.152 (294.766)
[Epoch  88 (165.09s)]	ELBO: -1024.266 (-1269.107)	Log prob: -729.599 (-977.718)	KLD: 294.667 (291.389)
[Epoch  89 (162.98s)]	ELBO: -994.181 (-1216.231)	Log prob: -699.650 (-925.658)	KLD: 294.531 (290.574)
[Epoch  90 (163.07s)]	ELBO: -999.031 (-1297.855)	Log prob: -703.764 (-1004.631)	KLD: 295.267 (293.224)
[Epoch  91 (165.47s)]	ELBO: -984.235 (-1323.847)	Log prob: -689.174 (-1026.351)	KLD: 295.061 (297.497)
[Epoch  92 (163.93s)]	ELBO: -948.757 (-1198.439)	Log prob: -653.390 (-904.055)	KLD: 295.367 (294.384)
[Epoch  93 (160.95s)]	ELBO: -929.467 (-1332.041)	Log prob: -633.931 (-1034.254)	KLD: 295.537 (297.787)
[Epoch  94 (164.70s)]	ELBO: -921.810 (-1285.543)	Log prob: -625.433 (-985.710)	KLD: 296.377 (299.833)
[Epoch  95 (163.61s)]	ELBO: -889.420 (-1117.721)	Log prob: -593.083 (-821.716)	KLD: 296.336 (296.005)
[Epoch  96 (164.32s)]	ELBO: -873.303 (-1142.369)	Log prob: -577.622 (-845.503)	KLD: 295.682 (296.866)
[Epoch  97 (162.16s)]	ELBO: -855.876 (-1130.876)	Log prob: -560.425 (-830.560)	KLD: 295.451 (300.316)
[Epoch  98 (164.35s)]	ELBO: -842.281 (-1425.249)	Log prob: -546.393 (-1129.221)	KLD: 295.888 (296.028)
[Epoch  99 (164.00s)]	ELBO: -854.200 (-1060.077)	Log prob: -557.497 (-762.603)	KLD: 296.703 (297.475)
[Epoch 100 (163.47s)]	ELBO: -804.577 (-1107.203)	Log prob: -508.134 (-816.562)	KLD: 296.443 (290.641)
Best epoch(s): [99]	Training time(s): 14074.42s (14074.42s)	Best ELBO: -804.577 (-1060.077)	Best log prob: -508.134 (-762.603)
Avg. mu: 0.012, 0.011, 0.041, -0.192, 0.102, 0.111, -0.125, 0.066, 0.176, 0.093, -0.017, 0.044, 0.016, -0.095, 0.118, -0.094, 0.004, -0.096, -0.152, 0.093, -0.061, -0.009, 0.242, 0.331, -0.017, -0.004, 0.069, 0.089, -0.030, -0.266, 0.007, -0.235, 0.023, -0.080, 0.148, 0.121, 0.014, 0.083, 0.057, -0.158, 0.013, 0.112, -0.045, -0.108, -0.035, -0.034, 0.037, 0.070, 0.079, 0.022, -0.107, -0.052, -0.053, -0.153, 0.069, 0.119, 0.109, 0.156, -0.103, -0.146, -0.019, -0.072, 0.026, -0.076, -0.100, 0.018, 0.031, 0.318, -0.106, -0.030, 0.158, 0.223, 0.179, 0.040, -0.041, 0.316, -0.120, -0.044, -0.020, 0.050, -0.172, 0.305, -0.021, 0.249, 0.017, 0.100, 0.016, -0.141, -0.005, -0.216, -0.161, -0.012, 0.246, 0.183, 0.065, -0.127, -0.051, -0.000, 0.166, 0.036, -0.052, 0.210, -0.254, -0.143, 0.080, 0.104, -0.107, -0.160, -0.097, -0.122, -0.158, 0.047, -0.132, -0.176, -0.037, 0.232, 0.141, -0.041, 0.108, -0.013, 0.162, -0.098, -0.032, 0.122, -0.168, -0.064, -0.192, -0.374
Avg. var: 0.014, 0.010, 0.025, 0.009, 0.036, 0.030, 0.018, 0.009, 0.033, 0.011, 0.079, 0.014, 0.020, 0.015, 0.012, 0.037, 0.026, 0.026, 0.013, 0.013, 0.191, 0.057, 0.013, 0.067, 0.021, 0.035, 0.013, 0.051, 0.015, 0.025, 0.020, 0.039, 0.026, 0.023, 0.016, 0.030, 0.041, 0.015, 0.019, 0.027, 0.012, 0.081, 0.021, 0.017, 0.017, 0.130, 0.066, 0.009, 0.001, 0.034, 0.046, 0.022, 0.023, 0.031, 0.015, 0.023, 0.017, 0.030, 0.011, 0.035, 0.030, 0.007, 0.010, 0.019, 0.012, 0.037, 0.021, 0.010, 0.046, 0.011, 0.039, 0.017, 0.011, 0.009, 0.028, 0.008, 0.041, 0.021, 0.008, 0.008, 0.016, 0.013, 0.046, 0.014, 0.085, 0.019, 0.009, 0.007, 0.011, 0.008, 0.073, 0.007, 0.008, 0.026, 0.007, 0.020, 0.013, 0.042, 0.025, 0.013, 0.019, 0.047, 0.007, 0.040, 0.144, 0.004, 0.149, 0.017, 0.049, 0.052, 0.013, 0.052, 0.026, 0.029, 0.020, 0.005, 0.050, 0.020, 0.006, 0.010, 0.011, 0.032, 0.014, 0.077, 0.023, 0.025, 0.017, 0.014
Max. mu: 6.419, 6.480, 5.591, 7.121, 5.283, 4.416, 6.361, 7.102, 4.373, 6.234, 4.962, 6.497, 5.916, 6.048, 6.756, 4.500, 7.143, 4.988, 5.017, 7.584, 3.206, 5.050, 7.547, 4.026, 5.364, 5.111, 5.909, 3.720, 5.698, 4.245, 5.219, 5.130, 5.925, 4.748, 6.372, 5.663, 4.113, 5.412, 6.452, 4.634, 8.747, 4.681, 5.709, 4.709, 5.751, 3.257, 4.325, 7.212, 8.234, 4.749, 3.686, 5.278, 5.775, 3.444, 5.338, 6.845, 6.051, 5.315, 7.669, 4.188, 5.161, 9.143, 6.958, 5.457, 6.011, 6.240, 5.309, 7.312, 4.551, 5.356, 5.944, 6.234, 6.837, 8.244, 4.029, 6.291, 3.982, 4.787, 6.456, 5.409, 6.227, 7.678, 3.752, 6.483, 3.476, 6.319, 8.178, 5.997, 6.050, 4.387, 3.706, 7.989, 5.887, 4.383, 10.173, 6.231, 7.409, 5.449, 5.149, 7.274, 7.416, 4.649, 8.072, 5.206, 3.679, 7.874, 4.150, 4.680, 4.777, 4.679, 5.569, 4.201, 6.359, 6.709, 5.853, 10.671, 4.372, 5.113, 9.386, 7.562, 6.144, 4.656, 5.126, 3.402, 5.512, 4.134, 5.819, 4.363
Max. var: 0.153, 0.061, 0.207, 0.112, 0.236, 0.247, 0.190, 0.151, 0.182, 0.085, 0.515, 0.148, 0.119, 0.139, 0.072, 0.186, 0.163, 0.176, 0.123, 0.107, 0.584, 0.222, 0.133, 0.443, 0.230, 0.150, 0.085, 0.237, 0.144, 0.231, 0.221, 0.138, 0.332, 0.186, 0.407, 0.218, 0.279, 0.222, 0.318, 0.179, 0.077, 0.402, 0.154, 0.110, 0.100, 0.766, 0.724, 0.054, 0.037, 0.362, 0.235, 0.222, 0.305, 0.217, 0.069, 0.169, 0.073, 0.307, 0.084, 0.351, 0.433, 0.037, 0.052, 0.125, 0.105, 0.191, 0.158, 0.048, 0.243, 0.752, 0.314, 0.074, 0.108, 0.113, 0.320, 0.115, 0.240, 0.172, 0.223, 0.130, 0.168, 0.102, 0.233, 0.209, 1.067, 0.108, 0.086, 0.137, 0.058, 0.142, 0.372, 0.081, 0.060, 0.105, 0.051, 0.159, 0.148, 0.191, 0.184, 0.066, 0.085, 0.274, 0.149, 0.270, 1.011, 0.059, 0.568, 0.207, 0.531, 0.389, 0.131, 0.430, 0.114, 0.233, 0.122, 0.027, 0.254, 0.101, 0.052, 0.091, 0.324, 0.193, 0.138, 0.304, 0.150, 0.157, 0.134, 0.161
Min. mu: -5.789, -5.719, -5.038, -7.691, -4.569, -3.995, -4.910, -7.243, -4.973, -6.906, -4.524, -4.948, -4.381, -8.822, -6.580, -4.255, -5.084, -4.966, -5.413, -6.903, -3.511, -5.170, -6.733, -3.506, -5.659, -5.117, -6.217, -3.763, -5.978, -5.889, -5.083, -5.796, -6.182, -5.869, -7.516, -3.915, -4.400, -7.382, -6.306, -5.213, -7.204, -4.205, -6.604, -5.246, -7.194, -4.177, -4.578, -5.622, -10.400, -4.792, -4.094, -6.470, -5.915, -3.843, -5.170, -6.007, -5.778, -6.616, -7.301, -4.752, -4.874, -9.031, -8.301, -4.851, -5.769, -4.668, -7.804, -6.521, -6.202, -5.131, -7.221, -5.645, -5.596, -8.493, -5.357, -5.789, -5.820, -5.404, -6.048, -4.956, -6.137, -5.548, -5.207, -4.889, -2.954, -5.686, -7.712, -5.718, -7.124, -7.492, -3.885, -7.346, -6.148, -4.722, -8.202, -5.148, -6.911, -4.223, -6.115, -6.911, -6.519, -4.678, -6.511, -4.167, -3.278, -9.301, -4.060, -6.693, -4.273, -4.866, -5.096, -4.594, -5.431, -4.787, -5.959, -8.447, -5.347, -5.254, -8.953, -7.787, -8.445, -5.370, -5.282, -3.423, -6.344, -4.202, -6.926, -7.126
Min. var: 0.000, 0.000, 0.001, 0.000, 0.001, 0.004, 0.000, 0.000, 0.003, 0.000, 0.003, 0.001, 0.000, 0.001, 0.000, 0.003, 0.001, 0.000, 0.000, 0.000, 0.012, 0.008, 0.000, 0.001, 0.000, 0.003, 0.000, 0.004, 0.000, 0.001, 0.001, 0.000, 0.001, 0.001, 0.000, 0.000, 0.001, 0.000, 0.000, 0.001, 0.000, 0.005, 0.001, 0.001, 0.000, 0.003, 0.002, 0.000, 0.000, 0.003, 0.002, 0.001, 0.001, 0.002, 0.000, 0.000, 0.000, 0.004, 0.001, 0.001, 0.001, 0.000, 0.001, 0.000, 0.000, 0.002, 0.001, 0.000, 0.003, 0.000, 0.003, 0.001, 0.000, 0.000, 0.001, 0.000, 0.001, 0.001, 0.000, 0.000, 0.001, 0.000, 0.002, 0.000, 0.001, 0.001, 0.000, 0.000, 0.001, 0.000, 0.003, 0.000, 0.000, 0.002, 0.000, 0.001, 0.000, 0.002, 0.001, 0.000, 0.001, 0.000, 0.000, 0.001, 0.004, 0.000, 0.006, 0.000, 0.001, 0.001, 0.000, 0.001, 0.001, 0.001, 0.001, 0.000, 0.002, 0.001, 0.000, 0.000, 0.000, 0.001, 0.000, 0.006, 0.001, 0.001, 0.000, 0.001
Cov. mu:
[[1.606 0.169 0.120 ... -0.026 0.021 -0.630]
 [0.169 1.569 0.329 ... 0.013 0.227 0.196]
 [0.120 0.329 1.432 ... 0.018 -0.174 -0.042]
 ...
 [-0.026 0.013 0.018 ... 1.018 -0.036 -0.109]
 [0.021 0.227 -0.174 ... -0.036 1.789 -0.123]
 [-0.630 0.196 -0.042 ... -0.109 -0.123 1.495]]
