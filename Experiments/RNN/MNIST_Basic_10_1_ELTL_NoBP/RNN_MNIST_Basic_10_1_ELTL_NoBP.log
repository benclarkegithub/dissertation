Encoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Encoder                                  --
├─Linear: 1-1                            31,400
├─Linear: 1-2                            1,640
=================================================================
Total params: 33,040
Trainable params: 33,040
Non-trainable params: 0
=================================================================
Encoder 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Encoder                                  --
├─Linear: 1-1                            31,400
├─Linear: 1-2                            1,640
=================================================================
Total params: 33,040
Trainable params: 33,040
Non-trainable params: 0
=================================================================
Encoder Encoder to Encoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderEncoderToEncoder                  --
├─Linear: 1-1                            3,240
├─Linear: 1-2                            1,640
=================================================================
Total params: 4,880
Trainable params: 4,880
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            1,640
├─Linear: 1-2                            41
├─Linear: 1-3                            41
=================================================================
Total params: 1,722
Trainable params: 1,722
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            1,806
├─Linear: 1-2                            43
├─Linear: 1-3                            43
=================================================================
Total params: 1,892
Trainable params: 1,892
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            1,980
├─Linear: 1-2                            45
├─Linear: 1-3                            45
=================================================================
Total params: 2,070
Trainable params: 2,070
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            2,162
├─Linear: 1-2                            47
├─Linear: 1-3                            47
=================================================================
Total params: 2,256
Trainable params: 2,256
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 4
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            2,352
├─Linear: 1-2                            49
├─Linear: 1-3                            49
=================================================================
Total params: 2,450
Trainable params: 2,450
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 5
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            2,550
├─Linear: 1-2                            51
├─Linear: 1-3                            51
=================================================================
Total params: 2,652
Trainable params: 2,652
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 6
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            2,756
├─Linear: 1-2                            53
├─Linear: 1-3                            53
=================================================================
Total params: 2,862
Trainable params: 2,862
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 7
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            2,970
├─Linear: 1-2                            55
├─Linear: 1-3                            55
=================================================================
Total params: 3,080
Trainable params: 3,080
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 8
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            3,192
├─Linear: 1-2                            57
├─Linear: 1-3                            57
=================================================================
Total params: 3,306
Trainable params: 3,306
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 9
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            3,422
├─Linear: 1-2                            59
├─Linear: 1-3                            59
=================================================================
Total params: 3,540
Trainable params: 3,540
Non-trainable params: 0
=================================================================
Latents to Decoder 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            80
=================================================================
Total params: 80
Trainable params: 80
Non-trainable params: 0
=================================================================
Latents to Decoder 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            80
=================================================================
Total params: 80
Trainable params: 80
Non-trainable params: 0
=================================================================
Latents to Decoder 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            80
=================================================================
Total params: 80
Trainable params: 80
Non-trainable params: 0
=================================================================
Latents to Decoder 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            80
=================================================================
Total params: 80
Trainable params: 80
Non-trainable params: 0
=================================================================
Latents to Decoder 4
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            80
=================================================================
Total params: 80
Trainable params: 80
Non-trainable params: 0
=================================================================
Latents to Decoder 5
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            80
=================================================================
Total params: 80
Trainable params: 80
Non-trainable params: 0
=================================================================
Latents to Decoder 6
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            80
=================================================================
Total params: 80
Trainable params: 80
Non-trainable params: 0
=================================================================
Latents to Decoder 7
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            80
=================================================================
Total params: 80
Trainable params: 80
Non-trainable params: 0
=================================================================
Latents to Decoder 8
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            80
=================================================================
Total params: 80
Trainable params: 80
Non-trainable params: 0
=================================================================
Latents to Decoder 9
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            80
=================================================================
Total params: 80
Trainable params: 80
Non-trainable params: 0
=================================================================
Decoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Decoder                                  --
├─Linear: 1-1                            1,640
├─Linear: 1-2                            32,144
=================================================================
Total params: 33,784
Trainable params: 33,784
Non-trainable params: 0
=================================================================
[Epoch   1 (157.10s)]	ELBO: 979.797, 1107.240, 1117.780, 1123.040, 1125.555, 1126.812, 1126.837, 1126.014, 1125.002, 1122.413 (1306.294)	Log prob: 1081.901, 1225.445, 1238.440, 1244.663, 1247.760, 1249.663, 1250.048, 1249.500, 1248.700, 1246.487 (1384.796)	KLD: 102.104, 16.102, 2.454, 0.964, 0.581, 0.647, 0.360, 0.274, 0.213, 0.377 (78.502)	Grad: 1.974, 0.369, 0.163, 0.121, 0.102, 0.129, 0.099, 0.107, 0.107, 0.120
[Epoch   2 (173.15s)]	ELBO: 1301.809, 1354.252, 1356.563, 1357.677, 1357.498, 1357.285, 1356.686, 1356.088, 1355.566, 1354.644 (1380.102)	Log prob: 1339.964, 1399.510, 1402.936, 1404.462, 1404.597, 1404.736, 1404.429, 1403.981, 1403.795, 1403.394 (1414.339)	KLD: 38.155, 7.104, 1.114, 0.410, 0.315, 0.353, 0.291, 0.149, 0.336, 0.522 (34.237)	Grad: 0.310, 0.111, 0.074, 0.060, 0.054, 0.060, 0.057, 0.055, 0.062, 0.060
[Epoch   3 (144.01s)]	ELBO: 1329.872, 1394.623, 1400.450, 1406.329, 1406.954, 1407.275, 1407.269, 1407.141, 1406.943, 1406.523 (1447.658)	Log prob: 1349.008, 1419.002, 1426.409, 1434.172, 1435.472, 1436.318, 1436.636, 1436.687, 1436.855, 1436.808 (1475.049)	KLD: 19.138, 5.241, 1.580, 1.885, 0.674, 0.527, 0.323, 0.179, 0.365, 0.373 (27.390)	Grad: 0.421, 0.179, 0.103, 0.141, 0.061, 0.074, 0.079, 0.063, 0.071, 0.062
[Epoch   4 (148.54s)]	ELBO: 1353.664, 1415.559, 1458.447, 1462.932, 1469.189, 1470.354, 1470.310, 1470.125, 1469.996, 1469.778 (1490.971)	Log prob: 1363.022, 1428.181, 1475.224, 1481.225, 1489.616, 1491.605, 1491.745, 1491.719, 1492.019, 1492.070 (1510.332)	KLD: 9.357, 3.265, 4.154, 1.518, 2.133, 0.823, 0.187, 0.156, 0.430, 0.270 (19.361)	Grad: 0.844, 0.305, 0.255, 0.278, 0.102, 0.130, 0.077, 0.065, 0.092, 0.063
[Epoch   5 (141.74s)]	ELBO: 1370.531, 1434.824, 1477.829, 1492.083, 1503.057, 1506.281, 1506.638, 1506.833, 1507.167, 1506.929 (1519.750)	Log prob: 1375.978, 1443.139, 1488.925, 1505.080, 1518.326, 1522.903, 1523.754, 1524.265, 1525.159, 1525.161 (1537.229)	KLD: 5.449, 2.866, 2.780, 1.903, 2.271, 1.353, 0.495, 0.314, 0.562, 0.240 (17.479)	Grad: 1.299, 0.409, 0.466, 0.267, 0.174, 0.189, 0.102, 0.072, 0.099, 0.063
[Epoch   6 (144.22s)]	ELBO: 1379.242, 1445.536, 1485.576, 1505.175, 1525.707, 1526.952, 1526.845, 1527.658, 1528.178, 1528.142 (1540.673)	Log prob: 1382.912, 1452.194, 1494.773, 1516.248, 1540.385, 1543.018, 1543.251, 1544.680, 1545.802, 1546.132 (1559.105)	KLD: 3.671, 2.987, 2.539, 1.876, 3.604, 1.388, 0.342, 0.615, 0.603, 0.366 (18.433)	Grad: 2.856, 0.514, 0.564, 0.340, 0.231, 0.188, 0.087, 0.096, 0.116, 0.068
[Epoch   7 (145.49s)]	ELBO: 1379.700, 1453.690, 1493.415, 1513.695, 1540.994, 1543.776, 1545.076, 1546.290, 1548.384, 1548.383 (1557.655)	Log prob: 1383.206, 1460.396, 1502.679, 1524.982, 1555.912, 1560.329, 1562.310, 1564.388, 1567.451, 1567.785 (1576.793)	KLD: 3.505, 3.201, 2.557, 2.024, 3.632, 1.633, 0.682, 0.865, 0.968, 0.335 (19.138)	Grad: 4.559, 0.717, 0.653, 0.346, 0.317, 0.230, 0.116, 0.133, 0.163, 0.074
[Epoch   8 (150.83s)]	ELBO: 1381.707, 1458.969, 1498.491, 1521.240, 1549.522, 1555.972, 1559.795, 1561.820, 1565.023, 1565.267 (1572.383)	Log prob: 1385.447, 1466.155, 1508.349, 1533.287, 1564.583, 1573.029, 1577.975, 1580.978, 1585.385, 1586.048 (1593.690)	KLD: 3.740, 3.446, 2.673, 2.188, 3.014, 1.997, 1.122, 0.977, 1.205, 0.418 (21.307)	Grad: 5.756, 0.837, 0.708, 0.421, 0.358, 0.255, 0.200, 0.159, 0.197, 0.086
[Epoch   9 (146.49s)]	ELBO: 1384.745, 1461.161, 1500.426, 1530.230, 1553.598, 1564.023, 1569.860, 1572.193, 1574.603, 1575.379 (1580.459)	Log prob: 1388.736, 1468.747, 1510.793, 1542.917, 1568.649, 1581.286, 1588.475, 1591.884, 1595.468, 1596.850 (1602.650)	KLD: 3.990, 3.597, 2.780, 2.320, 2.364, 2.212, 1.353, 1.075, 1.174, 0.605 (22.191)	Grad: 8.754, 1.001, 0.726, 0.415, 0.430, 0.276, 0.206, 0.167, 0.225, 0.101
[Epoch  10 (156.77s)]	ELBO: 1386.545, 1462.881, 1503.532, 1537.368, 1557.396, 1569.000, 1575.861, 1578.442, 1580.719, 1581.842 (1586.208)	Log prob: 1390.734, 1470.841, 1514.347, 1550.605, 1572.781, 1586.584, 1594.930, 1598.615, 1602.050, 1603.922 (1608.555)	KLD: 4.187, 3.773, 2.855, 2.421, 2.148, 2.200, 1.486, 1.102, 1.160, 0.749 (22.348)	Grad: 13.180, 1.337, 0.767, 0.410, 0.445, 0.306, 0.228, 0.195, 0.239, 0.117
[Epoch  11 (150.35s)]	ELBO: 1387.331, 1464.307, 1506.809, 1540.099, 1560.369, 1571.554, 1578.780, 1582.003, 1584.362, 1585.652 (1589.155)	Log prob: 1391.742, 1472.647, 1518.068, 1553.795, 1576.307, 1589.646, 1598.430, 1602.830, 1606.408, 1608.512 (1612.324)	KLD: 4.410, 3.930, 2.920, 2.437, 2.241, 2.155, 1.557, 1.177, 1.218, 0.814 (23.168)	Grad: 15.492, 1.517, 0.732, 0.518, 0.443, 0.305, 0.257, 0.210, 0.245, 0.144
[Epoch  12 (141.79s)]	ELBO: 1387.345, 1465.418, 1509.245, 1541.486, 1561.965, 1572.851, 1580.654, 1584.609, 1587.182, 1588.456 (1591.389)	Log prob: 1391.959, 1474.097, 1520.916, 1555.653, 1578.485, 1591.507, 1600.923, 1606.165, 1609.986, 1612.106 (1615.110)	KLD: 4.615, 4.064, 2.993, 2.496, 2.355, 2.135, 1.612, 1.288, 1.247, 0.847 (23.722)	Grad: 20.273, 1.370, 0.764, 0.504, 0.440, 0.294, 0.268, 0.227, 0.252, 0.142
[Epoch  13 (147.41s)]	ELBO: 1386.973, 1466.879, 1511.340, 1542.659, 1563.224, 1573.842, 1582.145, 1586.810, 1589.615, 1590.941 (1592.508)	Log prob: 1391.729, 1475.796, 1523.353, 1557.254, 1580.239, 1592.999, 1602.938, 1608.983, 1613.055, 1615.220 (1617.403)	KLD: 4.755, 4.162, 3.097, 2.581, 2.420, 2.142, 1.636, 1.379, 1.269, 0.838 (24.895)	Grad: 25.148, 1.578, 0.886, 0.592, 0.477, 0.321, 0.242, 0.261, 0.267, 0.148
[Epoch  14 (152.47s)]	ELBO: 1387.312, 1468.020, 1513.120, 1543.430, 1563.859, 1574.702, 1583.916, 1588.899, 1591.948, 1593.336 (1593.274)	Log prob: 1392.249, 1477.247, 1525.531, 1558.513, 1581.418, 1594.419, 1605.309, 1611.739, 1616.079, 1618.308 (1618.733)	KLD: 4.937, 4.290, 3.185, 2.672, 2.476, 2.158, 1.676, 1.447, 1.289, 0.841 (25.459)	Grad: 23.602, 1.773, 0.873, 0.584, 0.464, 0.334, 0.261, 0.270, 0.259, 0.147
[Epoch  15 (132.87s)]	ELBO: 1387.396, 1469.042, 1514.517, 1544.404, 1564.943, 1575.734, 1585.527, 1590.704, 1594.000, 1595.466 (1596.466)	Log prob: 1392.465, 1478.512, 1527.259, 1559.936, 1583.025, 1595.971, 1607.465, 1614.142, 1618.749, 1621.078 (1622.766)	KLD: 5.070, 4.401, 3.271, 2.790, 2.550, 2.154, 1.702, 1.501, 1.310, 0.862 (26.300)	Grad: 27.173, 2.101, 0.966, 0.680, 0.496, 0.344, 0.282, 0.281, 0.269, 0.153
[Epoch  16 (129.89s)]	ELBO: 1387.450, 1469.753, 1516.106, 1545.552, 1566.089, 1576.604, 1586.786, 1592.468, 1595.861, 1597.343 (1600.164)	Log prob: 1392.587, 1479.358, 1529.069, 1561.406, 1584.522, 1597.222, 1609.109, 1616.333, 1621.064, 1623.415 (1626.512)	KLD: 5.138, 4.467, 3.359, 2.890, 2.581, 2.184, 1.705, 1.543, 1.338, 0.868 (26.347)	Grad: 29.186, 2.231, 1.020, 0.723, 0.478, 0.354, 0.258, 0.301, 0.272, 0.156
[Epoch  17 (141.34s)]	ELBO: 1388.567, 1471.343, 1519.268, 1547.475, 1567.979, 1578.347, 1588.719, 1594.732, 1598.126, 1599.678 (1602.053)	Log prob: 1393.811, 1481.142, 1532.499, 1563.698, 1586.831, 1599.396, 1611.494, 1619.106, 1623.833, 1626.272 (1628.863)	KLD: 5.245, 4.555, 3.430, 2.991, 2.630, 2.196, 1.728, 1.599, 1.332, 0.886 (26.810)	Grad: 25.691, 1.975, 1.208, 0.760, 0.498, 0.341, 0.282, 0.300, 0.249, 0.147
[Epoch  18 (131.21s)]	ELBO: 1389.697, 1472.138, 1521.064, 1548.642, 1568.648, 1578.951, 1589.576, 1595.694, 1599.450, 1600.987 (1603.014)	Log prob: 1395.024, 1482.120, 1534.535, 1565.200, 1587.871, 1600.389, 1612.741, 1620.520, 1625.627, 1628.053 (1630.274)	KLD: 5.327, 4.655, 3.490, 3.087, 2.665, 2.214, 1.728, 1.661, 1.349, 0.890 (27.260)	Grad: 22.122, 2.415, 1.055, 0.872, 0.460, 0.341, 0.281, 0.268, 0.250, 0.150
[Epoch  19 (129.26s)]	ELBO: 1391.187, 1472.903, 1522.094, 1549.337, 1569.028, 1579.524, 1590.097, 1596.257, 1599.848, 1601.553 (1601.943)	Log prob: 1396.489, 1482.932, 1535.668, 1566.086, 1588.470, 1601.220, 1613.515, 1621.377, 1626.329, 1628.961 (1629.358)	KLD: 5.303, 4.727, 3.544, 3.176, 2.693, 2.254, 1.722, 1.702, 1.360, 0.927 (27.416)	Grad: 19.974, 2.631, 1.182, 0.954, 0.494, 0.350, 0.290, 0.312, 0.256, 0.161
[Epoch  20 (131.14s)]	ELBO: 1393.981, 1474.807, 1525.014, 1551.066, 1570.182, 1580.718, 1590.891, 1597.025, 1600.721, 1602.654 (1600.989)	Log prob: 1399.247, 1484.882, 1538.680, 1567.970, 1589.796, 1602.604, 1614.485, 1622.350, 1627.422, 1630.312 (1628.337)	KLD: 5.265, 4.811, 3.591, 3.238, 2.707, 2.273, 1.708, 1.730, 1.376, 0.959 (27.348)	Grad: 14.265, 2.697, 1.076, 1.081, 0.481, 0.337, 0.264, 0.270, 0.246, 0.149
[Epoch  21 (147.47s)]	ELBO: 1395.640, 1475.981, 1527.458, 1552.622, 1570.931, 1581.515, 1591.322, 1597.579, 1601.174, 1603.271 (1604.786)	Log prob: 1400.802, 1486.016, 1541.130, 1569.614, 1590.620, 1603.478, 1614.985, 1623.006, 1627.976, 1631.085 (1632.955)	KLD: 5.163, 4.871, 3.638, 3.321, 2.698, 2.272, 1.702, 1.764, 1.374, 1.014 (28.169)	Grad: 11.497, 2.585, 1.027, 0.880, 0.488, 0.336, 0.256, 0.278, 0.255, 0.146
[Epoch  22 (150.18s)]	ELBO: 1398.138, 1477.095, 1528.781, 1553.598, 1571.348, 1582.339, 1591.884, 1597.935, 1601.464, 1604.240 (1605.871)	Log prob: 1403.216, 1487.099, 1542.457, 1570.635, 1591.052, 1604.311, 1615.511, 1623.361, 1628.267, 1632.126 (1633.873)	KLD: 5.079, 4.924, 3.673, 3.361, 2.668, 2.266, 1.656, 1.799, 1.376, 1.083 (28.001)	Grad: 11.126, 2.851, 1.095, 1.205, 0.464, 0.308, 0.272, 0.281, 0.244, 0.151
[Epoch  23 (145.99s)]	ELBO: 1401.349, 1478.671, 1530.193, 1554.557, 1571.978, 1582.925, 1592.404, 1598.552, 1602.088, 1605.382 (1602.922)	Log prob: 1406.292, 1488.609, 1543.867, 1571.630, 1591.649, 1604.842, 1615.955, 1623.923, 1628.840, 1633.353 (1631.291)	KLD: 4.943, 4.995, 3.734, 3.400, 2.596, 2.247, 1.633, 1.822, 1.379, 1.221 (28.369)	Grad: 10.756, 2.643, 1.177, 1.093, 0.433, 0.304, 0.268, 0.307, 0.235, 0.160
[Epoch  24 (156.14s)]	ELBO: 1405.886, 1478.742, 1529.927, 1554.326, 1573.097, 1583.788, 1593.304, 1599.081, 1603.092, 1606.480 (1608.409)	Log prob: 1410.631, 1488.513, 1543.463, 1571.291, 1592.605, 1605.536, 1616.667, 1624.256, 1629.670, 1634.300 (1636.819)	KLD: 4.744, 5.028, 3.765, 3.427, 2.543, 2.240, 1.615, 1.813, 1.402, 1.243 (28.410)	Grad: 10.243, 3.409, 1.130, 0.960, 0.427, 0.305, 0.295, 0.318, 0.232, 0.163
[Epoch  25 (160.04s)]	ELBO: 1419.373, 1473.564, 1525.742, 1550.966, 1571.449, 1580.526, 1590.407, 1595.158, 1599.695, 1603.160 (1605.610)	Log prob: 1423.992, 1483.261, 1539.256, 1567.943, 1590.934, 1602.196, 1613.707, 1620.187, 1626.158, 1630.823 (1632.480)	KLD: 4.618, 5.079, 3.817, 3.463, 2.508, 2.184, 1.631, 1.729, 1.436, 1.200 (26.869)	Grad: 10.041, 3.512, 1.292, 1.167, 0.458, 0.299, 0.276, 0.311, 0.263, 0.157
[Epoch  26 (147.37s)]	ELBO: 1437.867, 1470.950, 1522.973, 1549.942, 1571.172, 1580.452, 1590.337, 1594.952, 1599.869, 1603.071 (1606.258)	Log prob: 1442.430, 1480.634, 1536.496, 1566.949, 1590.680, 1602.137, 1613.648, 1619.944, 1626.288, 1630.637 (1633.349)	KLD: 4.564, 5.120, 3.839, 3.484, 2.502, 2.176, 1.625, 1.680, 1.430, 1.144 (27.092)	Grad: 7.973, 2.987, 1.204, 1.084, 0.402, 0.280, 0.244, 0.288, 0.222, 0.147
[Epoch  27 (155.61s)]	ELBO: 1441.781, 1472.616, 1524.736, 1552.280, 1573.040, 1582.620, 1592.640, 1598.104, 1603.445, 1606.495 (1610.299)	Log prob: 1446.325, 1482.345, 1538.388, 1569.468, 1592.702, 1604.488, 1616.149, 1623.310, 1630.118, 1634.268 (1638.538)	KLD: 4.545, 5.183, 3.924, 3.534, 2.475, 2.207, 1.640, 1.696, 1.467, 1.102 (28.239)	Grad: 8.813, 2.773, 1.137, 1.106, 0.410, 0.273, 0.251, 0.255, 0.235, 0.146
[Epoch  28 (168.33s)]	ELBO: 1442.170, 1474.872, 1527.292, 1554.465, 1574.752, 1584.318, 1594.758, 1601.101, 1607.111, 1609.779 (1615.480)	Log prob: 1446.822, 1484.752, 1541.149, 1571.893, 1594.644, 1606.429, 1618.526, 1626.633, 1634.146, 1637.892 (1642.402)	KLD: 4.653, 5.227, 3.977, 3.571, 2.465, 2.220, 1.655, 1.765, 1.503, 1.077 (26.922)	Grad: 9.188, 3.052, 1.252, 1.227, 0.438, 0.322, 0.256, 0.283, 0.229, 0.144
[Epoch  29 (163.98s)]	ELBO: 1440.644, 1468.919, 1522.702, 1550.212, 1570.806, 1583.099, 1593.597, 1600.305, 1606.745, 1609.388 (1614.918)	Log prob: 1445.149, 1478.706, 1536.502, 1567.637, 1590.727, 1605.293, 1617.467, 1625.972, 1633.939, 1637.675 (1642.750)	KLD: 4.504, 5.284, 4.012, 3.627, 2.494, 2.272, 1.677, 1.798, 1.525, 1.095 (27.832)	Grad: 12.352, 3.562, 1.383, 1.243, 0.475, 0.326, 0.302, 0.299, 0.259, 0.163
[Epoch  30 (158.15s)]	ELBO: 1441.080, 1469.787, 1523.797, 1551.524, 1572.169, 1585.250, 1595.763, 1603.034, 1608.811, 1611.728 (1615.146)	Log prob: 1445.719, 1479.768, 1537.848, 1569.226, 1592.352, 1607.773, 1619.958, 1629.040, 1636.267, 1640.323 (1644.138)	KLD: 4.639, 5.342, 4.071, 3.650, 2.482, 2.340, 1.672, 1.810, 1.452, 1.138 (28.991)	Grad: 11.856, 3.481, 1.377, 1.296, 0.477, 0.323, 0.258, 0.282, 0.219, 0.155
[Epoch  31 (168.22s)]	ELBO: 1442.938, 1473.243, 1526.554, 1554.290, 1574.811, 1587.920, 1598.254, 1605.923, 1611.246, 1614.275 (1615.154)	Log prob: 1447.609, 1483.282, 1540.691, 1572.113, 1595.138, 1610.599, 1622.625, 1632.136, 1638.876, 1643.063 (1643.451)	KLD: 4.672, 5.366, 4.101, 3.685, 2.504, 2.353, 1.690, 1.843, 1.418, 1.157 (28.297)	Grad: 12.084, 3.670, 1.578, 1.255, 0.427, 0.309, 0.276, 0.286, 0.225, 0.163
[Epoch  32 (163.96s)]	ELBO: 1440.184, 1471.308, 1524.971, 1552.713, 1573.453, 1588.015, 1598.770, 1606.448, 1611.638, 1615.090 (1617.261)	Log prob: 1444.792, 1481.305, 1539.091, 1570.555, 1593.814, 1610.789, 1623.241, 1632.754, 1639.346, 1644.020 (1646.334)	KLD: 4.608, 5.389, 4.122, 3.721, 2.520, 2.414, 1.697, 1.835, 1.401, 1.222 (29.073)	Grad: 16.911, 5.511, 1.574, 1.357, 0.499, 0.353, 0.287, 0.306, 0.238, 0.167
[Epoch  33 (173.98s)]	ELBO: 1442.360, 1475.026, 1526.769, 1554.690, 1575.287, 1589.312, 1600.070, 1607.594, 1612.389, 1615.777 (1620.894)	Log prob: 1447.177, 1485.309, 1541.204, 1572.884, 1596.025, 1612.476, 1624.939, 1634.308, 1640.481, 1645.111 (1650.345)	KLD: 4.816, 5.469, 4.150, 3.759, 2.545, 2.425, 1.705, 1.846, 1.377, 1.241 (29.451)	Grad: 11.011, 4.195, 1.687, 1.147, 0.452, 0.314, 0.261, 0.273, 0.231, 0.163
[Epoch  34 (173.42s)]	ELBO: 1445.090, 1477.992, 1529.679, 1558.034, 1578.720, 1592.904, 1603.617, 1610.965, 1615.619, 1618.927 (1620.457)	Log prob: 1449.999, 1488.408, 1544.288, 1576.424, 1599.658, 1616.320, 1628.757, 1637.958, 1643.980, 1648.535 (1650.181)	KLD: 4.910, 5.507, 4.193, 3.781, 2.547, 2.478, 1.724, 1.853, 1.368, 1.246 (29.725)	Grad: 8.281, 2.784, 1.377, 1.181, 0.413, 0.307, 0.246, 0.272, 0.191, 0.145
[Epoch  35 (147.93s)]	ELBO: 1443.527, 1477.383, 1528.025, 1557.437, 1578.432, 1592.292, 1602.997, 1610.378, 1614.998, 1618.462 (1621.765)	Log prob: 1448.604, 1488.010, 1542.899, 1576.095, 1599.693, 1616.063, 1628.496, 1637.718, 1643.694, 1648.419 (1650.813)	KLD: 5.077, 5.551, 4.245, 3.785, 2.601, 2.512, 1.727, 1.842, 1.355, 1.262 (29.049)	Grad: 10.935, 3.243, 1.350, 1.223, 0.465, 0.318, 0.258, 0.249, 0.212, 0.156
[Epoch  36 (145.36s)]	ELBO: 1443.415, 1478.440, 1528.654, 1557.738, 1578.890, 1592.612, 1603.752, 1610.923, 1615.542, 1619.071 (1620.340)	Log prob: 1448.522, 1489.124, 1543.573, 1576.474, 1600.255, 1616.523, 1629.408, 1638.425, 1644.420, 1649.241 (1651.586)	KLD: 5.108, 5.575, 4.235, 3.816, 2.631, 2.544, 1.747, 1.844, 1.375, 1.294 (31.246)	Grad: 12.975, 3.555, 1.653, 1.217, 0.440, 0.322, 0.251, 0.268, 0.209, 0.154
[Epoch  37 (148.15s)]	ELBO: 1442.405, 1479.796, 1530.341, 1559.661, 1580.986, 1594.452, 1605.426, 1612.410, 1617.142, 1620.437 (1619.731)	Log prob: 1447.611, 1490.603, 1545.438, 1578.593, 1602.561, 1618.621, 1631.341, 1640.185, 1646.297, 1650.900 (1649.704)	KLD: 5.207, 5.600, 4.291, 3.835, 2.642, 2.595, 1.746, 1.858, 1.381, 1.308 (29.973)	Grad: 13.837, 3.539, 1.445, 1.314, 0.473, 0.340, 0.246, 0.260, 0.222, 0.155
[Epoch  38 (153.75s)]	ELBO: 1442.528, 1481.702, 1531.008, 1559.388, 1580.872, 1594.174, 1605.477, 1612.142, 1617.071, 1620.413 (1623.890)	Log prob: 1447.776, 1492.590, 1546.182, 1578.418, 1602.579, 1618.483, 1631.559, 1640.085, 1646.403, 1651.057 (1654.310)	KLD: 5.247, 5.641, 4.286, 3.858, 2.677, 2.601, 1.771, 1.863, 1.389, 1.311 (30.420)	Grad: 15.037, 4.185, 1.652, 1.151, 0.507, 0.341, 0.252, 0.268, 0.200, 0.157
[Epoch  39 (150.56s)]	ELBO: 1444.300, 1484.713, 1533.325, 1561.730, 1584.081, 1596.779, 1608.293, 1614.818, 1619.796, 1623.100 (1624.699)	Log prob: 1449.660, 1495.740, 1548.659, 1580.932, 1605.991, 1621.324, 1634.628, 1643.007, 1649.380, 1653.999 (1655.885)	KLD: 5.361, 5.668, 4.305, 3.869, 2.707, 2.636, 1.790, 1.853, 1.396, 1.315 (31.186)	Grad: 14.405, 3.557, 1.441, 1.110, 0.541, 0.304, 0.229, 0.252, 0.204, 0.151
[Epoch  40 (160.45s)]	ELBO: 1443.963, 1486.103, 1533.775, 1561.277, 1584.321, 1596.729, 1608.524, 1615.429, 1620.475, 1623.653 (1621.250)	Log prob: 1449.395, 1497.242, 1549.266, 1580.677, 1606.472, 1621.533, 1635.153, 1643.941, 1650.403, 1654.899 (1652.809)	KLD: 5.432, 5.708, 4.351, 3.908, 2.752, 2.652, 1.826, 1.881, 1.416, 1.317 (31.559)	Grad: 17.477, 3.311, 1.632, 1.183, 0.507, 0.318, 0.244, 0.253, 0.224, 0.151
[Epoch  41 (154.07s)]	ELBO: 1440.930, 1483.391, 1531.418, 1559.366, 1580.128, 1595.160, 1606.627, 1613.217, 1618.807, 1622.021 (1623.081)	Log prob: 1446.295, 1494.511, 1546.909, 1578.737, 1602.222, 1619.945, 1633.257, 1641.712, 1648.733, 1653.294 (1655.934)	KLD: 5.364, 5.757, 4.370, 3.880, 2.724, 2.691, 1.845, 1.865, 1.433, 1.343 (32.853)	Grad: 15.048, 3.771, 1.699, 1.109, 0.548, 0.369, 0.260, 0.267, 0.228, 0.161
[Epoch  42 (169.88s)]	ELBO: 1444.180, 1487.011, 1535.356, 1562.844, 1585.101, 1598.988, 1610.438, 1616.629, 1621.919, 1624.925 (1628.004)	Log prob: 1449.698, 1498.298, 1551.044, 1582.453, 1607.493, 1624.085, 1637.399, 1645.476, 1652.188, 1656.520 (1659.166)	KLD: 5.518, 5.768, 4.402, 3.921, 2.784, 2.705, 1.864, 1.884, 1.423, 1.326 (31.163)	Grad: 15.802, 4.277, 1.574, 1.123, 0.533, 0.332, 0.241, 0.260, 0.208, 0.155
[Epoch  43 (169.87s)]	ELBO: 1446.242, 1489.580, 1537.083, 1564.596, 1588.011, 1599.609, 1611.179, 1617.240, 1622.794, 1626.016 (1626.106)	Log prob: 1451.797, 1500.923, 1552.862, 1584.316, 1610.515, 1624.805, 1638.261, 1646.219, 1653.198, 1657.738 (1657.476)	KLD: 5.556, 5.786, 4.436, 3.942, 2.784, 2.692, 1.887, 1.896, 1.425, 1.317 (31.370)	Grad: 15.693, 3.998, 1.415, 1.054, 0.552, 0.313, 0.236, 0.236, 0.223, 0.159
[Epoch  44 (153.29s)]	ELBO: 1445.531, 1489.390, 1536.399, 1563.218, 1587.040, 1598.956, 1610.575, 1616.926, 1622.830, 1625.988 (1627.252)	Log prob: 1451.166, 1500.855, 1552.333, 1583.109, 1609.762, 1624.371, 1637.899, 1646.173, 1653.529, 1658.005 (1659.780)	KLD: 5.635, 5.831, 4.469, 3.957, 2.831, 2.692, 1.909, 1.923, 1.452, 1.317 (32.528)	Grad: 18.058, 4.368, 1.565, 1.368, 0.583, 0.323, 0.261, 0.268, 0.215, 0.161
[Epoch  45 (159.15s)]	ELBO: 1445.849, 1491.188, 1537.365, 1563.667, 1587.079, 1599.636, 1610.829, 1617.246, 1622.909, 1625.993 (1625.136)	Log prob: 1451.443, 1502.635, 1553.266, 1583.541, 1609.806, 1625.082, 1638.203, 1646.538, 1653.648, 1658.065 (1656.746)	KLD: 5.593, 5.853, 4.453, 3.973, 2.854, 2.717, 1.930, 1.920, 1.445, 1.333 (31.610)	Grad: 14.025, 4.163, 1.634, 1.090, 0.636, 0.314, 0.262, 0.271, 0.222, 0.156
[Epoch  46 (171.57s)]	ELBO: 1443.911, 1489.316, 1535.484, 1562.109, 1585.394, 1599.768, 1610.931, 1617.279, 1623.133, 1626.147 (1627.502)	Log prob: 1449.483, 1500.733, 1551.380, 1581.946, 1608.102, 1625.208, 1638.305, 1646.555, 1653.851, 1658.191 (1659.925)	KLD: 5.571, 5.847, 4.479, 3.942, 2.871, 2.732, 1.934, 1.900, 1.444, 1.326 (32.423)	Grad: 17.944, 4.345, 1.723, 0.995, 0.644, 0.332, 0.251, 0.263, 0.221, 0.165
[Epoch  47 (162.75s)]	ELBO: 1441.038, 1488.463, 1535.932, 1562.838, 1586.152, 1600.777, 1612.041, 1618.262, 1624.154, 1627.023 (1631.035)	Log prob: 1446.737, 1500.058, 1552.073, 1582.933, 1609.157, 1626.512, 1639.721, 1647.835, 1655.177, 1659.364 (1664.035)	KLD: 5.700, 5.896, 4.544, 3.955, 2.910, 2.729, 1.946, 1.893, 1.451, 1.317 (33.000)	Grad: 15.160, 4.278, 1.564, 0.928, 0.635, 0.334, 0.232, 0.254, 0.213, 0.155
[Epoch  48 (153.44s)]	ELBO: 1444.564, 1492.560, 1539.756, 1566.249, 1590.564, 1603.297, 1614.682, 1620.579, 1626.159, 1629.172 (1631.035)	Log prob: 1450.304, 1504.216, 1555.960, 1586.451, 1613.698, 1629.135, 1642.487, 1650.302, 1657.325, 1661.641 (1663.345)	KLD: 5.741, 5.915, 4.548, 3.998, 2.932, 2.705, 1.966, 1.919, 1.440, 1.305 (32.311)	Grad: 17.705, 3.799, 1.787, 1.009, 0.638, 0.324, 0.243, 0.257, 0.208, 0.156
[Epoch  49 (153.77s)]	ELBO: 1442.896, 1492.144, 1539.473, 1565.809, 1589.670, 1603.798, 1615.060, 1620.931, 1626.598, 1629.624 (1633.209)	Log prob: 1448.641, 1503.803, 1555.699, 1586.016, 1612.849, 1629.708, 1642.958, 1650.734, 1657.837, 1662.176 (1665.252)	KLD: 5.744, 5.916, 4.566, 3.983, 2.971, 2.732, 1.988, 1.905, 1.435, 1.313 (32.044)	Grad: 15.760, 4.311, 2.002, 0.877, 0.595, 0.314, 0.232, 0.244, 0.207, 0.155
[Epoch  50 (149.68s)]	ELBO: 1442.438, 1492.901, 1540.494, 1566.292, 1590.243, 1604.294, 1615.330, 1621.292, 1626.839, 1629.788 (1631.412)	Log prob: 1448.189, 1504.584, 1556.771, 1586.573, 1613.531, 1630.339, 1643.386, 1651.254, 1658.243, 1662.498 (1664.429)	KLD: 5.752, 5.933, 4.592, 4.006, 3.005, 2.756, 2.013, 1.905, 1.442, 1.304 (33.017)	Grad: 18.373, 4.248, 1.569, 1.078, 0.679, 0.323, 0.246, 0.246, 0.208, 0.157
[Epoch  51 (151.75s)]	ELBO: 1443.812, 1494.487, 1540.916, 1566.092, 1590.785, 1603.606, 1614.913, 1621.348, 1626.957, 1629.917 (1630.083)	Log prob: 1449.703, 1506.352, 1557.406, 1586.624, 1614.373, 1629.945, 1643.276, 1651.665, 1658.716, 1662.994 (1664.105)	KLD: 5.891, 5.975, 4.623, 4.042, 3.056, 2.751, 2.025, 1.953, 1.443, 1.319 (34.023)	Grad: 16.848, 4.156, 1.843, 0.939, 0.661, 0.321, 0.244, 0.236, 0.213, 0.152
[Epoch  52 (151.90s)]	ELBO: 1447.238, 1496.472, 1542.724, 1567.718, 1592.749, 1605.300, 1616.268, 1622.349, 1627.988, 1630.931 (1635.348)	Log prob: 1453.126, 1508.358, 1559.257, 1588.301, 1616.372, 1631.685, 1644.686, 1652.716, 1659.788, 1664.021 (1668.006)	KLD: 5.888, 5.999, 4.645, 4.051, 3.040, 2.763, 2.032, 1.949, 1.434, 1.290 (32.658)	Grad: 16.704, 4.246, 1.769, 1.096, 0.703, 0.293, 0.226, 0.248, 0.201, 0.161
[Epoch  53 (142.67s)]	ELBO: 1447.508, 1497.072, 1543.537, 1567.995, 1592.894, 1605.912, 1616.762, 1622.709, 1628.209, 1631.327 (1633.057)	Log prob: 1453.387, 1508.970, 1560.121, 1588.639, 1616.626, 1632.443, 1645.342, 1653.234, 1660.158, 1664.581 (1665.873)	KLD: 5.879, 6.019, 4.685, 4.062, 3.087, 2.799, 2.048, 1.945, 1.425, 1.305 (32.816)	Grad: 17.958, 4.354, 1.912, 1.014, 0.702, 0.315, 0.221, 0.238, 0.200, 0.159
[Epoch  54 (142.45s)]	ELBO: 1447.738, 1496.922, 1543.464, 1568.093, 1593.416, 1606.442, 1617.203, 1623.091, 1628.896, 1631.910 (1632.533)	Log prob: 1453.625, 1508.829, 1560.080, 1588.806, 1617.230, 1633.099, 1645.934, 1653.741, 1660.994, 1665.317 (1666.351)	KLD: 5.887, 6.019, 4.710, 4.097, 3.102, 2.843, 2.073, 1.920, 1.447, 1.308 (33.818)	Grad: 22.670, 4.773, 1.791, 0.893, 0.662, 0.316, 0.235, 0.247, 0.199, 0.167
[Epoch  55 (152.41s)]	ELBO: 1447.786, 1494.929, 1540.366, 1563.721, 1589.203, 1601.576, 1612.748, 1619.367, 1625.157, 1628.201 (1627.498)	Log prob: 1453.876, 1507.097, 1557.256, 1584.764, 1613.417, 1628.688, 1641.960, 1650.560, 1657.801, 1662.146 (1661.693)	KLD: 6.090, 6.079, 4.721, 4.153, 3.172, 2.896, 2.099, 1.982, 1.451, 1.301 (34.194)	Grad: 17.369, 4.674, 1.944, 1.007, 0.772, 0.297, 0.243, 0.234, 0.200, 0.162
[Epoch  56 (151.85s)]	ELBO: 1447.011, 1494.295, 1540.206, 1562.681, 1588.909, 1601.541, 1612.666, 1619.109, 1624.782, 1627.892 (1629.419)	Log prob: 1453.102, 1506.498, 1557.156, 1583.834, 1613.271, 1628.836, 1642.076, 1650.506, 1657.632, 1662.063 (1663.399)	KLD: 6.089, 6.114, 4.748, 4.203, 3.208, 2.930, 2.119, 1.986, 1.453, 1.320 (33.980)	Grad: 18.056, 4.493, 1.965, 1.081, 0.766, 0.307, 0.213, 0.235, 0.193, 0.162
[Epoch  57 (147.64s)]	ELBO: 1449.737, 1498.047, 1543.569, 1566.535, 1592.208, 1605.403, 1616.134, 1621.630, 1627.009, 1630.086 (1631.386)	Log prob: 1455.793, 1510.191, 1560.492, 1587.646, 1616.528, 1632.663, 1645.511, 1652.956, 1659.758, 1664.170 (1666.407)	KLD: 6.056, 6.088, 4.778, 4.187, 3.212, 2.940, 2.116, 1.950, 1.421, 1.336 (35.021)	Grad: 15.745, 4.774, 1.971, 0.858, 0.796, 0.293, 0.230, 0.228, 0.200, 0.169
[Epoch  58 (146.51s)]	ELBO: 1449.929, 1499.199, 1544.650, 1567.455, 1593.142, 1605.582, 1616.181, 1622.309, 1627.388, 1630.547 (1634.602)	Log prob: 1455.995, 1511.376, 1561.605, 1588.598, 1617.542, 1632.982, 1645.704, 1653.755, 1660.257, 1664.721 (1669.104)	KLD: 6.067, 6.110, 4.780, 4.187, 3.256, 3.000, 2.125, 1.921, 1.423, 1.305 (34.503)	Grad: 18.777, 4.189, 2.138, 0.961, 0.804, 0.305, 0.230, 0.228, 0.195, 0.165
[Epoch  59 (147.76s)]	ELBO: 1446.491, 1494.957, 1540.786, 1562.903, 1589.638, 1602.168, 1613.168, 1619.935, 1625.481, 1628.534 (1616.605)	Log prob: 1452.712, 1507.319, 1557.959, 1584.324, 1614.315, 1629.885, 1643.021, 1651.728, 1658.712, 1663.060 (1650.057)	KLD: 6.221, 6.144, 4.810, 4.246, 3.257, 3.040, 2.136, 1.939, 1.439, 1.293 (33.453)	Grad: 24.168, 4.613, 1.909, 1.007, 0.779, 0.327, 0.223, 0.243, 0.199, 0.167
[Epoch  60 (143.88s)]	ELBO: 1449.300, 1499.084, 1544.085, 1566.427, 1592.736, 1604.690, 1616.029, 1621.732, 1626.733, 1629.790 (1633.277)	Log prob: 1455.437, 1511.383, 1561.222, 1587.813, 1617.405, 1632.424, 1645.917, 1653.558, 1659.962, 1664.350 (1668.383)	KLD: 6.137, 6.161, 4.839, 4.248, 3.283, 3.064, 2.155, 1.938, 1.402, 1.333 (35.105)	Grad: 12.911, 4.837, 2.177, 0.955, 0.849, 0.294, 0.222, 0.232, 0.196, 0.169
[Epoch  61 (140.20s)]	ELBO: 1450.152, 1500.009, 1544.173, 1566.058, 1592.740, 1603.955, 1615.587, 1621.832, 1626.688, 1629.833 (1630.480)	Log prob: 1456.362, 1512.391, 1561.394, 1587.559, 1617.580, 1631.897, 1645.682, 1653.851, 1660.093, 1664.552 (1665.815)	KLD: 6.211, 6.171, 4.839, 4.280, 3.339, 3.102, 2.155, 1.922, 1.387, 1.313 (35.335)	Grad: 15.992, 4.716, 2.182, 0.924, 0.834, 0.309, 0.227, 0.224, 0.193, 0.169
[Epoch  62 (145.26s)]	ELBO: 1450.718, 1501.942, 1544.895, 1567.355, 1593.761, 1605.537, 1617.320, 1623.623, 1628.610, 1631.804 (1633.342)	Log prob: 1456.877, 1514.268, 1562.078, 1588.804, 1618.543, 1633.427, 1647.396, 1655.619, 1661.987, 1666.512 (1668.200)	KLD: 6.159, 6.166, 4.858, 4.266, 3.333, 3.108, 2.185, 1.918, 1.385, 1.329 (34.858)	Grad: 19.093, 5.346, 2.199, 0.832, 0.801, 0.328, 0.213, 0.222, 0.192, 0.164
[Epoch  63 (147.80s)]	ELBO: 1450.224, 1500.131, 1545.099, 1567.400, 1593.753, 1605.513, 1617.303, 1623.122, 1628.279, 1631.334 (1630.790)	Log prob: 1456.470, 1512.627, 1562.488, 1589.094, 1618.831, 1633.744, 1647.701, 1655.416, 1661.961, 1666.333 (1665.695)	KLD: 6.246, 6.251, 4.892, 4.304, 3.383, 3.153, 2.169, 1.894, 1.387, 1.319 (34.904)	Grad: 19.449, 4.638, 2.152, 0.885, 0.799, 0.327, 0.224, 0.205, 0.183, 0.167
[Epoch  64 (137.81s)]	ELBO: 1448.539, 1497.587, 1542.893, 1564.782, 1591.499, 1603.308, 1615.242, 1621.218, 1626.207, 1629.233 (1628.524)	Log prob: 1454.831, 1510.144, 1560.371, 1586.600, 1616.795, 1631.798, 1645.910, 1653.792, 1660.178, 1664.539 (1663.802)	KLD: 6.293, 6.265, 4.921, 4.339, 3.478, 3.196, 2.177, 1.906, 1.397, 1.336 (35.278)	Grad: 18.473, 5.703, 1.959, 0.943, 0.789, 0.323, 0.230, 0.209, 0.189, 0.176
[Epoch  65 (137.95s)]	ELBO: 1449.901, 1500.154, 1544.350, 1565.964, 1592.802, 1604.445, 1616.767, 1622.850, 1627.577, 1630.626 (1629.856)	Log prob: 1456.150, 1512.667, 1561.812, 1587.767, 1618.129, 1632.974, 1647.483, 1655.473, 1661.575, 1665.927 (1665.144)	KLD: 6.249, 6.265, 4.947, 4.341, 3.524, 3.202, 2.188, 1.908, 1.373, 1.305 (35.289)	Grad: 14.266, 5.061, 2.081, 0.957, 0.763, 0.329, 0.217, 0.212, 0.179, 0.166
[Epoch  66 (148.86s)]	ELBO: 1450.444, 1502.005, 1546.151, 1568.108, 1594.431, 1605.877, 1617.905, 1623.920, 1628.663, 1631.597 (1634.374)	Log prob: 1456.731, 1514.578, 1563.689, 1589.980, 1619.876, 1634.531, 1648.729, 1656.612, 1662.693, 1666.900 (1669.837)	KLD: 6.286, 6.289, 4.963, 4.334, 3.573, 3.209, 2.170, 1.868, 1.337, 1.274 (35.462)	Grad: 18.180, 5.310, 1.803, 0.914, 0.758, 0.337, 0.229, 0.213, 0.177, 0.169
[Epoch  67 (159.50s)]	ELBO: 1446.895, 1497.334, 1542.937, 1563.858, 1590.196, 1601.739, 1614.052, 1620.671, 1625.189, 1628.320 (1621.735)	Log prob: 1453.245, 1510.032, 1560.613, 1585.933, 1615.941, 1630.725, 1645.215, 1653.730, 1659.613, 1664.053 (1658.756)	KLD: 6.350, 6.347, 4.978, 4.400, 3.669, 3.242, 2.177, 1.896, 1.365, 1.309 (37.021)	Grad: 19.222, 5.059, 2.102, 0.966, 0.942, 0.332, 0.234, 0.218, 0.183, 0.172
[Epoch  68 (143.23s)]	ELBO: 1448.972, 1500.564, 1544.313, 1565.663, 1590.828, 1602.388, 1614.491, 1620.907, 1624.971, 1628.280 (1629.043)	Log prob: 1455.257, 1513.184, 1561.926, 1587.630, 1616.473, 1631.269, 1645.555, 1653.853, 1659.231, 1663.868 (1664.471)	KLD: 6.286, 6.333, 4.994, 4.354, 3.679, 3.233, 2.185, 1.881, 1.314, 1.327 (35.428)	Grad: 15.501, 5.597, 2.500, 0.997, 0.948, 0.334, 0.246, 0.220, 0.185, 0.176
[Epoch  69 (148.58s)]	ELBO: 1452.304, 1504.534, 1548.454, 1570.701, 1596.328, 1607.570, 1619.111, 1624.847, 1628.530, 1631.687 (1633.809)	Log prob: 1458.628, 1517.183, 1566.132, 1592.722, 1622.068, 1636.574, 1650.292, 1657.859, 1662.813, 1667.266 (1669.524)	KLD: 6.325, 6.325, 5.029, 4.344, 3.720, 3.263, 2.177, 1.830, 1.273, 1.295 (35.715)	Grad: 14.614, 6.056, 2.110, 0.836, 0.855, 0.325, 0.222, 0.206, 0.166, 0.169
[Epoch  70 (146.87s)]	ELBO: 1452.367, 1505.094, 1548.925, 1570.813, 1596.099, 1607.427, 1619.377, 1625.145, 1629.489, 1632.486 (1632.691)	Log prob: 1458.659, 1517.749, 1566.630, 1592.868, 1621.894, 1636.511, 1650.636, 1658.240, 1663.894, 1668.191 (1668.909)	KLD: 6.292, 6.364, 5.051, 4.349, 3.738, 3.292, 2.174, 1.836, 1.310, 1.301 (36.218)	Grad: 16.996, 4.885, 2.333, 0.857, 0.833, 0.329, 0.211, 0.204, 0.177, 0.168
[Epoch  71 (159.79s)]	ELBO: 1453.088, 1505.681, 1549.272, 1571.363, 1596.854, 1607.868, 1619.433, 1625.439, 1629.444, 1632.482 (1634.465)	Log prob: 1459.412, 1518.395, 1567.043, 1593.513, 1622.785, 1637.103, 1650.844, 1658.671, 1663.967, 1668.302 (1670.131)	KLD: 6.323, 6.390, 5.059, 4.378, 3.780, 3.305, 2.174, 1.823, 1.289, 1.297 (35.666)	Grad: 15.236, 5.355, 2.443, 0.798, 0.890, 0.324, 0.221, 0.207, 0.177, 0.173
[Epoch  72 (161.34s)]	ELBO: 1452.527, 1505.592, 1548.591, 1570.929, 1596.719, 1607.951, 1619.908, 1626.148, 1630.087, 1633.013 (1633.209)	Log prob: 1458.826, 1518.265, 1566.340, 1593.041, 1622.657, 1637.205, 1651.351, 1659.436, 1664.641, 1668.827 (1669.085)	KLD: 6.299, 6.375, 5.075, 4.363, 3.827, 3.314, 2.191, 1.843, 1.267, 1.259 (35.877)	Grad: 17.062, 7.000, 2.144, 0.815, 0.904, 0.318, 0.229, 0.222, 0.174, 0.176
[Epoch  73 (152.32s)]	ELBO: 1452.250, 1506.048, 1548.997, 1571.587, 1596.610, 1608.100, 1620.104, 1626.319, 1630.255, 1632.907 (1632.447)	Log prob: 1458.583, 1518.818, 1566.872, 1593.843, 1622.763, 1637.579, 1651.772, 1659.793, 1664.987, 1668.899 (1668.349)	KLD: 6.333, 6.436, 5.106, 4.380, 3.897, 3.325, 2.189, 1.807, 1.258, 1.260 (35.901)	Grad: 15.431, 4.825, 2.217, 0.790, 0.892, 0.319, 0.220, 0.205, 0.175, 0.165
[Epoch  74 (133.77s)]	ELBO: 1451.904, 1505.217, 1546.592, 1569.557, 1594.158, 1605.553, 1618.069, 1624.618, 1629.180, 1632.005 (1634.769)	Log prob: 1458.292, 1518.061, 1564.556, 1591.903, 1620.438, 1635.180, 1649.890, 1658.256, 1664.110, 1668.190 (1670.263)	KLD: 6.388, 6.456, 5.119, 4.385, 3.932, 3.349, 2.192, 1.817, 1.292, 1.255 (35.495)	Grad: 15.610, 5.506, 2.214, 0.887, 0.825, 0.338, 0.220, 0.221, 0.166, 0.167
[Epoch  75 (134.91s)]	ELBO: 1452.370, 1505.314, 1547.177, 1569.759, 1594.407, 1605.574, 1617.654, 1623.508, 1627.632, 1630.408 (1629.586)	Log prob: 1458.737, 1518.159, 1565.144, 1592.159, 1620.892, 1635.435, 1649.704, 1657.345, 1662.719, 1666.750 (1666.559)	KLD: 6.367, 6.480, 5.119, 4.432, 4.087, 3.375, 2.189, 1.787, 1.250, 1.257 (36.973)	Grad: 15.453, 5.983, 2.165, 0.960, 0.973, 0.349, 0.223, 0.203, 0.173, 0.173
[Epoch  76 (140.34s)]	ELBO: 1451.976, 1505.326, 1547.309, 1569.639, 1593.737, 1604.936, 1617.241, 1622.992, 1627.531, 1630.030 (1631.369)	Log prob: 1458.277, 1518.097, 1565.213, 1591.976, 1620.102, 1634.683, 1649.175, 1656.711, 1662.538, 1666.263 (1667.239)	KLD: 6.300, 6.471, 5.133, 4.433, 4.026, 3.383, 2.187, 1.785, 1.289, 1.225 (35.870)	Grad: 16.288, 7.016, 2.225, 0.880, 0.905, 0.333, 0.224, 0.214, 0.177, 0.174
No improvement after 25 epochs...
Best epoch(s): [52]	Training time(s): 11449.91s (11449.91s)	Best ELBO: 1633.013 (1635.348)	Best log prob: 1668.899 (1670.263)
Avg. mu: 0.085, -0.019, 0.350, -0.266, 1.014, -0.229, -0.300, -0.341, -0.110, 0.257
Avg. var: 0.000, 0.000, 0.000, 0.000, 0.005, 0.003, 0.014, 0.032, 0.063, 0.076
Max. mu: 0.458, 0.138, 0.792, 1.518, 4.441, 1.624, 3.667, 3.399, 4.173, 5.184
Max. var: 0.001, 0.000, 0.001, 0.061, 0.052, 0.031, 0.220, 0.415, 0.252, 0.604
Min. mu: -0.180, -0.126, -0.072, -0.624, -0.978, -1.867, -2.707, -6.544, -3.572, -4.992
Min. var: 0.000, 0.000, 0.000, 0.000, 0.001, 0.000, 0.002, 0.002, 0.004, 0.001
Cov. mu:
[[0.006 0.000 -0.000 0.000 0.000 0.005 0.003 0.001 0.001 -0.002]
 [0.000 0.001 0.000 -0.000 -0.000 0.002 -0.000 0.004 0.001 0.002]
 [-0.000 0.000 0.010 -0.000 0.007 0.004 -0.001 0.016 0.008 0.002]
 [0.000 -0.000 -0.000 0.024 -0.004 -0.002 -0.003 0.009 0.003 -0.002]
 [0.000 -0.000 0.007 -0.004 0.439 0.003 -0.012 -0.077 -0.071 0.051]
 [0.005 0.002 0.004 -0.002 0.003 0.097 0.010 0.004 0.015 0.004]
 [0.003 -0.000 -0.001 -0.003 -0.012 0.010 0.389 0.076 -0.008 -0.042]
 [0.001 0.004 0.016 0.009 -0.077 0.004 0.076 0.634 0.021 0.026]
 [0.001 0.001 0.008 0.003 -0.071 0.015 -0.008 0.021 0.747 0.036]
 [-0.002 0.002 0.002 -0.002 0.051 0.004 -0.042 0.026 0.036 0.695]]
