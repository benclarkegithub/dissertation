Encoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Encoder                                  --
├─Linear: 1-1                            31,400
├─Linear: 1-2                            1,640
=================================================================
Total params: 33,040
Trainable params: 33,040
Non-trainable params: 0
=================================================================
Encoder 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Encoder                                  --
├─Linear: 1-1                            31,400
├─Linear: 1-2                            1,640
=================================================================
Total params: 33,040
Trainable params: 33,040
Non-trainable params: 0
=================================================================
Encoder Encoder to Encoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderEncoderToEncoder                  --
├─Linear: 1-1                            3,240
├─Linear: 1-2                            1,640
=================================================================
Total params: 4,880
Trainable params: 4,880
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            1,640
├─Linear: 1-2                            82
├─Linear: 1-3                            82
=================================================================
Total params: 1,804
Trainable params: 1,804
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            1,980
├─Linear: 1-2                            90
├─Linear: 1-3                            90
=================================================================
Total params: 2,160
Trainable params: 2,160
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            2,352
├─Linear: 1-2                            98
├─Linear: 1-3                            98
=================================================================
Total params: 2,548
Trainable params: 2,548
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            2,756
├─Linear: 1-2                            106
├─Linear: 1-3                            106
=================================================================
Total params: 2,968
Trainable params: 2,968
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 4
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            3,192
├─Linear: 1-2                            114
├─Linear: 1-3                            114
=================================================================
Total params: 3,420
Trainable params: 3,420
Non-trainable params: 0
=================================================================
Latents to Decoder 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            120
=================================================================
Total params: 120
Trainable params: 120
Non-trainable params: 0
=================================================================
Latents to Decoder 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            120
=================================================================
Total params: 120
Trainable params: 120
Non-trainable params: 0
=================================================================
Latents to Decoder 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            120
=================================================================
Total params: 120
Trainable params: 120
Non-trainable params: 0
=================================================================
Latents to Decoder 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            120
=================================================================
Total params: 120
Trainable params: 120
Non-trainable params: 0
=================================================================
Latents to Decoder 4
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            120
=================================================================
Total params: 120
Trainable params: 120
Non-trainable params: 0
=================================================================
Decoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Decoder                                  --
├─Linear: 1-1                            1,640
├─Linear: 1-2                            32,144
=================================================================
Total params: 33,784
Trainable params: 33,784
Non-trainable params: 0
=================================================================
[Epoch   1 (28.09s)]	ELBO: 1208.661, 1229.132, 1236.510, 1238.096, 1237.574 (1374.821)	Log prob: 1227.032, 1248.957, 1257.383, 1260.049, 1260.896 (1388.897)	KLD: 18.371, 19.825, 20.872, 21.952, 23.322 (14.076)	Grad: 0.233, 0.262, 0.292, 0.290, 0.309
[Epoch   2 (26.11s)]	ELBO: 1399.229, 1403.174, 1402.936, 1401.993, 1400.945 (1418.661)	Log prob: 1407.794, 1413.361, 1414.040, 1413.781, 1413.506 (1430.621)	KLD: 8.565, 10.187, 11.104, 11.787, 12.561 (11.960)	Grad: 0.114, 0.120, 0.145, 0.169, 0.203
[Epoch   3 (26.06s)]	ELBO: 1418.081, 1457.995, 1458.221, 1457.827, 1457.117 (1497.309)	Log prob: 1425.719, 1469.945, 1471.148, 1471.257, 1471.131 (1512.091)	KLD: 7.637, 11.952, 12.927, 13.431, 14.014 (14.782)	Grad: 0.102, 0.116, 0.156, 0.204, 0.256
[Epoch   4 (25.49s)]	ELBO: 1429.276, 1516.341, 1517.177, 1516.984, 1516.457 (1532.697)	Log prob: 1436.827, 1529.485, 1531.446, 1531.477, 1531.365 (1547.269)	KLD: 7.551, 13.143, 14.270, 14.493, 14.909 (14.573)	Grad: 0.090, 0.127, 0.174, 0.233, 0.295
[Epoch   5 (26.94s)]	ELBO: 1443.757, 1545.364, 1545.644, 1547.808, 1547.554 (1561.547)	Log prob: 1451.340, 1558.558, 1559.485, 1562.438, 1562.512 (1577.127)	KLD: 7.582, 13.196, 13.839, 14.630, 14.959 (15.580)	Grad: 0.101, 0.135, 0.178, 0.239, 0.301
[Epoch   6 (29.68s)]	ELBO: 1454.813, 1558.252, 1568.084, 1572.612, 1572.512 (1584.241)	Log prob: 1462.302, 1571.174, 1582.979, 1588.796, 1588.916 (1601.302)	KLD: 7.489, 12.921, 14.896, 16.184, 16.403 (17.061)	Grad: 0.121, 0.151, 0.194, 0.254, 0.318
[Epoch   7 (35.25s)]	ELBO: 1460.774, 1562.858, 1596.501, 1601.395, 1601.350 (1616.024)	Log prob: 1468.217, 1575.683, 1613.066, 1619.331, 1619.402 (1634.575)	KLD: 7.443, 12.826, 16.566, 17.936, 18.052 (18.551)	Grad: 0.135, 0.171, 0.218, 0.279, 0.351
[Epoch   8 (45.54s)]	ELBO: 1466.593, 1569.884, 1615.090, 1623.952, 1623.907 (1630.478)	Log prob: 1473.969, 1582.741, 1631.975, 1642.551, 1642.578 (1648.953)	KLD: 7.375, 12.858, 16.886, 18.600, 18.672 (18.476)	Grad: 0.143, 0.180, 0.231, 0.286, 0.358
[Epoch   9 (67.33s)]	ELBO: 1472.099, 1576.527, 1625.013, 1634.872, 1634.849 (1635.687)	Log prob: 1479.411, 1589.325, 1641.885, 1653.438, 1653.444 (1654.044)	KLD: 7.312, 12.798, 16.872, 18.566, 18.595 (18.356)	Grad: 0.150, 0.187, 0.238, 0.294, 0.367
[Epoch  10 (68.39s)]	ELBO: 1477.073, 1581.873, 1630.884, 1641.440, 1641.450 (1643.378)	Log prob: 1484.327, 1594.584, 1647.690, 1659.931, 1659.955 (1661.216)	KLD: 7.254, 12.711, 16.805, 18.491, 18.505 (17.839)	Grad: 0.151, 0.195, 0.247, 0.310, 0.387
[Epoch  11 (58.64s)]	ELBO: 1481.877, 1586.232, 1635.008, 1646.126, 1646.090 (1647.886)	Log prob: 1489.077, 1598.852, 1651.749, 1664.564, 1664.539 (1666.111)	KLD: 7.198, 12.620, 16.740, 18.438, 18.450 (18.225)	Grad: 0.151, 0.200, 0.254, 0.320, 0.400
[Epoch  12 (58.56s)]	ELBO: 1486.007, 1589.779, 1638.505, 1650.085, 1650.072 (1650.686)	Log prob: 1493.186, 1602.356, 1655.220, 1668.502, 1668.498 (1669.218)	KLD: 7.178, 12.577, 16.715, 18.417, 18.425 (18.533)	Grad: 0.147, 0.200, 0.250, 0.316, 0.394
[Epoch  13 (63.56s)]	ELBO: 1489.643, 1592.617, 1641.517, 1653.596, 1653.652 (1654.096)	Log prob: 1496.810, 1605.161, 1658.207, 1672.002, 1672.064 (1672.640)	KLD: 7.166, 12.543, 16.691, 18.406, 18.413 (18.544)	Grad: 0.144, 0.201, 0.253, 0.319, 0.397
[Epoch  14 (60.05s)]	ELBO: 1492.778, 1595.086, 1644.236, 1656.746, 1656.726 (1656.236)	Log prob: 1499.942, 1607.617, 1660.929, 1675.161, 1675.146 (1674.584)	KLD: 7.165, 12.531, 16.692, 18.415, 18.420 (18.349)	Grad: 0.142, 0.204, 0.257, 0.325, 0.405
[Epoch  15 (62.15s)]	ELBO: 1495.429, 1597.341, 1646.764, 1659.651, 1659.644 (1659.377)	Log prob: 1502.584, 1609.853, 1663.436, 1678.052, 1678.049 (1677.424)	KLD: 7.156, 12.511, 16.673, 18.400, 18.406 (18.047)	Grad: 0.139, 0.205, 0.262, 0.332, 0.415
[Epoch  16 (60.13s)]	ELBO: 1497.940, 1599.478, 1649.139, 1662.492, 1662.512 (1663.062)	Log prob: 1505.097, 1611.994, 1665.828, 1680.915, 1680.942 (1681.218)	KLD: 7.158, 12.516, 16.688, 18.424, 18.431 (18.156)	Grad: 0.140, 0.208, 0.264, 0.334, 0.418
[Epoch  17 (59.01s)]	ELBO: 1499.777, 1601.446, 1651.405, 1665.065, 1665.029 (1664.484)	Log prob: 1506.930, 1613.959, 1668.103, 1683.513, 1683.488 (1682.821)	KLD: 7.153, 12.512, 16.698, 18.449, 18.457 (18.337)	Grad: 0.139, 0.207, 0.262, 0.331, 0.414
[Epoch  18 (66.03s)]	ELBO: 1501.566, 1603.166, 1653.177, 1667.011, 1667.036 (1667.066)	Log prob: 1508.716, 1615.684, 1669.877, 1685.465, 1685.505 (1685.124)	KLD: 7.149, 12.518, 16.699, 18.454, 18.467 (18.058)	Grad: 0.140, 0.208, 0.268, 0.340, 0.425
[Epoch  19 (61.23s)]	ELBO: 1503.521, 1604.913, 1655.013, 1669.022, 1669.010 (1669.053)	Log prob: 1510.641, 1617.403, 1671.679, 1687.453, 1687.461 (1687.413)	KLD: 7.120, 12.489, 16.666, 18.431, 18.452 (18.360)	Grad: 0.139, 0.209, 0.267, 0.338, 0.421
[Epoch  20 (67.44s)]	ELBO: 1504.892, 1606.361, 1656.517, 1670.698, 1670.748 (1669.948)	Log prob: 1512.021, 1618.868, 1673.199, 1689.167, 1689.270 (1688.556)	KLD: 7.127, 12.508, 16.681, 18.468, 18.521 (18.607)	Grad: 0.141, 0.211, 0.270, 0.341, 0.426
[Epoch  21 (72.10s)]	ELBO: 1506.209, 1607.740, 1657.889, 1672.146, 1672.334 (1672.340)	Log prob: 1513.333, 1620.251, 1674.585, 1690.709, 1691.051 (1691.359)	KLD: 7.124, 12.512, 16.696, 18.564, 18.718 (19.019)	Grad: 0.137, 0.207, 0.262, 0.331, 0.412
[Epoch  22 (68.13s)]	ELBO: 1507.516, 1609.067, 1659.180, 1674.201, 1674.687 (1675.638)	Log prob: 1514.622, 1621.574, 1675.862, 1693.150, 1694.015 (1695.015)	KLD: 7.105, 12.508, 16.682, 18.949, 19.327 (19.377)	Grad: 0.141, 0.214, 0.274, 0.351, 0.438
[Epoch  23 (67.93s)]	ELBO: 1508.629, 1610.337, 1660.150, 1677.292, 1678.329 (1680.805)	Log prob: 1515.744, 1622.856, 1676.837, 1696.801, 1698.462 (1701.222)	KLD: 7.115, 12.521, 16.687, 19.511, 20.133 (20.417)	Grad: 0.140, 0.210, 0.268, 0.345, 0.429
[Epoch  24 (75.92s)]	ELBO: 1509.892, 1611.519, 1661.153, 1679.724, 1681.745 (1683.798)	Log prob: 1516.998, 1624.035, 1677.833, 1699.461, 1702.355 (1704.452)	KLD: 7.106, 12.516, 16.679, 19.737, 20.611 (20.654)	Grad: 0.141, 0.212, 0.270, 0.349, 0.434
[Epoch  25 (78.34s)]	ELBO: 1510.857, 1612.557, 1662.127, 1681.629, 1684.409 (1686.685)	Log prob: 1517.969, 1625.090, 1678.826, 1701.481, 1705.271 (1707.230)	KLD: 7.112, 12.532, 16.699, 19.851, 20.863 (20.545)	Grad: 0.142, 0.215, 0.274, 0.355, 0.440
[Epoch  26 (68.61s)]	ELBO: 1511.769, 1613.628, 1663.087, 1683.132, 1686.456 (1687.642)	Log prob: 1518.875, 1626.166, 1679.799, 1703.057, 1707.483 (1708.808)	KLD: 7.104, 12.536, 16.713, 19.924, 21.028 (21.167)	Grad: 0.141, 0.212, 0.270, 0.347, 0.431
[Epoch  27 (78.71s)]	ELBO: 1512.918, 1614.557, 1664.009, 1684.429, 1688.106 (1688.179)	Log prob: 1520.019, 1627.108, 1680.744, 1704.409, 1709.217 (1709.253)	KLD: 7.102, 12.552, 16.735, 19.980, 21.112 (21.074)	Grad: 0.143, 0.215, 0.275, 0.352, 0.436
[Epoch  28 (78.06s)]	ELBO: 1513.622, 1615.400, 1664.631, 1685.309, 1689.274 (1689.883)	Log prob: 1520.725, 1627.952, 1681.370, 1705.314, 1710.436 (1711.483)	KLD: 7.104, 12.552, 16.740, 20.003, 21.162 (21.600)	Grad: 0.144, 0.219, 0.285, 0.366, 0.455
[Epoch  29 (68.46s)]	ELBO: 1514.699, 1616.549, 1665.820, 1686.633, 1690.889 (1691.335)	Log prob: 1521.809, 1629.120, 1682.582, 1706.674, 1712.112 (1712.704)	KLD: 7.110, 12.572, 16.762, 20.041, 21.223 (21.369)	Grad: 0.140, 0.215, 0.271, 0.348, 0.430
[Epoch  30 (85.39s)]	ELBO: 1515.514, 1617.314, 1666.403, 1687.471, 1691.899 (1693.037)	Log prob: 1522.632, 1629.901, 1683.179, 1707.533, 1713.160 (1714.198)	KLD: 7.118, 12.587, 16.775, 20.062, 21.261 (21.162)	Grad: 0.140, 0.216, 0.278, 0.358, 0.444
[Epoch  31 (84.58s)]	ELBO: 1516.280, 1618.004, 1667.119, 1688.216, 1692.888 (1693.520)	Log prob: 1523.393, 1630.587, 1683.895, 1708.287, 1714.182 (1714.679)	KLD: 7.114, 12.584, 16.776, 20.071, 21.293 (21.159)	Grad: 0.139, 0.217, 0.280, 0.361, 0.446
[Epoch  32 (88.75s)]	ELBO: 1517.133, 1618.945, 1667.984, 1689.181, 1694.011 (1694.682)	Log prob: 1524.252, 1631.542, 1684.783, 1709.289, 1715.358 (1716.125)	KLD: 7.118, 12.596, 16.800, 20.106, 21.347 (21.443)	Grad: 0.138, 0.214, 0.274, 0.350, 0.432
[Epoch  33 (71.86s)]	ELBO: 1517.863, 1619.619, 1668.693, 1689.991, 1694.863 (1695.346)	Log prob: 1524.978, 1632.227, 1685.504, 1710.109, 1716.230 (1716.475)	KLD: 7.116, 12.609, 16.809, 20.118, 21.365 (21.129)	Grad: 0.140, 0.218, 0.275, 0.351, 0.433
[Epoch  34 (77.28s)]	ELBO: 1518.668, 1620.331, 1669.321, 1690.614, 1695.566 (1695.740)	Log prob: 1525.785, 1632.945, 1686.140, 1710.729, 1716.935 (1717.211)	KLD: 7.119, 12.613, 16.817, 20.116, 21.369 (21.471)	Grad: 0.141, 0.220, 0.285, 0.367, 0.454
[Epoch  35 (76.68s)]	ELBO: 1519.324, 1620.964, 1669.899, 1691.221, 1696.372 (1696.840)	Log prob: 1526.448, 1633.588, 1686.729, 1711.362, 1717.784 (1718.371)	KLD: 7.125, 12.622, 16.830, 20.141, 21.412 (21.531)	Grad: 0.140, 0.217, 0.280, 0.359, 0.445
[Epoch  36 (68.59s)]	ELBO: 1520.063, 1621.716, 1670.686, 1691.943, 1697.183 (1697.405)	Log prob: 1527.195, 1634.355, 1687.536, 1712.100, 1718.611 (1718.844)	KLD: 7.131, 12.638, 16.850, 20.157, 21.428 (21.439)	Grad: 0.141, 0.220, 0.282, 0.361, 0.446
[Epoch  37 (66.48s)]	ELBO: 1520.939, 1622.466, 1671.331, 1692.550, 1697.901 (1697.730)	Log prob: 1528.078, 1635.116, 1688.194, 1712.729, 1719.366 (1719.466)	KLD: 7.139, 12.650, 16.861, 20.179, 21.465 (21.736)	Grad: 0.140, 0.218, 0.280, 0.360, 0.445
[Epoch  38 (60.30s)]	ELBO: 1521.479, 1622.953, 1671.754, 1693.059, 1698.446 (1699.226)	Log prob: 1528.628, 1635.620, 1688.639, 1713.265, 1719.947 (1720.510)	KLD: 7.149, 12.667, 16.885, 20.204, 21.501 (21.284)	Grad: 0.141, 0.220, 0.283, 0.361, 0.447
[Epoch  39 (56.80s)]	ELBO: 1522.315, 1623.737, 1672.513, 1693.719, 1699.213 (1699.789)	Log prob: 1529.466, 1636.404, 1689.397, 1713.916, 1720.707 (1721.498)	KLD: 7.150, 12.667, 16.883, 20.196, 21.494 (21.709)	Grad: 0.139, 0.215, 0.279, 0.357, 0.442
[Epoch  40 (56.04s)]	ELBO: 1522.980, 1624.337, 1673.105, 1694.370, 1699.843 (1700.303)	Log prob: 1530.132, 1637.014, 1689.994, 1714.570, 1721.360 (1721.917)	KLD: 7.152, 12.677, 16.889, 20.200, 21.518 (21.615)	Grad: 0.139, 0.218, 0.278, 0.354, 0.437
[Epoch  41 (55.49s)]	ELBO: 1523.612, 1624.809, 1673.494, 1694.734, 1700.337 (1700.340)	Log prob: 1530.778, 1637.508, 1690.407, 1714.964, 1721.875 (1721.804)	KLD: 7.165, 12.699, 16.912, 20.229, 21.536 (21.464)	Grad: 0.139, 0.217, 0.277, 0.355, 0.439
[Epoch  42 (59.36s)]	ELBO: 1524.303, 1625.382, 1673.921, 1695.042, 1700.620 (1700.427)	Log prob: 1531.472, 1638.088, 1690.850, 1715.292, 1722.186 (1722.111)	KLD: 7.170, 12.706, 16.929, 20.250, 21.565 (21.685)	Grad: 0.140, 0.219, 0.281, 0.361, 0.446
[Epoch  43 (63.71s)]	ELBO: 1524.989, 1626.049, 1674.579, 1695.635, 1701.351 (1702.624)	Log prob: 1532.173, 1638.784, 1691.539, 1715.912, 1722.950 (1724.111)	KLD: 7.185, 12.735, 16.960, 20.278, 21.599 (21.487)	Grad: 0.139, 0.219, 0.280, 0.359, 0.443
[Epoch  44 (60.26s)]	ELBO: 1525.585, 1626.569, 1674.975, 1696.052, 1701.790 (1701.752)	Log prob: 1532.760, 1639.288, 1691.924, 1716.310, 1723.377 (1723.231)	KLD: 7.175, 12.720, 16.949, 20.259, 21.585 (21.479)	Grad: 0.141, 0.219, 0.281, 0.358, 0.442
[Epoch  45 (66.76s)]	ELBO: 1526.182, 1627.026, 1675.425, 1696.500, 1702.247 (1701.149)	Log prob: 1533.377, 1639.769, 1692.397, 1716.786, 1723.853 (1723.082)	KLD: 7.196, 12.743, 16.974, 20.286, 21.607 (21.934)	Grad: 0.140, 0.218, 0.280, 0.356, 0.441
[Epoch  46 (66.75s)]	ELBO: 1527.051, 1627.547, 1675.932, 1696.835, 1702.662 (1702.965)	Log prob: 1534.256, 1640.302, 1692.905, 1717.128, 1724.289 (1724.496)	KLD: 7.204, 12.756, 16.973, 20.294, 21.627 (21.530)	Grad: 0.138, 0.218, 0.281, 0.359, 0.446
[Epoch  47 (66.98s)]	ELBO: 1527.539, 1627.942, 1676.322, 1697.271, 1703.070 (1700.118)	Log prob: 1534.748, 1640.699, 1693.305, 1717.565, 1724.691 (1722.273)	KLD: 7.208, 12.756, 16.983, 20.293, 21.620 (22.155)	Grad: 0.141, 0.220, 0.283, 0.362, 0.447
[Epoch  48 (69.63s)]	ELBO: 1528.174, 1628.444, 1676.604, 1697.503, 1703.396 (1703.399)	Log prob: 1535.397, 1641.228, 1693.615, 1717.829, 1725.048 (1724.657)	KLD: 7.222, 12.783, 17.011, 20.326, 21.652 (21.257)	Grad: 0.141, 0.222, 0.286, 0.365, 0.452
[Epoch  49 (65.16s)]	ELBO: 1528.768, 1628.908, 1677.210, 1697.982, 1703.831 (1703.291)	Log prob: 1536.000, 1641.707, 1694.232, 1718.320, 1725.500 (1724.883)	KLD: 7.232, 12.798, 17.021, 20.338, 21.669 (21.591)	Grad: 0.140, 0.220, 0.284, 0.361, 0.447
[Epoch  50 (67.41s)]	ELBO: 1529.457, 1629.478, 1677.574, 1698.334, 1704.265 (1703.757)	Log prob: 1536.699, 1642.284, 1694.610, 1718.688, 1725.948 (1725.657)	KLD: 7.241, 12.808, 17.035, 20.353, 21.684 (21.900)	Grad: 0.139, 0.219, 0.281, 0.359, 0.444
[Epoch  51 (74.08s)]	ELBO: 1529.844, 1629.887, 1677.887, 1698.605, 1704.574 (1704.317)	Log prob: 1537.097, 1642.706, 1694.931, 1718.963, 1726.260 (1726.039)	KLD: 7.253, 12.820, 17.044, 20.357, 21.685 (21.722)	Grad: 0.140, 0.219, 0.280, 0.357, 0.441
[Epoch  52 (72.94s)]	ELBO: 1530.502, 1630.434, 1678.426, 1699.038, 1704.946 (1704.520)	Log prob: 1537.771, 1643.276, 1695.494, 1719.422, 1726.665 (1726.230)	KLD: 7.269, 12.841, 17.068, 20.383, 21.719 (21.709)	Grad: 0.140, 0.218, 0.282, 0.358, 0.443
[Epoch  53 (75.04s)]	ELBO: 1531.034, 1630.683, 1678.619, 1699.239, 1705.188 (1704.644)	Log prob: 1538.301, 1643.529, 1695.694, 1719.630, 1726.929 (1726.724)	KLD: 7.267, 12.845, 17.076, 20.392, 21.741 (22.080)	Grad: 0.141, 0.220, 0.283, 0.361, 0.445
[Epoch  54 (80.56s)]	ELBO: 1531.752, 1631.343, 1679.048, 1699.631, 1705.550 (1706.063)	Log prob: 1539.026, 1644.199, 1696.130, 1720.023, 1727.276 (1727.402)	KLD: 7.274, 12.856, 17.083, 20.391, 21.726 (21.338)	Grad: 0.140, 0.220, 0.283, 0.360, 0.447
[Epoch  55 (75.83s)]	ELBO: 1532.299, 1631.752, 1679.330, 1699.946, 1705.925 (1705.490)	Log prob: 1539.582, 1644.622, 1696.430, 1720.369, 1727.693 (1727.595)	KLD: 7.284, 12.869, 17.100, 20.423, 21.768 (22.106)	Grad: 0.141, 0.224, 0.288, 0.369, 0.457
[Epoch  56 (70.82s)]	ELBO: 1532.772, 1632.300, 1679.955, 1700.376, 1706.381 (1705.171)	Log prob: 1540.066, 1645.181, 1697.067, 1720.805, 1728.146 (1726.816)	KLD: 7.294, 12.881, 17.113, 20.430, 21.764 (21.645)	Grad: 0.140, 0.218, 0.280, 0.356, 0.439
[Epoch  57 (67.53s)]	ELBO: 1533.206, 1632.581, 1680.200, 1700.644, 1706.626 (1705.653)	Log prob: 1540.507, 1645.473, 1697.311, 1721.071, 1728.388 (1727.366)	KLD: 7.303, 12.892, 17.112, 20.428, 21.761 (21.713)	Grad: 0.140, 0.220, 0.283, 0.360, 0.446
[Epoch  58 (77.63s)]	ELBO: 1533.787, 1632.935, 1680.549, 1700.977, 1706.942 (1706.811)	Log prob: 1541.098, 1645.838, 1697.677, 1721.407, 1728.709 (1728.510)	KLD: 7.311, 12.903, 17.128, 20.431, 21.767 (21.699)	Grad: 0.142, 0.221, 0.285, 0.363, 0.449
[Epoch  59 (80.21s)]	ELBO: 1534.056, 1633.158, 1680.668, 1701.031, 1706.974 (1705.956)	Log prob: 1541.372, 1646.070, 1697.813, 1721.488, 1728.772 (1727.587)	KLD: 7.316, 12.911, 17.144, 20.456, 21.798 (21.631)	Grad: 0.142, 0.223, 0.289, 0.369, 0.457
[Epoch  60 (67.65s)]	ELBO: 1534.692, 1633.522, 1681.182, 1701.534, 1707.433 (1707.177)	Log prob: 1542.024, 1646.455, 1698.350, 1722.028, 1729.266 (1729.024)	KLD: 7.332, 12.933, 17.168, 20.493, 21.833 (21.847)	Grad: 0.141, 0.221, 0.284, 0.361, 0.446
[Epoch  61 (70.68s)]	ELBO: 1535.225, 1634.064, 1681.532, 1701.837, 1707.833 (1707.785)	Log prob: 1542.559, 1647.007, 1698.715, 1722.339, 1729.674 (1729.488)	KLD: 7.334, 12.943, 17.181, 20.502, 21.841 (21.703)	Grad: 0.140, 0.221, 0.283, 0.359, 0.444
[Epoch  62 (63.60s)]	ELBO: 1535.486, 1634.273, 1681.683, 1702.047, 1708.026 (1706.803)	Log prob: 1542.817, 1647.213, 1698.859, 1722.543, 1729.865 (1728.829)	KLD: 7.332, 12.940, 17.175, 20.497, 21.839 (22.026)	Grad: 0.140, 0.220, 0.282, 0.359, 0.444
[Epoch  63 (61.12s)]	ELBO: 1536.088, 1634.669, 1682.024, 1702.336, 1708.250 (1707.711)	Log prob: 1543.429, 1647.622, 1699.217, 1722.848, 1730.096 (1729.599)	KLD: 7.342, 12.952, 17.193, 20.512, 21.846 (21.888)	Grad: 0.142, 0.222, 0.285, 0.363, 0.449
[Epoch  64 (58.75s)]	ELBO: 1536.747, 1635.216, 1682.483, 1702.713, 1708.621 (1708.801)	Log prob: 1544.091, 1648.171, 1699.664, 1723.211, 1730.446 (1730.582)	KLD: 7.344, 12.954, 17.181, 20.496, 21.825 (21.781)	Grad: 0.142, 0.220, 0.282, 0.359, 0.443
[Epoch  65 (70.19s)]	ELBO: 1536.907, 1635.296, 1682.602, 1702.897, 1708.719 (1706.930)	Log prob: 1544.264, 1648.266, 1699.802, 1723.419, 1730.578 (1728.727)	KLD: 7.357, 12.970, 17.201, 20.522, 21.860 (21.796)	Grad: 0.142, 0.223, 0.287, 0.366, 0.452
[Epoch  66 (69.98s)]	ELBO: 1537.355, 1635.730, 1682.931, 1703.205, 1709.062 (1708.089)	Log prob: 1544.712, 1648.709, 1700.142, 1723.735, 1730.923 (1729.826)	KLD: 7.357, 12.979, 17.210, 20.531, 21.862 (21.737)	Grad: 0.143, 0.223, 0.285, 0.361, 0.446
[Epoch  67 (73.63s)]	ELBO: 1537.933, 1635.967, 1683.145, 1703.397, 1709.247 (1708.008)	Log prob: 1545.301, 1648.955, 1700.367, 1723.935, 1731.115 (1730.208)	KLD: 7.370, 12.988, 17.221, 20.539, 21.868 (22.200)	Grad: 0.143, 0.221, 0.283, 0.360, 0.444
[Epoch  68 (76.57s)]	ELBO: 1538.113, 1636.197, 1683.370, 1703.638, 1709.395 (1709.075)	Log prob: 1545.487, 1649.188, 1700.599, 1724.194, 1731.285 (1730.949)	KLD: 7.374, 12.992, 17.229, 20.557, 21.891 (21.874)	Grad: 0.143, 0.223, 0.284, 0.361, 0.447
[Epoch  69 (77.90s)]	ELBO: 1538.629, 1636.470, 1683.620, 1703.861, 1709.645 (1705.149)	Log prob: 1546.000, 1649.463, 1700.850, 1724.408, 1731.521 (1727.142)	KLD: 7.370, 12.993, 17.231, 20.547, 21.877 (21.994)	Grad: 0.142, 0.220, 0.283, 0.361, 0.447
[Epoch  70 (80.33s)]	ELBO: 1538.905, 1636.498, 1683.731, 1704.001, 1709.751 (1709.985)	Log prob: 1546.277, 1649.495, 1700.951, 1724.552, 1731.640 (1731.425)	KLD: 7.372, 12.997, 17.222, 20.550, 21.889 (21.440)	Grad: 0.145, 0.226, 0.293, 0.375, 0.464
[Epoch  71 (79.53s)]	ELBO: 1539.629, 1637.113, 1684.264, 1704.478, 1710.283 (1709.774)	Log prob: 1547.022, 1650.137, 1701.522, 1725.061, 1732.208 (1731.517)	KLD: 7.392, 13.024, 17.258, 20.583, 21.925 (21.743)	Grad: 0.142, 0.222, 0.284, 0.361, 0.447
[Epoch  72 (90.27s)]	ELBO: 1539.896, 1637.377, 1684.309, 1704.507, 1710.308 (1708.616)	Log prob: 1547.299, 1650.409, 1701.580, 1725.101, 1732.241 (1730.588)	KLD: 7.402, 13.032, 17.271, 20.593, 21.933 (21.972)	Grad: 0.144, 0.223, 0.288, 0.365, 0.452
[Epoch  73 (99.97s)]	ELBO: 1540.310, 1637.584, 1684.544, 1704.856, 1710.543 (1710.547)	Log prob: 1547.707, 1650.613, 1701.809, 1725.457, 1732.522 (1732.673)	KLD: 7.398, 13.030, 17.265, 20.602, 21.979 (22.126)	Grad: 0.143, 0.221, 0.286, 0.364, 0.451
[Epoch  74 (90.28s)]	ELBO: 1540.675, 1638.000, 1684.920, 1705.230, 1711.123 (1710.257)	Log prob: 1548.091, 1651.052, 1702.209, 1725.850, 1733.321 (1732.821)	KLD: 7.415, 13.051, 17.290, 20.620, 22.198 (22.564)	Grad: 0.142, 0.219, 0.280, 0.356, 0.439
[Epoch  75 (75.06s)]	ELBO: 1540.988, 1638.030, 1684.944, 1705.203, 1711.523 (1710.952)	Log prob: 1548.400, 1651.075, 1702.226, 1725.804, 1733.988 (1733.661)	KLD: 7.412, 13.046, 17.281, 20.599, 22.465 (22.709)	Grad: 0.144, 0.224, 0.291, 0.370, 0.459
[Epoch  76 (72.31s)]	ELBO: 1541.409, 1638.491, 1685.332, 1705.445, 1712.251 (1711.259)	Log prob: 1548.837, 1651.557, 1702.628, 1726.073, 1734.915 (1733.753)	KLD: 7.428, 13.066, 17.295, 20.628, 22.665 (22.494)	Grad: 0.145, 0.223, 0.287, 0.365, 0.452
[Epoch  77 (79.05s)]	ELBO: 1542.017, 1638.788, 1685.546, 1705.685, 1712.944 (1712.461)	Log prob: 1549.458, 1651.874, 1702.861, 1726.342, 1735.740 (1735.307)	KLD: 7.440, 13.086, 17.315, 20.657, 22.797 (22.846)	Grad: 0.142, 0.221, 0.284, 0.360, 0.448
[Epoch  78 (79.58s)]	ELBO: 1542.120, 1639.042, 1685.628, 1705.686, 1713.280 (1711.508)	Log prob: 1549.552, 1652.119, 1702.925, 1726.326, 1736.135 (1734.082)	KLD: 7.431, 13.077, 17.298, 20.640, 22.855 (22.574)	Grad: 0.145, 0.224, 0.288, 0.368, 0.456
[Epoch  79 (78.83s)]	ELBO: 1542.548, 1639.248, 1685.896, 1705.901, 1713.733 (1712.276)	Log prob: 1549.988, 1652.340, 1703.211, 1726.559, 1736.685 (1735.217)	KLD: 7.441, 13.092, 17.316, 20.657, 22.952 (22.941)	Grad: 0.145, 0.222, 0.286, 0.363, 0.452
[Epoch  80 (78.00s)]	ELBO: 1542.831, 1639.477, 1686.022, 1706.199, 1714.254 (1712.907)	Log prob: 1550.281, 1652.584, 1703.354, 1726.869, 1737.274 (1735.776)	KLD: 7.449, 13.107, 17.331, 20.670, 23.020 (22.869)	Grad: 0.145, 0.223, 0.287, 0.365, 0.451
[Epoch  81 (80.34s)]	ELBO: 1543.117, 1639.918, 1686.314, 1706.365, 1714.644 (1713.113)	Log prob: 1550.560, 1653.019, 1703.636, 1727.024, 1737.661 (1736.089)	KLD: 7.443, 13.101, 17.323, 20.659, 23.018 (22.976)	Grad: 0.145, 0.222, 0.286, 0.362, 0.450
[Epoch  82 (61.02s)]	ELBO: 1543.589, 1640.119, 1686.470, 1706.544, 1714.824 (1714.152)	Log prob: 1551.051, 1653.241, 1703.821, 1727.236, 1737.922 (1737.254)	KLD: 7.463, 13.122, 17.352, 20.692, 23.096 (23.102)	Grad: 0.145, 0.222, 0.287, 0.365, 0.454
[Epoch  83 (72.08s)]	ELBO: 1543.969, 1640.346, 1686.844, 1706.961, 1715.362 (1714.284)	Log prob: 1551.435, 1653.479, 1704.195, 1727.655, 1738.476 (1737.586)	KLD: 7.466, 13.132, 17.350, 20.694, 23.115 (23.301)	Grad: 0.145, 0.222, 0.285, 0.361, 0.447
[Epoch  84 (61.00s)]	ELBO: 1544.315, 1640.738, 1687.061, 1707.156, 1715.653 (1715.017)	Log prob: 1551.791, 1653.882, 1704.435, 1727.876, 1738.818 (1738.240)	KLD: 7.476, 13.142, 17.375, 20.720, 23.165 (23.223)	Grad: 0.143, 0.219, 0.281, 0.358, 0.446
[Epoch  85 (62.52s)]	ELBO: 1544.763, 1640.760, 1687.159, 1707.226, 1715.851 (1714.386)	Log prob: 1552.246, 1653.902, 1704.529, 1727.932, 1739.010 (1737.511)	KLD: 7.483, 13.143, 17.369, 20.706, 23.161 (23.125)	Grad: 0.144, 0.220, 0.284, 0.362, 0.449
[Epoch  86 (63.90s)]	ELBO: 1544.724, 1640.786, 1687.086, 1707.190, 1715.796 (1714.772)	Log prob: 1552.192, 1653.909, 1704.434, 1727.888, 1738.952 (1737.984)	KLD: 7.468, 13.123, 17.349, 20.698, 23.155 (23.212)	Grad: 0.146, 0.224, 0.290, 0.369, 0.459
[Epoch  87 (69.73s)]	ELBO: 1545.039, 1640.990, 1687.314, 1707.556, 1716.172 (1715.429)	Log prob: 1552.521, 1654.143, 1704.692, 1728.293, 1739.368 (1738.631)	KLD: 7.480, 13.152, 17.377, 20.737, 23.196 (23.202)	Grad: 0.146, 0.223, 0.285, 0.363, 0.449
[Epoch  88 (67.08s)]	ELBO: 1545.516, 1641.492, 1687.770, 1707.854, 1716.598 (1715.367)	Log prob: 1553.005, 1654.658, 1705.154, 1728.594, 1739.800 (1738.636)	KLD: 7.490, 13.167, 17.386, 20.742, 23.202 (23.269)	Grad: 0.146, 0.221, 0.283, 0.359, 0.444
[Epoch  89 (68.55s)]	ELBO: 1545.804, 1641.452, 1687.754, 1707.815, 1716.534 (1715.956)	Log prob: 1553.294, 1654.618, 1705.146, 1728.562, 1739.755 (1738.947)	KLD: 7.490, 13.166, 17.391, 20.747, 23.220 (22.991)	Grad: 0.144, 0.222, 0.290, 0.371, 0.461
[Epoch  90 (64.13s)]	ELBO: 1545.943, 1641.762, 1687.913, 1708.041, 1716.819 (1715.114)	Log prob: 1553.439, 1654.931, 1705.305, 1728.777, 1740.034 (1738.206)	KLD: 7.496, 13.170, 17.391, 20.737, 23.215 (23.092)	Grad: 0.146, 0.223, 0.287, 0.366, 0.452
[Epoch  91 (62.72s)]	ELBO: 1546.021, 1641.851, 1688.036, 1708.115, 1716.908 (1716.129)	Log prob: 1553.521, 1655.031, 1705.438, 1728.876, 1740.142 (1739.350)	KLD: 7.499, 13.181, 17.401, 20.759, 23.233 (23.222)	Grad: 0.146, 0.224, 0.287, 0.365, 0.452
[Epoch  92 (67.27s)]	ELBO: 1546.480, 1642.327, 1688.416, 1708.564, 1717.410 (1715.829)	Log prob: 1553.980, 1655.517, 1705.832, 1729.336, 1740.660 (1739.062)	KLD: 7.501, 13.189, 17.415, 20.771, 23.248 (23.234)	Grad: 0.146, 0.221, 0.283, 0.360, 0.445
[Epoch  93 (68.72s)]	ELBO: 1546.895, 1642.558, 1688.557, 1708.720, 1717.509 (1716.897)	Log prob: 1554.411, 1655.759, 1705.979, 1729.503, 1740.764 (1740.211)	KLD: 7.515, 13.201, 17.424, 20.782, 23.254 (23.315)	Grad: 0.145, 0.220, 0.282, 0.359, 0.445
[Epoch  94 (64.05s)]	ELBO: 1547.126, 1642.536, 1688.619, 1708.782, 1717.590 (1716.558)	Log prob: 1554.644, 1655.742, 1706.049, 1729.568, 1740.860 (1739.566)	KLD: 7.518, 13.207, 17.431, 20.784, 23.270 (23.009)	Grad: 0.147, 0.222, 0.286, 0.361, 0.446
[Epoch  95 (57.23s)]	ELBO: 1547.373, 1642.726, 1688.689, 1708.896, 1717.648 (1716.817)	Log prob: 1554.890, 1655.929, 1706.107, 1729.684, 1740.914 (1740.291)	KLD: 7.517, 13.202, 17.417, 20.786, 23.266 (23.474)	Grad: 0.146, 0.222, 0.287, 0.365, 0.452
[Epoch  96 (53.63s)]	ELBO: 1547.476, 1643.041, 1689.147, 1709.193, 1718.032 (1715.472)	Log prob: 1554.994, 1656.252, 1706.590, 1729.995, 1741.328 (1738.859)	KLD: 7.519, 13.211, 17.443, 20.803, 23.297 (23.387)	Grad: 0.146, 0.221, 0.284, 0.360, 0.445
[Epoch  97 (52.02s)]	ELBO: 1547.854, 1643.264, 1689.258, 1709.331, 1718.061 (1718.172)	Log prob: 1555.380, 1656.483, 1706.696, 1730.140, 1741.355 (1741.137)	KLD: 7.526, 13.219, 17.439, 20.808, 23.294 (22.965)	Grad: 0.144, 0.220, 0.283, 0.359, 0.444
[Epoch  98 (51.93s)]	ELBO: 1548.178, 1643.545, 1689.583, 1709.619, 1718.357 (1716.201)	Log prob: 1555.701, 1656.761, 1707.021, 1730.411, 1741.616 (1739.496)	KLD: 7.524, 13.215, 17.440, 20.792, 23.258 (23.295)	Grad: 0.145, 0.220, 0.284, 0.361, 0.446
[Epoch  99 (53.34s)]	ELBO: 1548.384, 1643.719, 1689.594, 1709.727, 1718.443 (1716.667)	Log prob: 1555.914, 1656.948, 1707.043, 1730.545, 1741.737 (1739.808)	KLD: 7.530, 13.229, 17.448, 20.819, 23.294 (23.141)	Grad: 0.146, 0.219, 0.282, 0.358, 0.444
[Epoch 100 (64.59s)]	ELBO: 1548.622, 1643.760, 1689.747, 1709.805, 1718.523 (1716.615)	Log prob: 1556.157, 1656.996, 1707.201, 1730.623, 1741.818 (1740.202)	KLD: 7.534, 13.236, 17.454, 20.819, 23.296 (23.587)	Grad: 0.145, 0.221, 0.283, 0.359, 0.444
Best epoch(s): [97]	Training time(s): 6619.99s (6619.99s)	Best ELBO: 1718.523 (1718.172)	Best log prob: 1741.818 (1741.137)
Avg. mu: 0.037, -0.008, -0.151, -0.031, -0.143, -0.024, -0.021, -0.020, -0.079, 0.053
Avg. var: 0.002, 0.002, 0.004, 0.007, 0.018, 0.014, 0.049, 0.033, 0.082, 0.106
Max. mu: 4.561, 4.239, 3.108, 3.603, 4.660, 3.811, 4.177, 4.091, 4.824, 3.891
Max. var: 0.042, 0.020, 0.037, 0.099, 0.076, 0.078, 0.227, 0.126, 0.338, 0.375
Min. mu: -3.909, -4.438, -3.883, -3.965, -3.891, -3.863, -4.015, -4.452, -4.583, -4.463
Min. var: 0.000, 0.000, 0.001, 0.001, 0.005, 0.002, 0.016, 0.012, 0.031, 0.040
Cov. mu:
[[1.757 -0.045 0.225 0.158 -0.006 0.059 0.061 -0.176 -0.018 -0.121]
 [-0.045 1.797 -0.336 -0.227 0.043 0.093 -0.159 -0.088 -0.031 0.082]
 [0.225 -0.336 1.219 0.179 0.044 0.019 0.076 0.035 -0.036 -0.047]
 [0.158 -0.227 0.179 1.011 -0.004 -0.040 -0.025 0.071 -0.080 0.035]
 [-0.006 0.043 0.044 -0.004 1.010 -0.009 0.072 0.069 0.002 0.024]
 [0.059 0.093 0.019 -0.040 -0.009 0.935 -0.033 -0.019 -0.119 0.026]
 [0.061 -0.159 0.076 -0.025 0.072 -0.033 0.990 -0.024 0.058 -0.031]
 [-0.176 -0.088 0.035 0.071 0.069 -0.019 -0.024 0.904 -0.012 -0.045]
 [-0.018 -0.031 -0.036 -0.080 0.002 -0.119 0.058 -0.012 0.890 -0.009]
 [-0.121 0.082 -0.047 0.035 0.024 0.026 -0.031 -0.045 -0.009 0.971]]
Avg. mu: 0.037, -0.008, -0.151, -0.031, -0.143, -0.024, -0.021, -0.020, -0.079, 0.053
Avg. var: 0.002, 0.002, 0.004, 0.007, 0.018, 0.014, 0.049, 0.033, 0.082, 0.106
Max. mu: 4.561, 4.239, 3.108, 3.603, 4.660, 3.811, 4.177, 4.091, 4.824, 3.891
Max. var: 0.042, 0.020, 0.037, 0.099, 0.076, 0.078, 0.227, 0.126, 0.338, 0.375
Min. mu: -3.909, -4.438, -3.883, -3.965, -3.891, -3.863, -4.015, -4.452, -4.583, -4.463
Min. var: 0.000, 0.000, 0.001, 0.001, 0.005, 0.002, 0.016, 0.012, 0.031, 0.040
Cov. mu:
[[1.757 -0.045 0.225 0.158 -0.006 0.059 0.061 -0.176 -0.018 -0.121]
 [-0.045 1.797 -0.336 -0.227 0.043 0.093 -0.159 -0.088 -0.031 0.082]
 [0.225 -0.336 1.219 0.179 0.044 0.019 0.076 0.035 -0.036 -0.047]
 [0.158 -0.227 0.179 1.011 -0.004 -0.040 -0.025 0.071 -0.080 0.035]
 [-0.006 0.043 0.044 -0.004 1.010 -0.009 0.072 0.069 0.002 0.024]
 [0.059 0.093 0.019 -0.040 -0.009 0.935 -0.033 -0.019 -0.119 0.026]
 [0.061 -0.159 0.076 -0.025 0.072 -0.033 0.990 -0.024 0.058 -0.031]
 [-0.176 -0.088 0.035 0.071 0.069 -0.019 -0.024 0.904 -0.012 -0.045]
 [-0.018 -0.031 -0.036 -0.080 0.002 -0.119 0.058 -0.012 0.890 -0.009]
 [-0.121 0.082 -0.047 0.035 0.024 0.026 -0.031 -0.045 -0.009 0.971]]
Avg. mu: 0.037, -0.008, -0.151, -0.031, -0.143, -0.024, -0.021, -0.020, -0.079, 0.053
Avg. var: 0.002, 0.002, 0.004, 0.007, 0.018, 0.014, 0.049, 0.033, 0.082, 0.106
Max. mu: 4.561, 4.239, 3.108, 3.603, 4.660, 3.811, 4.177, 4.091, 4.824, 3.891
Max. var: 0.042, 0.020, 0.037, 0.099, 0.076, 0.078, 0.227, 0.126, 0.338, 0.375
Min. mu: -3.909, -4.438, -3.883, -3.965, -3.891, -3.863, -4.015, -4.452, -4.583, -4.463
Min. var: 0.000, 0.000, 0.001, 0.001, 0.005, 0.002, 0.016, 0.012, 0.031, 0.040
Cov. mu:
[[1.757 -0.045 0.225 0.158 -0.006 0.059 0.061 -0.176 -0.018 -0.121]
 [-0.045 1.797 -0.336 -0.227 0.043 0.093 -0.159 -0.088 -0.031 0.082]
 [0.225 -0.336 1.219 0.179 0.044 0.019 0.076 0.035 -0.036 -0.047]
 [0.158 -0.227 0.179 1.011 -0.004 -0.040 -0.025 0.071 -0.080 0.035]
 [-0.006 0.043 0.044 -0.004 1.010 -0.009 0.072 0.069 0.002 0.024]
 [0.059 0.093 0.019 -0.040 -0.009 0.935 -0.033 -0.019 -0.119 0.026]
 [0.061 -0.159 0.076 -0.025 0.072 -0.033 0.990 -0.024 0.058 -0.031]
 [-0.176 -0.088 0.035 0.071 0.069 -0.019 -0.024 0.904 -0.012 -0.045]
 [-0.018 -0.031 -0.036 -0.080 0.002 -0.119 0.058 -0.012 0.890 -0.009]
 [-0.121 0.082 -0.047 0.035 0.024 0.026 -0.031 -0.045 -0.009 0.971]]
