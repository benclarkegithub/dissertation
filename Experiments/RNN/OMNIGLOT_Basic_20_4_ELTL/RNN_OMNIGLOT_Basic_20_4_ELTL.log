Encoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Encoder                                  --
├─Linear: 1-1                            882,080
├─Linear: 1-2                            6,480
=================================================================
Total params: 888,560
Trainable params: 888,560
Non-trainable params: 0
=================================================================
Encoder 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Encoder                                  --
├─Linear: 1-1                            882,080
├─Linear: 1-2                            6,480
=================================================================
Total params: 888,560
Trainable params: 888,560
Non-trainable params: 0
=================================================================
Encoder Encoder to Encoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderEncoderToEncoder                  --
├─Linear: 1-1                            12,880
├─Linear: 1-2                            6,480
=================================================================
Total params: 19,360
Trainable params: 19,360
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            6,480
├─Linear: 1-2                            324
├─Linear: 1-3                            324
=================================================================
Total params: 7,128
Trainable params: 7,128
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            7,832
├─Linear: 1-2                            356
├─Linear: 1-3                            356
=================================================================
Total params: 8,544
Trainable params: 8,544
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            9,312
├─Linear: 1-2                            388
├─Linear: 1-3                            388
=================================================================
Total params: 10,088
Trainable params: 10,088
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            10,920
├─Linear: 1-2                            420
├─Linear: 1-3                            420
=================================================================
Total params: 11,760
Trainable params: 11,760
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 4
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            12,656
├─Linear: 1-2                            452
├─Linear: 1-3                            452
=================================================================
Total params: 13,560
Trainable params: 13,560
Non-trainable params: 0
=================================================================
Latents to Decoder 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            400
=================================================================
Total params: 400
Trainable params: 400
Non-trainable params: 0
=================================================================
Latents to Decoder 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            400
=================================================================
Total params: 400
Trainable params: 400
Non-trainable params: 0
=================================================================
Latents to Decoder 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            400
=================================================================
Total params: 400
Trainable params: 400
Non-trainable params: 0
=================================================================
Latents to Decoder 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            400
=================================================================
Total params: 400
Trainable params: 400
Non-trainable params: 0
=================================================================
Latents to Decoder 4
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            400
=================================================================
Total params: 400
Trainable params: 400
Non-trainable params: 0
=================================================================
Decoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Decoder                                  --
├─Linear: 1-1                            6,480
├─Linear: 1-2                            893,025
=================================================================
Total params: 899,505
Trainable params: 899,505
Non-trainable params: 0
=================================================================
[Epoch   1 (28.77s)]	ELBO: 11548.989, 12954.412, 13207.742, 13273.625, 13205.262 (20127.767)	Log prob: 11753.266, 13216.611, 13529.245, 13618.564, 13600.164 (20373.357)	KLD: 204.278, 57.918, 59.303, 23.439, 49.965 (245.591)	Grad: 36.291, 8.081, 6.297, 2.563, 7.828
[Epoch   2 (46.21s)]	ELBO: 20147.477, 20175.695, 20166.271, 20144.688, 20113.320 (20479.457)	Log prob: 20292.555, 20321.662, 20315.006, 20295.641, 20266.535 (20590.841)	KLD: 145.079, 0.890, 2.762, 2.219, 2.267 (111.384)	Grad: 11.860, 0.690, 0.522, 0.270, 0.363
[Epoch   3 (46.31s)]	ELBO: 20299.598, 20311.732, 20297.184, 20276.789, 20251.047 (20515.342)	Log prob: 20390.566, 20404.602, 20393.074, 20377.004, 20355.805 (20614.421)	KLD: 90.968, 1.899, 3.020, 4.329, 4.542 (99.079)	Grad: 11.715, 0.462, 0.331, 0.235, 0.342
[Epoch   4 (45.38s)]	ELBO: 20358.150, 20370.191, 20357.078, 20341.781, 20321.354 (20612.824)	Log prob: 20430.180, 20444.654, 20434.797, 20423.504, 20407.559 (20684.239)	KLD: 72.026, 2.435, 3.262, 3.997, 4.482 (71.413)	Grad: 9.568, 0.491, 0.249, 0.210, 0.290
[Epoch   5 (39.43s)]	ELBO: 20403.148, 20420.201, 20409.812, 20397.492, 20382.891 (20686.871)	Log prob: 20463.725, 20483.656, 20476.512, 20467.863, 20457.637 (20751.965)	KLD: 60.572, 2.887, 3.240, 3.670, 4.377 (65.094)	Grad: 9.032, 0.564, 0.404, 0.351, 0.400
[Epoch   6 (41.03s)]	ELBO: 20446.736, 20468.521, 20459.803, 20451.184, 20440.295 (20715.923)	Log prob: 20499.324, 20524.443, 20519.051, 20513.973, 20507.100 (20777.341)	KLD: 52.588, 3.339, 3.320, 3.541, 4.018 (61.417)	Grad: 9.197, 0.805, 0.571, 0.520, 0.499
[Epoch   7 (37.60s)]	ELBO: 20416.953, 20435.482, 20425.553, 20417.832, 20408.785 (20695.104)	Log prob: 20463.631, 20485.725, 20479.246, 20475.131, 20470.113 (20753.706)	KLD: 46.679, 3.568, 3.445, 3.608, 4.027 (58.603)	Grad: 11.437, 1.191, 0.858, 0.759, 0.720
[Epoch   8 (37.39s)]	ELBO: 20456.102, 20475.145, 20470.777, 20466.785, 20461.098 (20723.242)	Log prob: 20500.109, 20522.277, 20520.797, 20520.041, 20517.869 (20771.428)	KLD: 44.005, 3.132, 2.881, 3.236, 3.516 (48.187)	Grad: 8.800, 0.756, 0.539, 0.549, 0.510
[Epoch   9 (36.75s)]	ELBO: 20483.184, 20502.816, 20499.971, 20500.246, 20497.818 (20699.540)	Log prob: 20522.729, 20545.934, 20546.215, 20549.785, 20550.613 (20744.874)	KLD: 39.543, 3.577, 3.128, 3.294, 3.257 (45.334)	Grad: 8.512, 0.786, 0.630, 0.639, 0.620
[Epoch  10 (36.38s)]	ELBO: 20469.854, 20491.299, 20486.859, 20487.498, 20483.977 (20815.871)	Log prob: 20506.750, 20532.703, 20531.777, 20536.096, 20535.662 (20868.720)	KLD: 36.892, 4.512, 3.513, 3.678, 3.094 (52.848)	Grad: 10.096, 1.003, 0.773, 0.744, 0.702
[Epoch  11 (37.29s)]	ELBO: 20561.504, 20593.066, 20595.334, 20600.729, 20599.492 (20846.341)	Log prob: 20596.484, 20633.182, 20638.984, 20647.861, 20649.479 (20899.103)	KLD: 34.975, 5.142, 3.532, 3.480, 2.854 (52.762)	Grad: 5.566, 0.449, 0.304, 0.295, 0.291
[Epoch  12 (37.64s)]	ELBO: 20549.033, 20595.609, 20599.465, 20602.635, 20599.516 (20731.968)	Log prob: 20581.484, 20635.133, 20642.891, 20649.391, 20648.791 (20776.673)	KLD: 32.451, 7.074, 3.902, 3.329, 2.516 (44.706)	Grad: 5.593, 0.695, 0.505, 0.493, 0.473
[Epoch  13 (37.08s)]	ELBO: 20443.373, 20518.387, 20515.369, 20512.971, 20503.789 (20638.566)	Log prob: 20471.939, 20555.359, 20556.266, 20557.309, 20550.697 (20681.276)	KLD: 28.562, 8.409, 3.925, 3.442, 2.574 (42.710)	Grad: 12.953, 1.759, 1.265, 1.047, 1.217
[Epoch  14 (37.63s)]	ELBO: 20520.926, 20621.047, 20624.135, 20622.266, 20620.197 (20927.172)	Log prob: 20549.453, 20658.705, 20665.029, 20665.930, 20666.197 (20976.320)	KLD: 28.528, 9.129, 3.244, 2.767, 2.330 (49.148)	Grad: 7.396, 1.016, 0.659, 0.530, 0.493
[Epoch  15 (40.37s)]	ELBO: 20544.791, 20715.484, 20719.262, 20720.527, 20718.176 (20933.991)	Log prob: 20572.117, 20753.988, 20761.496, 20765.416, 20765.311 (20984.956)	KLD: 27.327, 11.169, 3.734, 2.655, 2.256 (50.965)	Grad: 4.505, 0.912, 0.452, 0.376, 0.347
[Epoch  16 (41.91s)]	ELBO: 20525.400, 20715.621, 20715.037, 20714.178, 20711.209 (20948.667)	Log prob: 20550.896, 20752.438, 20755.416, 20757.410, 20756.582 (20997.313)	KLD: 25.493, 11.327, 3.556, 2.855, 2.137 (48.646)	Grad: 7.446, 2.086, 1.056, 0.822, 0.738
[Epoch  17 (43.08s)]	ELBO: 20540.240, 20742.578, 20742.623, 20745.191, 20742.039 (20922.327)	Log prob: 20565.033, 20777.805, 20781.061, 20786.506, 20785.578 (20964.896)	KLD: 24.793, 10.438, 3.206, 2.882, 2.216 (42.570)	Grad: 6.385, 1.627, 0.792, 0.656, 0.609
[Epoch  18 (41.95s)]	ELBO: 20524.500, 20729.160, 20726.611, 20729.010, 20725.771 (20984.754)	Log prob: 20548.703, 20763.717, 20764.254, 20769.553, 20768.420 (21023.759)	KLD: 24.207, 10.355, 3.081, 2.901, 2.106 (39.006)	Grad: 6.543, 2.055, 0.973, 0.806, 0.752
[Epoch  19 (37.86s)]	ELBO: 20606.928, 20771.750, 20771.516, 20775.254, 20772.643 (21057.604)	Log prob: 20631.734, 20805.576, 20808.289, 20814.707, 20814.078 (21103.051)	KLD: 24.808, 9.017, 2.951, 2.680, 1.979 (45.446)	Grad: 5.484, 1.742, 0.776, 0.642, 0.568
[Epoch  20 (37.35s)]	ELBO: 20713.213, 20810.865, 20812.818, 20814.941, 20813.100 (21088.610)	Log prob: 20739.705, 20845.379, 20850.311, 20854.994, 20855.078 (21133.605)	KLD: 26.497, 8.016, 2.985, 2.557, 1.924 (44.995)	Grad: 3.737, 1.200, 0.476, 0.444, 0.401
[Epoch  21 (37.86s)]	ELBO: 20817.244, 20833.297, 20830.562, 20828.434, 20823.902 (21090.012)	Log prob: 20846.537, 20868.127, 20868.041, 20868.246, 20865.584 (21129.581)	KLD: 29.293, 5.538, 2.654, 2.327, 1.871 (39.569)	Grad: 5.593, 1.785, 0.786, 0.732, 0.663
[Epoch  22 (36.95s)]	ELBO: 20895.336, 20899.982, 20896.219, 20894.211, 20891.879 (21145.648)	Log prob: 20926.197, 20935.189, 20933.625, 20933.709, 20933.076 (21198.620)	KLD: 30.857, 4.351, 2.202, 2.088, 1.697 (52.972)	Grad: 5.052, 1.516, 0.650, 0.543, 0.500
[Epoch  23 (38.27s)]	ELBO: 20937.340, 20940.902, 20937.133, 20934.721, 20930.703 (21175.379)	Log prob: 20968.252, 20976.162, 20974.547, 20974.105, 20971.771 (21215.487)	KLD: 30.909, 4.349, 2.152, 1.971, 1.681 (40.110)	Grad: 6.185, 1.087, 0.617, 0.592, 0.525
[Epoch  24 (35.29s)]	ELBO: 20977.246, 20980.783, 20977.979, 20975.277, 20972.082 (21222.493)	Log prob: 21006.896, 21014.629, 21013.916, 21013.232, 21011.734 (21270.404)	KLD: 29.652, 4.194, 2.092, 2.012, 1.700 (47.911)	Grad: 5.680, 0.923, 0.507, 0.481, 0.449
[Epoch  25 (35.18s)]	ELBO: 20971.990, 20972.979, 20970.432, 20967.504, 20963.656 (21258.479)	Log prob: 21000.979, 21006.215, 21005.701, 21004.658, 21002.414 (21302.614)	KLD: 28.984, 4.251, 2.038, 1.874, 1.613 (44.136)	Grad: 5.273, 1.112, 0.530, 0.479, 0.438
[Epoch  26 (33.13s)]	ELBO: 21016.771, 21017.676, 21014.545, 21012.816, 21010.285 (21281.304)	Log prob: 21045.295, 21050.430, 21049.273, 21049.434, 21048.529 (21322.006)	KLD: 28.526, 4.231, 1.972, 1.888, 1.630 (40.702)	Grad: 4.002, 0.793, 0.413, 0.365, 0.358
[Epoch  27 (35.28s)]	ELBO: 21007.500, 21007.613, 21004.172, 21001.559, 20998.781 (21238.807)	Log prob: 21034.658, 21039.016, 21037.605, 21036.918, 21035.602 (21283.148)	KLD: 27.156, 4.247, 2.034, 1.919, 1.463 (44.342)	Grad: 6.164, 1.055, 0.553, 0.516, 0.496
[Epoch  28 (35.16s)]	ELBO: 21009.541, 21005.432, 21002.822, 20999.684, 20997.457 (21291.903)	Log prob: 21036.500, 21036.152, 21035.500, 21034.129, 21033.238 (21332.465)	KLD: 26.959, 3.761, 1.959, 1.771, 1.331 (40.562)	Grad: 5.978, 1.379, 0.619, 0.545, 0.493
[Epoch  29 (34.35s)]	ELBO: 21031.521, 21033.521, 21030.354, 21028.072, 21026.791 (21305.407)	Log prob: 21057.852, 21063.834, 21062.617, 21062.094, 21062.234 (21342.736)	KLD: 26.328, 3.984, 1.953, 1.762, 1.415 (37.329)	Grad: 3.727, 0.727, 0.381, 0.347, 0.341
[Epoch  30 (33.63s)]	ELBO: 21053.436, 21053.695, 21051.459, 21049.455, 21047.406 (21311.311)	Log prob: 21079.467, 21083.850, 21083.594, 21083.281, 21082.533 (21351.664)	KLD: 26.033, 4.123, 1.979, 1.690, 1.302 (40.354)	Grad: 4.958, 1.003, 0.484, 0.440, 0.439
[Epoch  31 (34.55s)]	ELBO: 21058.084, 21058.652, 21056.188, 21054.598, 21052.609 (21334.471)	Log prob: 21083.463, 21088.115, 21087.533, 21087.621, 21087.053 (21372.839)	KLD: 25.382, 4.083, 1.875, 1.686, 1.421 (38.368)	Grad: 5.508, 0.850, 0.485, 0.446, 0.458
[Epoch  32 (37.34s)]	ELBO: 21071.783, 21070.740, 21068.418, 21065.984, 21063.924 (21345.871)	Log prob: 21097.152, 21100.129, 21099.699, 21098.961, 21098.287 (21383.592)	KLD: 25.363, 4.028, 1.893, 1.694, 1.382 (37.721)	Grad: 5.564, 0.878, 0.485, 0.453, 0.455
[Epoch  33 (37.12s)]	ELBO: 21100.223, 21099.361, 21098.385, 21096.885, 21094.871 (21313.582)	Log prob: 21125.420, 21128.443, 21129.234, 21129.295, 21128.615 (21346.341)	KLD: 25.201, 3.879, 1.770, 1.562, 1.340 (32.760)	Grad: 4.140, 0.867, 0.440, 0.371, 0.362
[Epoch  34 (36.36s)]	ELBO: 21086.645, 21087.215, 21085.873, 21084.186, 21082.541 (21317.046)	Log prob: 21111.342, 21115.891, 21116.359, 21116.215, 21115.896 (21356.825)	KLD: 24.701, 3.974, 1.813, 1.535, 1.336 (39.779)	Grad: 6.094, 1.288, 0.615, 0.532, 0.499
[Epoch  35 (39.49s)]	ELBO: 21109.090, 21111.822, 21112.104, 21111.072, 21108.650 (21308.396)	Log prob: 21134.111, 21140.840, 21142.963, 21143.473, 21142.314 (21351.756)	KLD: 25.017, 4.005, 1.843, 1.538, 1.261 (43.361)	Grad: 3.873, 0.793, 0.405, 0.356, 0.337
[Epoch  36 (37.42s)]	ELBO: 21097.320, 21102.004, 21102.504, 21102.070, 21099.432 (21407.600)	Log prob: 21122.031, 21131.004, 21133.578, 21134.652, 21133.203 (21442.481)	KLD: 24.712, 4.292, 2.062, 1.518, 1.187 (34.880)	Grad: 6.009, 1.242, 0.592, 0.520, 0.498
[Epoch  37 (37.83s)]	ELBO: 21130.965, 21143.867, 21148.125, 21147.547, 21145.941 (21414.441)	Log prob: 21155.924, 21173.240, 21179.996, 21180.936, 21180.615 (21451.395)	KLD: 24.956, 4.415, 2.499, 1.515, 1.287 (36.953)	Grad: 6.000, 1.143, 0.687, 0.547, 0.510
[Epoch  38 (37.71s)]	ELBO: 21159.871, 21200.812, 21215.555, 21213.342, 21212.346 (21461.675)	Log prob: 21184.598, 21231.396, 21250.312, 21249.920, 21250.301 (21503.502)	KLD: 24.722, 5.864, 4.168, 1.824, 1.379 (41.826)	Grad: 4.383, 0.989, 0.551, 0.417, 0.369
[Epoch  39 (37.29s)]	ELBO: 21202.145, 21272.996, 21281.047, 21280.482, 21278.150 (21558.787)	Log prob: 21228.486, 21308.186, 21320.072, 21321.770, 21320.938 (21606.040)	KLD: 26.344, 8.845, 3.838, 2.260, 1.497 (47.253)	Grad: 6.415, 1.238, 0.758, 0.555, 0.497
[Epoch  40 (36.57s)]	ELBO: 21308.828, 21361.652, 21362.488, 21362.703, 21361.590 (21627.784)	Log prob: 21338.309, 21398.438, 21402.043, 21404.027, 21404.381 (21676.120)	KLD: 29.480, 7.304, 2.774, 1.764, 1.471 (48.336)	Grad: 7.381, 1.663, 0.876, 0.674, 0.588
[Epoch  41 (37.21s)]	ELBO: 21386.424, 21415.119, 21413.041, 21411.920, 21409.371 (21694.101)	Log prob: 21417.684, 21451.744, 21451.984, 21452.402, 21451.254 (21738.152)	KLD: 31.262, 5.366, 2.320, 1.534, 1.406 (44.049)	Grad: 7.039, 1.430, 0.792, 0.649, 0.590
[Epoch  42 (38.48s)]	ELBO: 21485.871, 21499.371, 21497.990, 21496.578, 21495.232 (21725.669)	Log prob: 21517.838, 21535.967, 21536.811, 21536.998, 21537.070 (21773.378)	KLD: 31.963, 4.628, 2.226, 1.599, 1.416 (47.709)	Grad: 4.827, 0.865, 0.499, 0.415, 0.380
[Epoch  43 (38.39s)]	ELBO: 21509.994, 21516.658, 21514.539, 21512.543, 21511.137 (21706.495)	Log prob: 21542.066, 21553.186, 21553.270, 21552.842, 21552.947 (21745.011)	KLD: 32.075, 4.456, 2.202, 1.563, 1.514 (38.517)	Grad: 6.471, 1.234, 0.634, 0.579, 0.527
[Epoch  44 (36.38s)]	ELBO: 21496.623, 21499.188, 21495.854, 21494.582, 21492.998 (21761.498)	Log prob: 21528.234, 21535.133, 21533.859, 21534.262, 21534.297 (21802.884)	KLD: 31.612, 4.337, 2.060, 1.675, 1.614 (41.384)	Grad: 8.417, 1.532, 0.839, 0.756, 0.655
[Epoch  45 (37.73s)]	ELBO: 21543.545, 21549.039, 21548.307, 21548.838, 21547.973 (21791.785)	Log prob: 21575.516, 21585.395, 21586.617, 21588.848, 21589.521 (21837.225)	KLD: 31.973, 4.385, 1.954, 1.703, 1.534 (45.441)	Grad: 4.188, 0.795, 0.498, 0.448, 0.382
[Epoch  46 (37.08s)]	ELBO: 21585.115, 21590.672, 21594.322, 21598.729, 21595.834 (21662.305)	Log prob: 21617.566, 21627.566, 21633.506, 21639.984, 21638.824 (21698.288)	KLD: 32.446, 4.443, 2.291, 2.074, 1.732 (35.983)	Grad: 5.212, 0.916, 0.562, 0.511, 0.478
[Epoch  47 (36.87s)]	ELBO: 21553.635, 21563.965, 21582.020, 21584.828, 21582.322 (21830.262)	Log prob: 21585.303, 21600.109, 21621.961, 21627.082, 21626.281 (21876.660)	KLD: 31.666, 4.481, 3.798, 2.306, 1.701 (46.397)	Grad: 8.032, 1.482, 1.021, 0.788, 0.679
[Epoch  48 (38.31s)]	ELBO: 21571.254, 21585.758, 21616.674, 21616.758, 21614.611 (21900.796)	Log prob: 21602.953, 21621.850, 21657.709, 21660.279, 21660.205 (21942.551)	KLD: 31.699, 4.394, 4.938, 2.487, 2.069 (41.756)	Grad: 7.464, 1.485, 1.056, 0.702, 0.624
[Epoch  49 (38.15s)]	ELBO: 21620.424, 21654.762, 21698.354, 21698.453, 21697.109 (21845.388)	Log prob: 21652.598, 21692.119, 21741.049, 21743.289, 21743.768 (21895.996)	KLD: 32.174, 5.184, 5.334, 2.151, 1.814 (50.608)	Grad: 6.047, 1.263, 0.895, 0.581, 0.489
[Epoch  50 (38.11s)]	ELBO: 21616.869, 21671.586, 21704.881, 21703.227, 21703.115 (21846.521)	Log prob: 21648.443, 21709.205, 21747.467, 21747.854, 21749.266 (21895.224)	KLD: 31.572, 6.052, 4.962, 2.047, 1.516 (48.704)	Grad: 7.807, 1.395, 1.220, 0.722, 0.640
[Epoch  51 (37.72s)]	ELBO: 21649.322, 21733.172, 21770.309, 21770.268, 21768.684 (21952.945)	Log prob: 21680.953, 21771.906, 21814.459, 21816.379, 21816.256 (22000.496)	KLD: 31.639, 7.098, 5.409, 1.968, 1.459 (47.550)	Grad: 6.504, 1.263, 0.940, 0.597, 0.547
[Epoch  52 (36.80s)]	ELBO: 21667.139, 21774.719, 21807.947, 21806.576, 21806.146 (21992.655)	Log prob: 21698.209, 21813.523, 21851.684, 21852.031, 21852.939 (22036.775)	KLD: 31.069, 7.739, 4.928, 1.722, 1.336 (44.121)	Grad: 4.478, 1.108, 0.650, 0.421, 0.377
[Epoch  53 (37.74s)]	ELBO: 21665.383, 21796.662, 21821.996, 21822.059, 21819.971 (21989.650)	Log prob: 21696.295, 21835.859, 21865.771, 21867.416, 21866.590 (22038.224)	KLD: 30.911, 8.287, 4.579, 1.585, 1.261 (48.575)	Grad: 5.598, 1.457, 0.898, 0.532, 0.500
[Epoch  54 (37.44s)]	ELBO: 21683.297, 21829.227, 21853.371, 21852.855, 21850.611 (22035.874)	Log prob: 21713.859, 21868.229, 21896.730, 21897.785, 21896.742 (22084.203)	KLD: 30.563, 8.442, 4.357, 1.570, 1.199 (48.328)	Grad: 5.533, 1.377, 0.847, 0.530, 0.495
[Epoch  55 (37.65s)]	ELBO: 21653.564, 21804.270, 21826.762, 21826.340, 21823.098 (22017.594)	Log prob: 21683.021, 21841.996, 21868.660, 21869.895, 21867.896 (22066.858)	KLD: 29.459, 8.266, 4.173, 1.656, 1.246 (49.263)	Grad: 8.450, 2.167, 1.090, 0.741, 0.686
[Epoch  56 (36.70s)]	ELBO: 21701.531, 21869.879, 21888.703, 21887.465, 21885.682 (22048.501)	Log prob: 21731.025, 21907.789, 21930.588, 21930.854, 21930.271 (22096.325)	KLD: 29.494, 8.418, 3.974, 1.501, 1.204 (47.825)	Grad: 5.543, 1.506, 0.839, 0.538, 0.490
[Epoch  57 (36.85s)]	ELBO: 21724.830, 21898.098, 21915.662, 21914.719, 21913.271 (22090.934)	Log prob: 21754.814, 21936.768, 21958.365, 21959.037, 21958.744 (22135.008)	KLD: 29.983, 8.689, 4.036, 1.607, 1.151 (44.074)	Grad: 4.193, 1.150, 0.647, 0.395, 0.386
[Epoch  58 (37.62s)]	ELBO: 21728.943, 21907.777, 21924.537, 21924.184, 21921.996 (22037.761)	Log prob: 21757.912, 21945.322, 21966.121, 21967.385, 21966.330 (22086.592)	KLD: 28.974, 8.573, 4.037, 1.616, 1.132 (48.831)	Grad: 5.742, 1.820, 0.928, 0.596, 0.546
[Epoch  59 (37.25s)]	ELBO: 21730.359, 21915.615, 21930.820, 21929.602, 21928.139 (22089.457)	Log prob: 21759.318, 21953.172, 21972.492, 21972.795, 21972.545 (22128.503)	KLD: 28.954, 8.599, 4.118, 1.525, 1.211 (39.046)	Grad: 5.673, 1.959, 1.037, 0.606, 0.575
[Epoch  60 (36.62s)]	ELBO: 21642.662, 21813.691, 21822.277, 21820.211, 21817.922 (22008.235)	Log prob: 21670.332, 21850.127, 21862.881, 21862.643, 21861.629 (22052.750)	KLD: 27.668, 8.767, 4.168, 1.828, 1.276 (44.515)	Grad: 10.494, 3.110, 1.634, 0.955, 0.928
[Epoch  61 (37.45s)]	ELBO: 21725.326, 21929.814, 21944.125, 21945.588, 21943.234 (22062.499)	Log prob: 21752.400, 21965.859, 21984.322, 21987.359, 21986.195 (22111.952)	KLD: 27.074, 8.972, 4.148, 1.576, 1.190 (49.451)	Grad: 5.769, 1.618, 0.770, 0.523, 0.464
[Epoch  62 (36.64s)]	ELBO: 21744.234, 21954.857, 21968.645, 21969.064, 21967.498 (22145.441)	Log prob: 21772.104, 21992.383, 22010.141, 22012.215, 22011.793 (22191.186)	KLD: 27.871, 9.653, 3.974, 1.650, 1.139 (45.744)	Grad: 4.808, 1.884, 0.911, 0.543, 0.474
[Epoch  63 (38.06s)]	ELBO: 21763.201, 21992.115, 22005.043, 22004.939, 22004.043 (22178.641)	Log prob: 21790.992, 22029.799, 22046.566, 22048.117, 22048.291 (22222.464)	KLD: 27.793, 9.894, 3.838, 1.658, 1.064 (43.823)	Grad: 5.221, 1.695, 0.751, 0.485, 0.454
[Epoch  64 (36.55s)]	ELBO: 21767.033, 22015.969, 22029.074, 22030.227, 22029.406 (22180.020)	Log prob: 21794.686, 22054.311, 22071.322, 22074.303, 22074.600 (22227.338)	KLD: 27.650, 10.695, 3.903, 1.831, 1.120 (47.318)	Grad: 4.851, 1.894, 0.753, 0.492, 0.439
[Epoch  65 (38.42s)]	ELBO: 21748.654, 22030.322, 22041.531, 22043.895, 22042.805 (22180.541)	Log prob: 21775.846, 22069.109, 22084.037, 22088.395, 22088.479 (22229.267)	KLD: 27.194, 11.596, 3.714, 1.995, 1.173 (48.725)	Grad: 7.631, 2.716, 1.104, 0.725, 0.642
[Epoch  66 (39.08s)]	ELBO: 21773.441, 22092.908, 22105.160, 22107.768, 22108.184 (22266.068)	Log prob: 21800.684, 22133.139, 22149.188, 22153.871, 22155.473 (22313.987)	KLD: 27.242, 12.981, 3.801, 2.078, 1.186 (47.919)	Grad: 6.317, 2.669, 1.098, 0.699, 0.575
[Epoch  67 (38.15s)]	ELBO: 21791.436, 22160.498, 22179.906, 22183.338, 22183.107 (22321.554)	Log prob: 21818.926, 22202.047, 22225.705, 22231.420, 22232.539 (22375.461)	KLD: 27.496, 14.053, 4.252, 2.281, 1.349 (53.907)	Grad: 5.806, 2.682, 0.869, 0.619, 0.503
[Epoch  68 (38.17s)]	ELBO: 21813.416, 22200.285, 22217.363, 22219.838, 22221.170 (22345.001)	Log prob: 21841.098, 22243.018, 22264.461, 22269.119, 22272.152 (22400.109)	KLD: 27.675, 15.058, 4.363, 2.185, 1.703 (55.108)	Grad: 6.314, 3.856, 1.097, 0.887, 0.671
[Epoch  69 (38.08s)]	ELBO: 21845.246, 22240.359, 22256.062, 22261.234, 22260.865 (22329.708)	Log prob: 21873.377, 22283.920, 22303.934, 22311.777, 22313.199 (22386.588)	KLD: 28.130, 15.431, 4.308, 2.672, 1.793 (56.880)	Grad: 6.598, 3.931, 1.130, 0.696, 0.631
[Epoch  70 (37.41s)]	ELBO: 21889.268, 22280.098, 22295.654, 22299.250, 22296.922 (22478.630)	Log prob: 21918.584, 22324.535, 22344.221, 22350.088, 22349.557 (22532.559)	KLD: 29.317, 15.121, 4.124, 2.272, 1.799 (53.929)	Grad: 6.076, 4.111, 1.103, 0.806, 0.678
[Epoch  71 (36.62s)]	ELBO: 21914.029, 22321.604, 22333.873, 22337.209, 22335.299 (22457.744)	Log prob: 21943.656, 22366.637, 22382.850, 22388.574, 22388.477 (22516.155)	KLD: 29.624, 15.408, 3.945, 2.386, 1.813 (58.412)	Grad: 7.336, 3.705, 1.010, 0.680, 0.598
[Epoch  72 (36.82s)]	ELBO: 21950.119, 22370.176, 22379.084, 22380.965, 22378.809 (22551.611)	Log prob: 21980.457, 22416.135, 22428.840, 22433.195, 22432.566 (22601.644)	KLD: 30.334, 15.627, 3.790, 2.479, 1.533 (50.032)	Grad: 6.602, 3.656, 0.879, 0.695, 0.607
[Epoch  73 (38.01s)]	ELBO: 21985.350, 22408.131, 22415.725, 22416.658, 22414.672 (22407.462)	Log prob: 22015.566, 22453.387, 22464.510, 22467.822, 22467.277 (22469.201)	KLD: 30.212, 15.045, 3.528, 2.381, 1.442 (61.739)	Grad: 5.781, 3.781, 1.000, 0.713, 0.571
[Epoch  74 (39.16s)]	ELBO: 21963.115, 22365.896, 22369.365, 22369.477, 22366.516 (22452.921)	Log prob: 21992.988, 22410.400, 22417.402, 22419.564, 22417.977 (22507.800)	KLD: 29.872, 14.626, 3.536, 2.052, 1.369 (54.881)	Grad: 7.234, 5.073, 1.399, 0.926, 0.757
[Epoch  75 (36.84s)]	ELBO: 21980.266, 22409.156, 22414.027, 22413.951, 22412.516 (22585.665)	Log prob: 22010.119, 22454.080, 22462.289, 22464.135, 22463.871 (22633.557)	KLD: 29.855, 15.068, 3.338, 1.922, 1.168 (47.893)	Grad: 7.572, 4.914, 1.051, 0.860, 0.675
[Epoch  76 (37.22s)]	ELBO: 22008.797, 22456.984, 22462.273, 22463.074, 22461.428 (22575.475)	Log prob: 22039.186, 22502.549, 22511.137, 22513.863, 22513.416 (22625.437)	KLD: 30.389, 15.179, 3.296, 1.926, 1.198 (49.962)	Grad: 6.007, 2.966, 0.723, 0.577, 0.469
[Epoch  77 (36.97s)]	ELBO: 22018.805, 22465.266, 22468.514, 22468.559, 22466.119 (22543.588)	Log prob: 22049.137, 22510.457, 22516.908, 22518.941, 22517.684 (22597.826)	KLD: 30.335, 14.853, 3.208, 1.992, 1.178 (54.239)	Grad: 5.022, 4.105, 0.888, 0.648, 0.541
[Epoch  78 (38.08s)]	ELBO: 22015.510, 22455.902, 22457.193, 22457.672, 22455.090 (22637.136)	Log prob: 22045.816, 22500.646, 22505.045, 22507.611, 22506.188 (22688.538)	KLD: 30.310, 14.429, 3.113, 2.093, 1.151 (51.402)	Grad: 7.586, 5.046, 1.268, 0.841, 0.706
[Epoch  79 (38.07s)]	ELBO: 22034.895, 22505.217, 22507.734, 22507.506, 22506.014 (22628.243)	Log prob: 22065.340, 22550.553, 22556.053, 22557.916, 22557.477 (22680.496)	KLD: 30.443, 14.894, 2.979, 2.093, 1.057 (52.255)	Grad: 7.937, 3.213, 0.885, 0.718, 0.575
[Epoch  80 (37.86s)]	ELBO: 22038.223, 22511.189, 22514.281, 22514.133, 22512.295 (22656.040)	Log prob: 22068.490, 22556.264, 22562.285, 22564.223, 22563.449 (22707.202)	KLD: 30.269, 14.800, 2.937, 2.083, 1.064 (51.162)	Grad: 6.003, 3.686, 0.831, 0.672, 0.519
[Epoch  81 (38.87s)]	ELBO: 22054.941, 22538.984, 22541.859, 22542.258, 22540.904 (22682.791)	Log prob: 22085.174, 22583.865, 22589.615, 22592.043, 22591.664 (22734.552)	KLD: 30.236, 14.640, 2.885, 2.023, 0.973 (51.761)	Grad: 6.839, 3.196, 0.846, 0.645, 0.504
[Epoch  82 (38.80s)]	ELBO: 22054.984, 22534.697, 22536.426, 22536.129, 22534.506 (22650.146)	Log prob: 22085.369, 22579.646, 22584.164, 22585.844, 22585.229 (22702.682)	KLD: 30.384, 14.565, 2.790, 1.975, 1.008 (52.536)	Grad: 7.428, 4.675, 1.024, 0.812, 0.647
[Epoch  83 (38.65s)]	ELBO: 22072.928, 22566.971, 22568.920, 22569.441, 22567.299 (22682.932)	Log prob: 22103.242, 22611.777, 22616.508, 22619.225, 22618.143 (22731.281)	KLD: 30.319, 14.486, 2.784, 2.194, 1.058 (48.350)	Grad: 5.901, 3.731, 0.875, 0.715, 0.532
[Epoch  84 (38.20s)]	ELBO: 22108.664, 22613.709, 22615.744, 22616.273, 22614.643 (22670.184)	Log prob: 22139.174, 22658.760, 22663.633, 22666.172, 22665.475 (22723.711)	KLD: 30.511, 14.541, 2.837, 2.012, 0.927 (53.527)	Grad: 5.715, 3.116, 0.759, 0.587, 0.454
[Epoch  85 (36.91s)]	ELBO: 22070.141, 22570.223, 22570.678, 22571.746, 22569.746 (22562.835)	Log prob: 22099.953, 22614.309, 22617.553, 22620.629, 22619.580 (22621.480)	KLD: 29.811, 14.275, 2.791, 2.010, 0.944 (58.644)	Grad: 9.540, 4.565, 1.051, 0.869, 0.706
[Epoch  86 (37.39s)]	ELBO: 22094.977, 22604.646, 22605.975, 22606.066, 22604.645 (22702.150)	Log prob: 22125.043, 22648.992, 22653.082, 22655.326, 22654.916 (22755.270)	KLD: 30.067, 14.282, 2.759, 2.151, 1.013 (53.119)	Grad: 6.845, 3.926, 0.823, 0.709, 0.536
[Epoch  87 (37.31s)]	ELBO: 22110.439, 22631.730, 22633.598, 22634.734, 22633.652 (22737.616)	Log prob: 22140.439, 22676.043, 22680.822, 22683.975, 22683.844 (22789.906)	KLD: 30.001, 14.314, 2.911, 2.017, 0.947 (52.291)	Grad: 6.761, 3.749, 0.834, 0.656, 0.536
[Epoch  88 (37.90s)]	ELBO: 22103.086, 22623.736, 22625.998, 22625.822, 22623.100 (22778.414)	Log prob: 22133.078, 22668.203, 22673.279, 22675.197, 22673.484 (22827.859)	KLD: 29.989, 14.472, 2.818, 2.097, 1.006 (49.445)	Grad: 7.469, 4.966, 1.052, 0.881, 0.657
[Epoch  89 (38.42s)]	ELBO: 22143.025, 22685.533, 22687.594, 22689.953, 22688.789 (22791.497)	Log prob: 22173.211, 22730.111, 22734.951, 22739.342, 22739.104 (22841.135)	KLD: 30.189, 14.389, 2.781, 2.029, 0.928 (49.638)	Grad: 6.074, 3.152, 0.704, 0.607, 0.452
[Epoch  90 (38.31s)]	ELBO: 22125.410, 22667.191, 22670.115, 22670.375, 22668.703 (22746.941)	Log prob: 22155.650, 22712.062, 22717.842, 22720.355, 22719.521 (22797.484)	KLD: 30.241, 14.632, 2.852, 2.255, 0.842 (50.543)	Grad: 8.277, 4.433, 0.916, 0.897, 0.640
[Epoch  91 (36.44s)]	ELBO: 22164.600, 22717.027, 22720.197, 22720.750, 22720.295 (22736.995)	Log prob: 22194.789, 22761.957, 22767.977, 22770.666, 22770.973 (22790.451)	KLD: 30.188, 14.739, 2.853, 2.138, 0.760 (53.455)	Grad: 6.091, 4.035, 0.830, 0.670, 0.500
[Epoch  92 (36.93s)]	ELBO: 22148.732, 22706.041, 22708.334, 22709.707, 22708.600 (22721.670)	Log prob: 22178.803, 22750.850, 22755.977, 22759.691, 22759.439 (22778.620)	KLD: 30.073, 14.732, 2.831, 2.347, 0.858 (56.949)	Grad: 9.193, 4.465, 0.981, 0.898, 0.669
[Epoch  93 (37.14s)]	ELBO: 22177.102, 22748.246, 22751.945, 22754.076, 22752.514 (22860.116)	Log prob: 22207.850, 22793.932, 22800.520, 22805.117, 22804.373 (22911.096)	KLD: 30.741, 14.944, 2.893, 2.462, 0.819 (50.980)	Grad: 6.067, 3.746, 0.820, 0.661, 0.482
[Epoch  94 (37.40s)]	ELBO: 22186.375, 22771.197, 22774.918, 22776.117, 22775.115 (22825.155)	Log prob: 22216.689, 22816.564, 22823.160, 22826.947, 22826.861 (22881.746)	KLD: 30.315, 15.053, 2.872, 2.586, 0.912 (56.591)	Grad: 5.413, 3.121, 0.762, 0.617, 0.444
[Epoch  95 (36.78s)]	ELBO: 22175.877, 22759.547, 22762.730, 22765.566, 22764.590 (22852.885)	Log prob: 22206.385, 22805.209, 22811.381, 22816.719, 22816.578 (22906.853)	KLD: 30.507, 15.152, 2.986, 2.513, 0.830 (53.967)	Grad: 6.524, 4.637, 0.954, 0.795, 0.568
[Epoch  96 (37.42s)]	ELBO: 22195.178, 22781.197, 22784.301, 22787.928, 22787.490 (22845.912)	Log prob: 22225.504, 22826.359, 22832.396, 22838.871, 22839.328 (22899.048)	KLD: 30.326, 14.833, 2.940, 2.838, 0.901 (53.136)	Grad: 7.373, 4.372, 1.024, 0.819, 0.591
[Epoch  97 (36.92s)]	ELBO: 22216.566, 22819.480, 22823.316, 22827.447, 22827.414 (22852.005)	Log prob: 22247.033, 22865.199, 22872.100, 22878.980, 22879.881 (22903.337)	KLD: 30.470, 15.248, 3.068, 2.748, 0.931 (51.332)	Grad: 6.671, 3.950, 0.937, 0.806, 0.540
[Epoch  98 (37.49s)]	ELBO: 22205.340, 22824.025, 22828.521, 22834.783, 22833.834 (22879.851)	Log prob: 22235.896, 22870.109, 22877.832, 22887.340, 22887.291 (22934.784)	KLD: 30.553, 15.536, 3.223, 3.242, 0.903 (54.933)	Grad: 6.748, 3.508, 1.008, 0.789, 0.489
[Epoch  99 (40.28s)]	ELBO: 22213.404, 22840.291, 22844.900, 22853.736, 22853.646 (22824.027)	Log prob: 22244.078, 22886.234, 22894.098, 22906.488, 22907.260 (22880.465)	KLD: 30.671, 15.276, 3.250, 3.554, 0.868 (56.438)	Grad: 6.658, 4.023, 1.059, 0.866, 0.540
[Epoch 100 (37.68s)]	ELBO: 22230.715, 22858.209, 22863.924, 22873.820, 22873.225 (22948.747)	Log prob: 22261.137, 22904.090, 22913.090, 22926.502, 22926.738 (23003.511)	KLD: 30.423, 15.458, 3.288, 3.514, 0.834 (54.764)	Grad: 6.819, 4.729, 1.030, 1.018, 0.608
Best epoch(s): [100]	Training time(s): 3772.22s (3772.22s)	Best ELBO: 22873.225 (22948.747)	Best log prob: 22926.738 (23003.511)
Avg. mu: -0.208, 0.795, 1.126, 2.396, -1.318, -0.830, 0.004, 0.106, 0.184, -0.781, -0.001, -0.140, -0.008, 0.011, 0.327, -0.546, -0.362, 0.227, 0.298, 0.196
Avg. var: 0.004, 0.007, 0.005, 0.007, 0.047, 0.012, 0.022, 0.013, 0.086, 0.203, 0.413, 0.149, 0.192, 0.367, 0.143, 0.235, 0.398, 0.758, 0.604, 0.472
Max. mu: 11.200, 12.005, 6.698, 13.662, 4.401, 4.486, 7.221, 11.701, 4.960, 4.630, 2.462, 3.261, 3.946, 4.177, 3.714, 2.230, 1.342, 1.961, 1.333, 1.517
Max. var: 0.696, 0.167, 0.125, 0.202, 0.349, 0.065, 0.187, 0.157, 0.304, 0.686, 1.118, 0.387, 0.818, 1.306, 0.393, 0.707, 1.209, 1.899, 2.033, 1.408
Min. mu: -9.554, -12.339, -12.156, -8.675, -5.939, -8.843, -7.751, -6.474, -3.843, -2.168, -2.015, -4.841, -4.444, -4.635, -4.296, -2.387, -1.714, -1.798, -2.165, -3.675
Min. var: 0.000, 0.000, 0.000, 0.000, 0.002, 0.000, 0.001, 0.000, 0.014, 0.024, 0.044, 0.016, 0.017, 0.078, 0.013, 0.054, 0.088, 0.241, 0.110, 0.080
Cov. mu:
[[6.895 -1.043 0.314 1.309 -0.750 -0.163 0.276 -0.820 -0.207 -0.403
  -0.237 0.514 -0.343 -0.181 -0.425 -0.397 -0.163 0.123 -0.113 0.060]
 [-1.043 8.878 0.666 1.579 1.587 -1.388 0.235 -0.064 -0.628 -0.445 0.596
  0.002 0.208 0.192 -0.213 0.510 0.056 0.139 0.158 -0.263]
 [0.314 0.666 4.399 -2.499 0.202 0.347 -1.312 -0.305 -0.659 0.284 0.067
  -0.131 0.309 -0.448 0.038 0.125 -0.110 0.074 0.006 0.118]
 [1.309 1.579 -2.499 9.410 1.413 -1.615 1.400 -1.353 -0.783 -0.349 0.210
  1.011 -0.286 0.632 -0.292 0.309 0.163 -0.001 0.141 -0.264]
 [-0.750 1.587 0.202 1.413 2.361 -1.625 -0.782 0.205 -0.424 0.169 0.264
  0.269 0.120 0.473 0.588 0.418 -0.190 0.148 0.020 0.127]
 [-0.163 -1.388 0.347 -1.615 -1.625 3.926 -1.936 0.176 0.663 -0.162
  -0.376 -0.249 0.485 -0.422 0.229 -0.028 0.047 -0.126 0.191 -0.046]
 [0.276 0.235 -1.312 1.400 -0.782 -1.936 3.689 -1.645 0.038 -0.229 0.166
  -0.056 -0.565 0.372 -0.682 -0.303 0.118 -0.114 -0.043 0.011]
 [-0.820 -0.064 -0.305 -1.353 0.205 0.176 -1.645 3.413 -0.193 0.469 0.075
  -0.223 -0.092 -0.686 -0.276 -0.054 0.256 0.010 -0.231 -0.406]
 [-0.207 -0.628 -0.659 -0.783 -0.424 0.663 0.038 -0.193 0.716 -0.174
  -0.096 -0.135 0.141 0.141 0.385 0.007 -0.079 -0.016 0.051 0.105]
 [-0.403 -0.445 0.284 -0.349 0.169 -0.162 -0.229 0.469 -0.174 0.317 0.027
  -0.117 -0.094 -0.100 -0.126 0.005 0.061 -0.035 -0.054 -0.044]
 [-0.237 0.596 0.067 0.210 0.264 -0.376 0.166 0.075 -0.096 0.027 0.145
  -0.043 -0.004 0.028 -0.004 0.062 0.008 0.021 -0.012 -0.039]
 [0.514 0.002 -0.131 1.011 0.269 -0.249 -0.056 -0.223 -0.135 -0.117
  -0.043 0.371 -0.040 0.059 0.118 0.078 -0.040 0.071 -0.011 -0.016]
 [-0.343 0.208 0.309 -0.286 0.120 0.485 -0.565 -0.092 0.141 -0.094 -0.004
  -0.040 0.423 -0.049 0.332 0.086 -0.075 0.042 0.060 0.049]
 [-0.181 0.192 -0.448 0.632 0.473 -0.422 0.372 -0.686 0.141 -0.100 0.028
  0.059 -0.049 0.475 0.237 0.067 -0.107 -0.006 0.074 0.181]
 [-0.425 -0.213 0.038 -0.292 0.588 0.229 -0.682 -0.276 0.385 -0.126
  -0.004 0.118 0.332 0.237 1.078 0.323 -0.212 0.096 0.052 0.191]
 [-0.397 0.510 0.125 0.309 0.418 -0.028 -0.303 -0.054 0.007 0.005 0.062
  0.078 0.086 0.067 0.323 0.238 -0.042 0.045 0.020 -0.026]
 [-0.163 0.056 -0.110 0.163 -0.190 0.047 0.118 0.256 -0.079 0.061 0.008
  -0.040 -0.075 -0.107 -0.212 -0.042 0.102 -0.040 -0.026 -0.101]
 [0.123 0.139 0.074 -0.001 0.148 -0.126 -0.114 0.010 -0.016 -0.035 0.021
  0.071 0.042 -0.006 0.096 0.045 -0.040 0.060 -0.017 -0.007]
 [-0.113 0.158 0.006 0.141 0.020 0.191 -0.043 -0.231 0.051 -0.054 -0.012
  -0.011 0.060 0.074 0.052 0.020 -0.026 -0.017 0.067 0.047]
 [0.060 -0.263 0.118 -0.264 0.127 -0.046 0.011 -0.406 0.105 -0.044 -0.039
  -0.016 0.049 0.181 0.191 -0.026 -0.101 -0.007 0.047 0.200]]
Avg. mu: -0.208, 0.795, 1.126, 2.396, -1.318, -0.830, 0.004, 0.106, 0.184, -0.781, -0.001, -0.140, -0.008, 0.011, 0.327, -0.546, -0.362, 0.227, 0.298, 0.196
Avg. var: 0.004, 0.007, 0.005, 0.007, 0.047, 0.012, 0.022, 0.013, 0.086, 0.203, 0.413, 0.149, 0.192, 0.367, 0.143, 0.235, 0.398, 0.758, 0.604, 0.472
Max. mu: 11.200, 12.005, 6.698, 13.662, 4.401, 4.486, 7.221, 11.701, 4.960, 4.630, 2.462, 3.261, 3.946, 4.177, 3.714, 2.230, 1.342, 1.961, 1.333, 1.517
Max. var: 0.696, 0.167, 0.125, 0.202, 0.349, 0.065, 0.187, 0.157, 0.304, 0.686, 1.118, 0.387, 0.818, 1.306, 0.393, 0.707, 1.209, 1.899, 2.033, 1.408
Min. mu: -9.554, -12.339, -12.156, -8.675, -5.939, -8.843, -7.751, -6.474, -3.843, -2.168, -2.015, -4.841, -4.444, -4.635, -4.296, -2.387, -1.714, -1.798, -2.165, -3.675
Min. var: 0.000, 0.000, 0.000, 0.000, 0.002, 0.000, 0.001, 0.000, 0.014, 0.024, 0.044, 0.016, 0.017, 0.078, 0.013, 0.054, 0.088, 0.241, 0.110, 0.080
Cov. mu:
[[6.895 -1.043 0.314 1.309 -0.750 -0.163 0.276 -0.820 -0.207 -0.403
  -0.237 0.514 -0.343 -0.181 -0.425 -0.397 -0.163 0.123 -0.113 0.060]
 [-1.043 8.878 0.666 1.579 1.587 -1.388 0.235 -0.064 -0.628 -0.445 0.596
  0.002 0.208 0.192 -0.213 0.510 0.056 0.139 0.158 -0.263]
 [0.314 0.666 4.399 -2.499 0.202 0.347 -1.312 -0.305 -0.659 0.284 0.067
  -0.131 0.309 -0.448 0.038 0.125 -0.110 0.074 0.006 0.118]
 [1.309 1.579 -2.499 9.410 1.413 -1.615 1.400 -1.353 -0.783 -0.349 0.210
  1.011 -0.286 0.632 -0.292 0.309 0.163 -0.001 0.141 -0.264]
 [-0.750 1.587 0.202 1.413 2.361 -1.625 -0.782 0.205 -0.424 0.169 0.264
  0.269 0.120 0.473 0.588 0.418 -0.190 0.148 0.020 0.127]
 [-0.163 -1.388 0.347 -1.615 -1.625 3.926 -1.936 0.176 0.663 -0.162
  -0.376 -0.249 0.485 -0.422 0.229 -0.028 0.047 -0.126 0.191 -0.046]
 [0.276 0.235 -1.312 1.400 -0.782 -1.936 3.689 -1.645 0.038 -0.229 0.166
  -0.056 -0.565 0.372 -0.682 -0.303 0.118 -0.114 -0.043 0.011]
 [-0.820 -0.064 -0.305 -1.353 0.205 0.176 -1.645 3.413 -0.193 0.469 0.075
  -0.223 -0.092 -0.686 -0.276 -0.054 0.256 0.010 -0.231 -0.406]
 [-0.207 -0.628 -0.659 -0.783 -0.424 0.663 0.038 -0.193 0.716 -0.174
  -0.096 -0.135 0.141 0.141 0.385 0.007 -0.079 -0.016 0.051 0.105]
 [-0.403 -0.445 0.284 -0.349 0.169 -0.162 -0.229 0.469 -0.174 0.317 0.027
  -0.117 -0.094 -0.100 -0.126 0.005 0.061 -0.035 -0.054 -0.044]
 [-0.237 0.596 0.067 0.210 0.264 -0.376 0.166 0.075 -0.096 0.027 0.145
  -0.043 -0.004 0.028 -0.004 0.062 0.008 0.021 -0.012 -0.039]
 [0.514 0.002 -0.131 1.011 0.269 -0.249 -0.056 -0.223 -0.135 -0.117
  -0.043 0.371 -0.040 0.059 0.118 0.078 -0.040 0.071 -0.011 -0.016]
 [-0.343 0.208 0.309 -0.286 0.120 0.485 -0.565 -0.092 0.141 -0.094 -0.004
  -0.040 0.423 -0.049 0.332 0.086 -0.075 0.042 0.060 0.049]
 [-0.181 0.192 -0.448 0.632 0.473 -0.422 0.372 -0.686 0.141 -0.100 0.028
  0.059 -0.049 0.475 0.237 0.067 -0.107 -0.006 0.074 0.181]
 [-0.425 -0.213 0.038 -0.292 0.588 0.229 -0.682 -0.276 0.385 -0.126
  -0.004 0.118 0.332 0.237 1.078 0.323 -0.212 0.096 0.052 0.191]
 [-0.397 0.510 0.125 0.309 0.418 -0.028 -0.303 -0.054 0.007 0.005 0.062
  0.078 0.086 0.067 0.323 0.238 -0.042 0.045 0.020 -0.026]
 [-0.163 0.056 -0.110 0.163 -0.190 0.047 0.118 0.256 -0.079 0.061 0.008
  -0.040 -0.075 -0.107 -0.212 -0.042 0.102 -0.040 -0.026 -0.101]
 [0.123 0.139 0.074 -0.001 0.148 -0.126 -0.114 0.010 -0.016 -0.035 0.021
  0.071 0.042 -0.006 0.096 0.045 -0.040 0.060 -0.017 -0.007]
 [-0.113 0.158 0.006 0.141 0.020 0.191 -0.043 -0.231 0.051 -0.054 -0.012
  -0.011 0.060 0.074 0.052 0.020 -0.026 -0.017 0.067 0.047]
 [0.060 -0.263 0.118 -0.264 0.127 -0.046 0.011 -0.406 0.105 -0.044 -0.039
  -0.016 0.049 0.181 0.191 -0.026 -0.101 -0.007 0.047 0.200]]
