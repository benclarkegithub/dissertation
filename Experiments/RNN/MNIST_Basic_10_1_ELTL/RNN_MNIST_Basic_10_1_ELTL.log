Encoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Encoder                                  --
├─Linear: 1-1                            31,400
├─Linear: 1-2                            1,640
=================================================================
Total params: 33,040
Trainable params: 33,040
Non-trainable params: 0
=================================================================
Encoder 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Encoder                                  --
├─Linear: 1-1                            31,400
├─Linear: 1-2                            1,640
=================================================================
Total params: 33,040
Trainable params: 33,040
Non-trainable params: 0
=================================================================
Encoder Encoder to Encoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderEncoderToEncoder                  --
├─Linear: 1-1                            3,240
├─Linear: 1-2                            1,640
=================================================================
Total params: 4,880
Trainable params: 4,880
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            1,640
├─Linear: 1-2                            41
├─Linear: 1-3                            41
=================================================================
Total params: 1,722
Trainable params: 1,722
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            1,806
├─Linear: 1-2                            43
├─Linear: 1-3                            43
=================================================================
Total params: 1,892
Trainable params: 1,892
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            1,980
├─Linear: 1-2                            45
├─Linear: 1-3                            45
=================================================================
Total params: 2,070
Trainable params: 2,070
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            2,162
├─Linear: 1-2                            47
├─Linear: 1-3                            47
=================================================================
Total params: 2,256
Trainable params: 2,256
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 4
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            2,352
├─Linear: 1-2                            49
├─Linear: 1-3                            49
=================================================================
Total params: 2,450
Trainable params: 2,450
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 5
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            2,550
├─Linear: 1-2                            51
├─Linear: 1-3                            51
=================================================================
Total params: 2,652
Trainable params: 2,652
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 6
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            2,756
├─Linear: 1-2                            53
├─Linear: 1-3                            53
=================================================================
Total params: 2,862
Trainable params: 2,862
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 7
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            2,970
├─Linear: 1-2                            55
├─Linear: 1-3                            55
=================================================================
Total params: 3,080
Trainable params: 3,080
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 8
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            3,192
├─Linear: 1-2                            57
├─Linear: 1-3                            57
=================================================================
Total params: 3,306
Trainable params: 3,306
Non-trainable params: 0
=================================================================
Encoder Latents to Latents 9
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderLatentsToLatents                  --
├─Linear: 1-1                            3,422
├─Linear: 1-2                            59
├─Linear: 1-3                            59
=================================================================
Total params: 3,540
Trainable params: 3,540
Non-trainable params: 0
=================================================================
Latents to Decoder 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            80
=================================================================
Total params: 80
Trainable params: 80
Non-trainable params: 0
=================================================================
Latents to Decoder 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            80
=================================================================
Total params: 80
Trainable params: 80
Non-trainable params: 0
=================================================================
Latents to Decoder 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            80
=================================================================
Total params: 80
Trainable params: 80
Non-trainable params: 0
=================================================================
Latents to Decoder 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            80
=================================================================
Total params: 80
Trainable params: 80
Non-trainable params: 0
=================================================================
Latents to Decoder 4
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            80
=================================================================
Total params: 80
Trainable params: 80
Non-trainable params: 0
=================================================================
Latents to Decoder 5
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            80
=================================================================
Total params: 80
Trainable params: 80
Non-trainable params: 0
=================================================================
Latents to Decoder 6
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            80
=================================================================
Total params: 80
Trainable params: 80
Non-trainable params: 0
=================================================================
Latents to Decoder 7
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            80
=================================================================
Total params: 80
Trainable params: 80
Non-trainable params: 0
=================================================================
Latents to Decoder 8
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            80
=================================================================
Total params: 80
Trainable params: 80
Non-trainable params: 0
=================================================================
Latents to Decoder 9
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            80
=================================================================
Total params: 80
Trainable params: 80
Non-trainable params: 0
=================================================================
Decoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Decoder                                  --
├─Linear: 1-1                            1,640
├─Linear: 1-2                            32,144
=================================================================
Total params: 33,784
Trainable params: 33,784
Non-trainable params: 0
=================================================================
[Epoch   1 (42.14s)]	ELBO: 1114.841, 1202.556, 1226.690, 1237.066, 1242.146, 1246.044, 1246.159, 1245.148, 1242.755, 1238.769 (1383.011)	Log prob: 1128.628, 1220.037, 1245.205, 1256.125, 1261.778, 1266.378, 1266.860, 1266.284, 1264.366, 1261.067 (1399.347)	KLD: 13.786, 3.696, 1.033, 0.544, 0.574, 0.701, 0.368, 0.435, 0.475, 0.686 (16.336)	Grad: 5.353, 0.914, 0.289, 0.158, 0.093, 0.075, 0.017, 0.016, 0.015, 0.065
[Epoch   2 (80.20s)]	ELBO: 1331.465, 1395.562, 1400.278, 1400.105, 1399.634, 1399.256, 1398.714, 1397.946, 1397.155, 1396.042 (1411.115)	Log prob: 1336.909, 1404.637, 1410.624, 1411.143, 1411.309, 1411.594, 1411.288, 1410.963, 1410.614, 1410.268 (1424.050)	KLD: 5.444, 3.631, 1.272, 0.691, 0.637, 0.664, 0.235, 0.442, 0.441, 0.769 (12.935)	Grad: 2.822, 0.438, 0.090, 0.047, 0.054, 0.048, 0.033, 0.043, 0.042, 0.063
[Epoch   3 (85.60s)]	ELBO: 1339.598, 1417.508, 1431.057, 1434.050, 1434.428, 1434.746, 1434.944, 1434.408, 1433.939, 1433.255 (1465.545)	Log prob: 1343.678, 1425.455, 1440.668, 1444.571, 1445.521, 1446.576, 1447.181, 1446.978, 1446.850, 1446.771 (1479.704)	KLD: 4.081, 3.866, 1.665, 0.910, 0.570, 0.737, 0.406, 0.334, 0.343, 0.604 (14.159)	Grad: 2.600, 1.003, 0.130, 0.094, 0.103, 0.076, 0.090, 0.073, 0.072, 0.079
[Epoch   4 (74.94s)]	ELBO: 1349.432, 1430.438, 1467.059, 1486.135, 1487.100, 1487.651, 1487.297, 1487.170, 1486.670, 1485.934 (1503.614)	Log prob: 1353.062, 1437.762, 1476.785, 1497.975, 1499.495, 1500.968, 1501.048, 1501.272, 1501.064, 1500.832 (1518.548)	KLD: 3.630, 3.695, 2.402, 2.113, 0.556, 0.924, 0.432, 0.350, 0.293, 0.504 (14.934)	Grad: 1.947, 0.983, 0.225, 0.300, 0.119, 0.117, 0.100, 0.091, 0.078, 0.083
[Epoch   5 (75.21s)]	ELBO: 1365.879, 1440.888, 1488.999, 1517.933, 1518.355, 1518.772, 1518.977, 1518.711, 1518.634, 1518.118 (1544.618)	Log prob: 1369.347, 1447.847, 1498.850, 1529.954, 1530.881, 1532.271, 1532.686, 1532.717, 1532.875, 1532.771 (1560.978)	KLD: 3.468, 3.490, 2.894, 2.168, 0.506, 0.973, 0.210, 0.295, 0.238, 0.411 (16.360)	Grad: 1.553, 0.719, 0.293, 0.246, 0.114, 0.120, 0.089, 0.089, 0.080, 0.086
[Epoch   6 (75.55s)]	ELBO: 1381.126, 1446.945, 1506.571, 1547.759, 1561.039, 1562.995, 1564.657, 1564.472, 1564.271, 1564.198 (1578.298)	Log prob: 1384.573, 1453.665, 1516.375, 1560.096, 1575.014, 1578.135, 1580.590, 1580.538, 1580.595, 1580.810 (1594.750)	KLD: 3.446, 3.273, 3.084, 2.533, 1.640, 1.163, 0.794, 0.133, 0.257, 0.289 (16.453)	Grad: 1.966, 0.774, 0.384, 0.348, 0.299, 0.187, 0.172, 0.092, 0.098, 0.108
[Epoch   7 (75.74s)]	ELBO: 1386.183, 1451.747, 1515.936, 1560.437, 1581.249, 1581.787, 1585.729, 1585.788, 1585.702, 1586.482 (1595.953)	Log prob: 1389.586, 1458.276, 1525.597, 1572.665, 1595.497, 1597.087, 1602.069, 1602.282, 1602.326, 1603.673 (1613.310)	KLD: 3.403, 3.126, 3.133, 2.566, 2.021, 1.053, 1.040, 0.152, 0.131, 0.567 (17.356)	Grad: 2.301, 0.819, 0.444, 0.360, 0.392, 0.175, 0.186, 0.088, 0.085, 0.126
[Epoch   8 (75.72s)]	ELBO: 1389.643, 1455.940, 1521.424, 1568.320, 1590.177, 1591.570, 1600.242, 1600.390, 1600.420, 1600.505 (1607.345)	Log prob: 1393.106, 1462.456, 1531.060, 1580.506, 1604.401, 1606.839, 1617.050, 1617.416, 1617.535, 1618.103 (1624.597)	KLD: 3.462, 3.053, 3.121, 2.550, 2.038, 1.046, 1.539, 0.216, 0.092, 0.482 (17.253)	Grad: 2.463, 0.877, 0.527, 0.402, 0.403, 0.192, 0.235, 0.107, 0.092, 0.127
[Epoch   9 (84.75s)]	ELBO: 1391.837, 1459.171, 1526.701, 1574.951, 1597.428, 1603.494, 1611.256, 1611.580, 1611.567, 1611.366 (1616.037)	Log prob: 1395.334, 1465.730, 1536.381, 1587.139, 1611.681, 1618.960, 1628.230, 1628.890, 1628.953, 1629.098 (1633.700)	KLD: 3.497, 3.062, 3.122, 2.508, 2.065, 1.213, 1.509, 0.335, 0.075, 0.346 (17.664)	Grad: 2.432, 0.895, 0.543, 0.387, 0.378, 0.209, 0.241, 0.117, 0.089, 0.115
[Epoch  10 (87.40s)]	ELBO: 1393.955, 1461.602, 1531.620, 1580.042, 1602.861, 1615.227, 1619.773, 1620.681, 1620.724, 1620.585 (1626.131)	Log prob: 1397.491, 1468.207, 1541.357, 1592.249, 1617.148, 1631.080, 1636.920, 1638.344, 1638.477, 1638.603 (1643.856)	KLD: 3.536, 3.069, 3.131, 2.471, 2.077, 1.568, 1.296, 0.515, 0.092, 0.263 (17.725)	Grad: 2.219, 0.939, 0.557, 0.434, 0.350, 0.242, 0.241, 0.144, 0.094, 0.114
[Epoch  11 (89.16s)]	ELBO: 1395.640, 1463.722, 1536.253, 1584.533, 1607.616, 1623.764, 1626.925, 1630.095, 1630.162, 1630.042 (1635.642)	Log prob: 1399.169, 1470.320, 1545.975, 1596.716, 1621.863, 1639.753, 1644.119, 1648.326, 1648.584, 1648.679 (1654.500)	KLD: 3.530, 3.068, 3.126, 2.459, 2.064, 1.742, 1.205, 1.036, 0.192, 0.217 (18.858)	Grad: 2.040, 1.032, 0.589, 0.438, 0.364, 0.262, 0.244, 0.194, 0.104, 0.121
[Epoch  12 (125.50s)]	ELBO: 1396.719, 1465.392, 1540.792, 1588.917, 1612.010, 1630.642, 1634.304, 1638.815, 1638.821, 1638.695 (1642.431)	Log prob: 1400.256, 1472.002, 1550.533, 1601.109, 1626.253, 1646.704, 1651.589, 1657.351, 1657.533, 1657.558 (1661.080)	KLD: 3.537, 3.072, 3.132, 2.451, 2.052, 1.818, 1.223, 1.251, 0.178, 0.150 (18.650)	Grad: 1.902, 1.012, 0.605, 0.445, 0.373, 0.284, 0.257, 0.215, 0.107, 0.115
[Epoch  13 (176.39s)]	ELBO: 1398.140, 1467.080, 1545.130, 1593.355, 1616.418, 1635.762, 1641.691, 1645.186, 1645.148, 1645.149 (1648.989)	Log prob: 1401.677, 1473.704, 1554.894, 1605.559, 1630.667, 1651.875, 1659.123, 1663.780, 1663.887, 1663.990 (1668.061)	KLD: 3.537, 3.087, 3.139, 2.441, 2.045, 1.863, 1.321, 1.159, 0.147, 0.102 (19.072)	Grad: 1.822, 1.012, 0.607, 0.423, 0.405, 0.321, 0.262, 0.230, 0.107, 0.111
[Epoch  14 (153.30s)]	ELBO: 1399.505, 1468.468, 1548.548, 1596.843, 1620.040, 1639.487, 1647.721, 1650.065, 1650.118, 1650.083 (1652.141)	Log prob: 1403.031, 1475.105, 1558.335, 1609.078, 1634.303, 1655.661, 1665.338, 1668.725, 1668.973, 1669.002 (1671.052)	KLD: 3.526, 3.111, 3.150, 2.447, 2.030, 1.910, 1.443, 1.043, 0.194, 0.065 (18.911)	Grad: 1.710, 1.041, 0.643, 0.414, 0.390, 0.305, 0.269, 0.219, 0.110, 0.107
[Epoch  15 (147.42s)]	ELBO: 1401.045, 1469.795, 1551.424, 1599.766, 1622.863, 1642.458, 1652.018, 1653.929, 1654.088, 1654.096 (1657.056)	Log prob: 1404.555, 1476.454, 1561.242, 1612.031, 1637.145, 1658.680, 1669.771, 1672.656, 1673.088, 1673.148 (1676.150)	KLD: 3.509, 3.151, 3.159, 2.445, 2.019, 1.940, 1.531, 0.974, 0.274, 0.051 (19.094)	Grad: 1.601, 1.024, 0.609, 0.400, 0.382, 0.306, 0.314, 0.230, 0.119, 0.106
[Epoch  16 (141.31s)]	ELBO: 1402.202, 1471.710, 1553.955, 1602.292, 1625.474, 1645.269, 1655.567, 1657.583, 1657.961, 1658.008 (1660.463)	Log prob: 1405.691, 1478.385, 1563.798, 1614.588, 1639.785, 1661.534, 1673.418, 1676.378, 1677.198, 1677.293 (1679.692)	KLD: 3.491, 3.185, 3.167, 2.453, 2.015, 1.955, 1.585, 0.945, 0.441, 0.049 (19.229)	Grad: 1.535, 1.083, 0.618, 0.391, 0.374, 0.306, 0.330, 0.225, 0.138, 0.108
[Epoch  17 (140.59s)]	ELBO: 1403.047, 1473.879, 1556.125, 1604.427, 1627.794, 1647.657, 1658.549, 1661.305, 1662.025, 1662.024 (1664.503)	Log prob: 1406.528, 1480.594, 1566.041, 1616.804, 1642.192, 1664.021, 1676.546, 1680.288, 1681.595, 1681.651 (1683.809)	KLD: 3.480, 3.235, 3.200, 2.460, 2.021, 1.968, 1.630, 0.988, 0.587, 0.056 (19.306)	Grad: 1.484, 1.019, 0.644, 0.430, 0.373, 0.299, 0.308, 0.226, 0.153, 0.109
[Epoch  18 (142.54s)]	ELBO: 1403.827, 1474.989, 1558.165, 1606.378, 1629.719, 1649.732, 1660.993, 1664.754, 1665.438, 1665.507 (1667.133)	Log prob: 1407.290, 1481.711, 1568.110, 1618.787, 1644.153, 1666.140, 1679.071, 1683.901, 1685.176, 1685.316 (1686.506)	KLD: 3.462, 3.260, 3.223, 2.464, 2.025, 1.973, 1.671, 1.069, 0.592, 0.071 (19.373)	Grad: 1.547, 1.028, 0.648, 0.415, 0.399, 0.304, 0.303, 0.245, 0.158, 0.112
[Epoch  19 (149.79s)]	ELBO: 1404.523, 1475.966, 1560.028, 1608.203, 1631.652, 1651.704, 1663.266, 1667.705, 1668.286, 1668.320 (1669.997)	Log prob: 1407.972, 1482.691, 1569.981, 1620.621, 1646.093, 1668.125, 1681.384, 1686.954, 1688.124, 1688.245 (1689.621)	KLD: 3.449, 3.276, 3.229, 2.465, 2.023, 1.979, 1.696, 1.132, 0.589, 0.086 (19.624)	Grad: 1.433, 1.019, 0.652, 0.407, 0.394, 0.319, 0.299, 0.241, 0.155, 0.114
[Epoch  20 (143.70s)]	ELBO: 1405.043, 1476.691, 1561.569, 1609.632, 1632.977, 1653.234, 1665.104, 1669.969, 1670.552, 1670.665 (1672.643)	Log prob: 1408.488, 1483.414, 1571.527, 1622.059, 1647.428, 1669.669, 1683.255, 1689.323, 1690.518, 1690.759 (1693.024)	KLD: 3.444, 3.278, 3.237, 2.467, 2.025, 1.983, 1.717, 1.203, 0.612, 0.127 (20.382)	Grad: 1.467, 1.043, 0.659, 0.424, 0.371, 0.324, 0.299, 0.240, 0.163, 0.121
[Epoch  21 (154.28s)]	ELBO: 1405.328, 1477.056, 1562.698, 1610.746, 1634.214, 1654.546, 1666.602, 1671.620, 1672.661, 1672.838 (1675.601)	Log prob: 1408.760, 1483.775, 1572.651, 1623.170, 1648.661, 1670.981, 1684.760, 1691.019, 1692.746, 1693.161 (1695.800)	KLD: 3.431, 3.286, 3.237, 2.471, 2.024, 1.986, 1.724, 1.240, 0.687, 0.238 (20.200)	Grad: 1.422, 1.095, 0.697, 0.417, 0.397, 0.324, 0.282, 0.254, 0.179, 0.138
[Epoch  22 (154.98s)]	ELBO: 1405.915, 1478.108, 1564.241, 1612.111, 1635.600, 1656.017, 1668.194, 1673.522, 1674.924, 1675.255 (1676.745)	Log prob: 1409.339, 1484.826, 1574.188, 1624.530, 1650.046, 1672.444, 1686.360, 1692.954, 1695.141, 1695.787 (1697.160)	KLD: 3.425, 3.293, 3.230, 2.470, 2.029, 1.981, 1.737, 1.266, 0.785, 0.315 (20.414)	Grad: 1.426, 1.051, 0.676, 0.436, 0.391, 0.302, 0.267, 0.236, 0.189, 0.143
[Epoch  23 (139.36s)]	ELBO: 1406.280, 1478.733, 1565.490, 1613.205, 1636.744, 1657.187, 1669.478, 1674.983, 1676.818, 1677.263 (1678.430)	Log prob: 1409.699, 1485.446, 1575.428, 1625.617, 1651.184, 1673.613, 1687.641, 1694.432, 1697.132, 1697.984 (1699.116)	KLD: 3.419, 3.293, 3.226, 2.476, 2.026, 1.984, 1.738, 1.286, 0.864, 0.407 (20.686)	Grad: 1.333, 1.039, 0.665, 0.441, 0.360, 0.313, 0.255, 0.238, 0.185, 0.155
[Epoch  24 (142.37s)]	ELBO: 1406.747, 1479.357, 1566.663, 1614.305, 1637.799, 1658.246, 1670.605, 1676.196, 1678.467, 1679.139 (1681.007)	Log prob: 1410.167, 1486.067, 1576.601, 1626.721, 1652.240, 1674.671, 1688.777, 1695.674, 1698.881, 1700.078 (1701.554)	KLD: 3.420, 3.290, 3.228, 2.478, 2.024, 1.984, 1.747, 1.307, 0.936, 0.525 (20.547)	Grad: 1.362, 1.085, 0.706, 0.440, 0.399, 0.321, 0.243, 0.248, 0.209, 0.185
[Epoch  25 (155.15s)]	ELBO: 1407.487, 1479.802, 1567.630, 1615.157, 1638.713, 1659.229, 1671.670, 1677.523, 1680.084, 1681.264 (1682.928)	Log prob: 1410.906, 1486.509, 1577.563, 1627.568, 1653.150, 1675.655, 1689.846, 1697.023, 1700.569, 1702.450 (1704.072)	KLD: 3.419, 3.287, 3.228, 2.477, 2.026, 1.988, 1.751, 1.323, 0.985, 0.701 (21.144)	Grad: 1.378, 1.054, 0.672, 0.429, 0.378, 0.310, 0.259, 0.233, 0.202, 0.205
[Epoch  26 (138.16s)]	ELBO: 1408.361, 1480.262, 1568.629, 1616.012, 1639.619, 1660.088, 1672.650, 1678.660, 1681.422, 1683.152 (1684.809)	Log prob: 1411.771, 1486.967, 1578.554, 1628.417, 1654.053, 1676.505, 1690.826, 1698.177, 1701.977, 1704.556 (1705.795)	KLD: 3.410, 3.294, 3.220, 2.481, 2.028, 1.986, 1.757, 1.341, 1.038, 0.849 (20.986)	Grad: 1.328, 1.078, 0.663, 0.414, 0.353, 0.300, 0.265, 0.245, 0.200, 0.227
[Epoch  27 (128.28s)]	ELBO: 1408.908, 1480.750, 1569.653, 1616.897, 1640.433, 1660.883, 1673.495, 1679.699, 1682.718, 1684.891 (1686.664)	Log prob: 1412.317, 1487.453, 1579.578, 1629.301, 1654.862, 1677.295, 1691.667, 1699.237, 1703.321, 1706.444 (1708.371)	KLD: 3.409, 3.295, 3.218, 2.483, 2.024, 1.984, 1.759, 1.364, 1.065, 0.950 (21.707)	Grad: 1.301, 1.088, 0.689, 0.446, 0.392, 0.323, 0.277, 0.247, 0.212, 0.246
[Epoch  28 (135.56s)]	ELBO: 1409.558, 1481.255, 1570.487, 1617.684, 1641.348, 1661.767, 1674.416, 1680.862, 1684.224, 1686.723 (1687.249)	Log prob: 1412.967, 1487.959, 1580.416, 1630.093, 1655.781, 1678.181, 1692.591, 1700.427, 1704.890, 1708.393 (1709.054)	KLD: 3.409, 3.295, 3.224, 2.481, 2.025, 1.980, 1.763, 1.389, 1.101, 1.002 (21.805)	Grad: 1.301, 1.074, 0.667, 0.444, 0.343, 0.306, 0.256, 0.240, 0.211, 0.241
[Epoch  29 (137.64s)]	ELBO: 1410.088, 1481.666, 1571.473, 1618.385, 1642.074, 1662.437, 1675.233, 1681.879, 1685.475, 1688.188 (1689.501)	Log prob: 1413.494, 1488.372, 1581.392, 1630.787, 1656.504, 1678.849, 1693.415, 1701.470, 1706.203, 1709.960 (1711.218)	KLD: 3.406, 3.299, 3.214, 2.481, 2.029, 1.984, 1.768, 1.410, 1.136, 1.044 (21.716)	Grad: 1.288, 1.118, 0.686, 0.456, 0.366, 0.307, 0.263, 0.255, 0.207, 0.254
[Epoch  30 (127.58s)]	ELBO: 1410.728, 1482.168, 1572.331, 1619.103, 1642.761, 1663.131, 1675.892, 1682.807, 1686.739, 1689.546 (1690.579)	Log prob: 1414.129, 1488.874, 1582.255, 1631.511, 1657.195, 1679.550, 1694.079, 1702.430, 1707.520, 1711.398 (1712.222)	KLD: 3.402, 3.305, 3.219, 2.483, 2.026, 1.984, 1.769, 1.435, 1.157, 1.072 (21.643)	Grad: 1.255, 1.100, 0.695, 0.488, 0.386, 0.316, 0.274, 0.247, 0.220, 0.272
[Epoch  31 (130.61s)]	ELBO: 1411.264, 1482.568, 1573.140, 1619.764, 1643.498, 1663.862, 1676.721, 1683.843, 1687.877, 1690.956 (1693.050)	Log prob: 1414.667, 1489.277, 1583.067, 1632.178, 1657.938, 1680.287, 1694.922, 1703.501, 1708.718, 1712.892 (1715.005)	KLD: 3.402, 3.306, 3.218, 2.486, 2.029, 1.983, 1.776, 1.457, 1.183, 1.095 (21.955)	Grad: 1.248, 1.107, 0.701, 0.470, 0.368, 0.307, 0.256, 0.247, 0.236, 0.266
[Epoch  32 (138.67s)]	ELBO: 1411.652, 1482.902, 1573.889, 1620.386, 1644.173, 1664.526, 1677.441, 1684.742, 1689.045, 1692.334 (1693.569)	Log prob: 1415.054, 1489.614, 1583.813, 1632.797, 1658.618, 1680.959, 1695.646, 1704.422, 1709.940, 1714.345 (1715.567)	KLD: 3.403, 3.308, 3.213, 2.486, 2.036, 1.987, 1.772, 1.473, 1.216, 1.115 (21.998)	Grad: 1.225, 1.123, 0.687, 0.462, 0.358, 0.313, 0.265, 0.255, 0.208, 0.260
[Epoch  33 (145.36s)]	ELBO: 1411.953, 1483.258, 1574.563, 1620.987, 1644.809, 1665.109, 1678.101, 1685.647, 1690.133, 1693.527 (1694.955)	Log prob: 1415.357, 1489.972, 1584.490, 1633.401, 1659.255, 1681.542, 1696.306, 1705.337, 1711.049, 1715.575 (1716.808)	KLD: 3.403, 3.311, 3.213, 2.488, 2.032, 1.987, 1.771, 1.486, 1.227, 1.130 (21.853)	Grad: 1.218, 1.133, 0.737, 0.468, 0.356, 0.319, 0.269, 0.246, 0.235, 0.272
[Epoch  34 (156.52s)]	ELBO: 1412.345, 1483.587, 1575.448, 1621.627, 1645.536, 1665.889, 1678.870, 1686.587, 1691.197, 1694.668 (1695.221)	Log prob: 1415.746, 1490.305, 1585.382, 1634.050, 1659.995, 1682.333, 1697.094, 1706.307, 1712.158, 1716.767 (1717.301)	KLD: 3.401, 3.317, 3.216, 2.488, 2.035, 1.986, 1.779, 1.497, 1.240, 1.139 (22.080)	Grad: 1.199, 1.120, 0.691, 0.483, 0.344, 0.312, 0.276, 0.248, 0.212, 0.262
[Epoch  35 (141.85s)]	ELBO: 1412.390, 1483.873, 1575.952, 1622.165, 1646.087, 1666.441, 1679.474, 1687.264, 1692.016, 1695.539 (1696.291)	Log prob: 1415.790, 1490.591, 1585.887, 1634.593, 1660.554, 1682.891, 1697.706, 1707.002, 1713.001, 1717.667 (1717.991)	KLD: 3.400, 3.319, 3.216, 2.491, 2.040, 1.982, 1.783, 1.506, 1.248, 1.142 (21.700)	Grad: 1.162, 1.135, 0.667, 0.471, 0.333, 0.315, 0.288, 0.257, 0.222, 0.256
[Epoch  36 (162.06s)]	ELBO: 1412.672, 1484.271, 1576.518, 1622.798, 1646.845, 1667.170, 1680.284, 1688.183, 1693.010, 1696.589 (1697.978)	Log prob: 1416.074, 1490.985, 1586.447, 1635.217, 1661.303, 1683.612, 1698.513, 1707.925, 1714.015, 1718.743 (1720.162)	KLD: 3.402, 3.312, 3.214, 2.490, 2.040, 1.984, 1.785, 1.514, 1.262, 1.148 (22.183)	Grad: 1.147, 1.125, 0.672, 0.458, 0.357, 0.303, 0.273, 0.244, 0.215, 0.246
[Epoch  37 (150.27s)]	ELBO: 1413.030, 1484.698, 1577.185, 1623.335, 1647.385, 1667.633, 1680.823, 1688.901, 1693.823, 1697.286 (1698.381)	Log prob: 1416.431, 1491.418, 1587.119, 1635.761, 1661.848, 1684.086, 1699.061, 1708.663, 1714.851, 1719.458 (1720.409)	KLD: 3.401, 3.319, 3.215, 2.492, 2.039, 1.989, 1.786, 1.523, 1.266, 1.144 (22.028)	Grad: 1.187, 1.140, 0.662, 0.460, 0.373, 0.324, 0.281, 0.252, 0.223, 0.258
[Epoch  38 (148.63s)]	ELBO: 1413.161, 1484.878, 1577.682, 1623.787, 1647.958, 1668.314, 1681.472, 1689.733, 1694.634, 1698.248 (1699.193)	Log prob: 1416.566, 1491.599, 1587.619, 1636.221, 1662.434, 1684.780, 1699.720, 1709.512, 1715.677, 1720.438 (1721.492)	KLD: 3.406, 3.316, 3.216, 2.496, 2.043, 1.991, 1.781, 1.530, 1.265, 1.148 (22.300)	Grad: 1.153, 1.156, 0.671, 0.475, 0.333, 0.315, 0.273, 0.240, 0.219, 0.252
[Epoch  39 (158.09s)]	ELBO: 1413.437, 1485.196, 1578.220, 1624.290, 1648.568, 1668.810, 1682.076, 1690.452, 1695.331, 1698.998 (1700.665)	Log prob: 1416.843, 1491.919, 1588.163, 1636.730, 1663.056, 1685.285, 1700.340, 1710.252, 1716.395, 1721.212 (1722.909)	KLD: 3.405, 3.318, 3.218, 2.499, 2.048, 1.987, 1.788, 1.536, 1.264, 1.149 (22.244)	Grad: 1.124, 1.157, 0.664, 0.485, 0.344, 0.318, 0.273, 0.236, 0.228, 0.234
[Epoch  40 (169.01s)]	ELBO: 1413.685, 1485.481, 1578.620, 1624.734, 1648.954, 1669.245, 1682.514, 1690.881, 1695.920, 1699.510 (1700.201)	Log prob: 1417.095, 1492.209, 1588.569, 1637.184, 1663.454, 1685.738, 1700.795, 1710.700, 1717.012, 1721.741 (1722.378)	KLD: 3.410, 3.319, 3.221, 2.504, 2.047, 1.994, 1.787, 1.541, 1.271, 1.139 (22.177)	Grad: 1.167, 1.157, 0.681, 0.494, 0.339, 0.339, 0.266, 0.251, 0.230, 0.248
[Epoch  41 (158.05s)]	ELBO: 1413.780, 1485.619, 1579.021, 1625.079, 1649.391, 1669.635, 1682.965, 1691.392, 1696.495, 1700.100 (1700.508)	Log prob: 1417.193, 1492.354, 1588.974, 1637.536, 1663.898, 1686.138, 1701.256, 1711.226, 1717.603, 1722.349 (1723.184)	KLD: 3.412, 3.324, 3.218, 2.503, 2.049, 1.996, 1.789, 1.545, 1.274, 1.140 (22.676)	Grad: 1.118, 1.186, 0.668, 0.444, 0.363, 0.310, 0.259, 0.250, 0.222, 0.237
[Epoch  42 (158.06s)]	ELBO: 1413.971, 1486.002, 1579.443, 1625.501, 1649.861, 1670.090, 1683.475, 1691.947, 1697.020, 1700.650 (1702.560)	Log prob: 1417.385, 1492.737, 1589.391, 1637.951, 1664.359, 1686.586, 1701.761, 1711.784, 1718.140, 1722.904 (1724.653)	KLD: 3.414, 3.321, 3.213, 2.502, 2.049, 1.998, 1.789, 1.552, 1.283, 1.135 (22.092)	Grad: 1.127, 1.166, 0.686, 0.466, 0.378, 0.309, 0.283, 0.258, 0.221, 0.249
[Epoch  43 (170.28s)]	ELBO: 1414.409, 1486.415, 1579.979, 1626.092, 1650.515, 1670.769, 1684.115, 1692.760, 1697.827, 1701.485 (1703.539)	Log prob: 1417.832, 1493.163, 1589.945, 1638.569, 1665.048, 1687.297, 1702.435, 1712.635, 1718.976, 1723.776 (1725.884)	KLD: 3.422, 3.326, 3.218, 2.510, 2.057, 1.994, 1.790, 1.556, 1.275, 1.142 (22.345)	Grad: 1.075, 1.203, 0.671, 0.452, 0.342, 0.331, 0.277, 0.226, 0.220, 0.226
[Epoch  44 (157.13s)]	ELBO: 1414.507, 1486.744, 1580.355, 1626.449, 1650.964, 1671.225, 1684.624, 1693.263, 1698.362, 1701.993 (1703.133)	Log prob: 1417.929, 1493.491, 1590.321, 1638.925, 1665.491, 1687.754, 1702.946, 1713.148, 1719.530, 1724.297 (1725.106)	KLD: 3.422, 3.325, 3.219, 2.508, 2.053, 2.003, 1.792, 1.562, 1.285, 1.136 (21.973)	Grad: 1.093, 1.196, 0.666, 0.443, 0.334, 0.303, 0.282, 0.232, 0.211, 0.234
[Epoch  45 (181.38s)]	ELBO: 1414.675, 1486.979, 1580.823, 1626.868, 1651.364, 1671.549, 1684.976, 1693.688, 1698.786, 1702.393 (1703.724)	Log prob: 1418.098, 1493.724, 1590.786, 1639.338, 1665.893, 1688.080, 1703.298, 1713.575, 1719.951, 1724.703 (1725.691)	KLD: 3.422, 3.321, 3.219, 2.508, 2.058, 2.003, 1.790, 1.565, 1.276, 1.147 (21.967)	Grad: 1.094, 1.173, 0.670, 0.448, 0.360, 0.294, 0.263, 0.244, 0.218, 0.218
[Epoch  46 (158.77s)]	ELBO: 1414.867, 1487.315, 1581.194, 1627.225, 1651.785, 1671.985, 1685.453, 1694.100, 1699.275, 1702.911 (1703.552)	Log prob: 1418.294, 1494.067, 1591.166, 1639.703, 1666.317, 1688.518, 1703.775, 1713.988, 1720.438, 1725.214 (1725.822)	KLD: 3.427, 3.324, 3.220, 2.506, 2.054, 2.003, 1.789, 1.565, 1.274, 1.141 (22.270)	Grad: 1.106, 1.219, 0.670, 0.466, 0.329, 0.301, 0.291, 0.240, 0.219, 0.223
[Epoch  47 (147.23s)]	ELBO: 1415.053, 1487.561, 1581.499, 1627.410, 1652.054, 1672.238, 1685.767, 1694.502, 1699.671, 1703.391 (1703.747)	Log prob: 1418.481, 1494.313, 1591.474, 1639.896, 1666.596, 1688.790, 1704.109, 1714.412, 1720.858, 1725.711 (1725.841)	KLD: 3.428, 3.325, 3.221, 2.510, 2.058, 2.010, 1.791, 1.566, 1.277, 1.133 (22.094)	Grad: 1.137, 1.210, 0.660, 0.477, 0.368, 0.297, 0.292, 0.229, 0.213, 0.220
[Epoch  48 (142.26s)]	ELBO: 1415.197, 1487.831, 1581.850, 1627.836, 1652.513, 1672.615, 1686.298, 1695.020, 1700.164, 1703.833 (1704.473)	Log prob: 1418.633, 1494.598, 1591.840, 1640.338, 1667.075, 1689.188, 1704.664, 1714.959, 1721.385, 1726.192 (1726.724)	KLD: 3.436, 3.330, 3.225, 2.513, 2.058, 2.009, 1.795, 1.574, 1.282, 1.136 (22.251)	Grad: 1.084, 1.177, 0.661, 0.463, 0.334, 0.306, 0.268, 0.229, 0.213, 0.216
[Epoch  49 (149.69s)]	ELBO: 1415.437, 1488.102, 1582.157, 1628.037, 1652.778, 1672.946, 1686.599, 1695.339, 1700.522, 1704.087 (1705.465)	Log prob: 1418.873, 1494.864, 1592.144, 1640.536, 1667.336, 1689.514, 1704.955, 1715.263, 1721.733, 1726.425 (1727.264)	KLD: 3.436, 3.326, 3.224, 2.513, 2.059, 2.009, 1.789, 1.570, 1.286, 1.125 (21.800)	Grad: 1.123, 1.218, 0.675, 0.484, 0.335, 0.306, 0.263, 0.236, 0.216, 0.234
[Epoch  50 (150.66s)]	ELBO: 1415.622, 1488.413, 1582.615, 1628.569, 1653.400, 1673.377, 1687.069, 1695.786, 1700.954, 1704.654 (1704.510)	Log prob: 1419.058, 1495.177, 1592.605, 1641.079, 1667.976, 1689.963, 1705.454, 1715.744, 1722.190, 1727.034 (1726.854)	KLD: 3.436, 3.330, 3.225, 2.519, 2.067, 2.009, 1.799, 1.572, 1.278, 1.143 (22.344)	Grad: 1.093, 1.212, 0.667, 0.466, 0.330, 0.321, 0.268, 0.236, 0.206, 0.209
[Epoch  51 (145.43s)]	ELBO: 1415.900, 1488.691, 1582.968, 1628.863, 1653.666, 1673.707, 1687.353, 1696.102, 1701.332, 1704.949 (1703.840)	Log prob: 1419.339, 1495.462, 1592.963, 1641.380, 1668.245, 1690.299, 1705.743, 1716.062, 1722.577, 1727.328 (1726.289)	KLD: 3.440, 3.331, 3.224, 2.521, 2.065, 2.012, 1.796, 1.572, 1.284, 1.135 (22.449)	Grad: 1.103, 1.235, 0.649, 0.468, 0.351, 0.310, 0.293, 0.234, 0.209, 0.215
[Epoch  52 (165.58s)]	ELBO: 1416.016, 1488.925, 1583.319, 1629.216, 1654.056, 1674.111, 1687.737, 1696.501, 1701.684, 1705.338 (1707.084)	Log prob: 1419.463, 1495.707, 1593.327, 1641.741, 1668.647, 1690.711, 1706.137, 1716.473, 1722.941, 1727.720 (1729.703)	KLD: 3.446, 3.335, 3.226, 2.517, 2.066, 2.010, 1.801, 1.569, 1.286, 1.126 (22.619)	Grad: 1.097, 1.220, 0.662, 0.472, 0.316, 0.300, 0.273, 0.248, 0.210, 0.216
[Epoch  53 (161.56s)]	ELBO: 1416.237, 1489.240, 1583.596, 1629.384, 1654.257, 1674.310, 1687.958, 1696.803, 1701.953, 1705.662 (1706.337)	Log prob: 1419.690, 1496.030, 1593.618, 1641.929, 1668.871, 1690.940, 1706.384, 1716.807, 1723.239, 1728.081 (1729.014)	KLD: 3.454, 3.335, 3.233, 2.524, 2.068, 2.016, 1.797, 1.577, 1.280, 1.135 (22.678)	Grad: 1.066, 1.211, 0.643, 0.461, 0.370, 0.312, 0.257, 0.225, 0.211, 0.211
[Epoch  54 (165.00s)]	ELBO: 1416.464, 1489.705, 1584.070, 1629.905, 1654.883, 1674.926, 1688.606, 1697.400, 1702.628, 1706.307 (1707.433)	Log prob: 1419.922, 1496.496, 1594.091, 1642.447, 1669.494, 1691.553, 1707.030, 1717.399, 1723.907, 1728.722 (1729.966)	KLD: 3.457, 3.333, 3.231, 2.522, 2.068, 2.017, 1.797, 1.574, 1.281, 1.136 (22.534)	Grad: 1.061, 1.207, 0.662, 0.452, 0.321, 0.306, 0.255, 0.226, 0.210, 0.207
[Epoch  55 (165.19s)]	ELBO: 1416.692, 1489.964, 1584.432, 1630.233, 1655.155, 1675.243, 1688.949, 1697.784, 1703.002, 1706.594 (1708.047)	Log prob: 1420.153, 1496.757, 1594.458, 1642.781, 1669.776, 1691.882, 1707.388, 1717.801, 1724.299, 1729.015 (1730.191)	KLD: 3.462, 3.332, 3.232, 2.523, 2.074, 2.016, 1.800, 1.576, 1.282, 1.123 (22.144)	Grad: 1.123, 1.153, 0.640, 0.451, 0.339, 0.298, 0.260, 0.224, 0.200, 0.233
[Epoch  56 (150.58s)]	ELBO: 1417.008, 1490.420, 1584.660, 1630.488, 1655.554, 1675.544, 1689.227, 1698.011, 1703.269, 1706.940 (1707.844)	Log prob: 1420.468, 1497.220, 1594.696, 1643.048, 1670.183, 1692.192, 1707.670, 1718.031, 1724.570, 1729.370 (1730.035)	KLD: 3.460, 3.338, 3.238, 2.524, 2.070, 2.017, 1.796, 1.577, 1.282, 1.127 (22.192)	Grad: 1.059, 1.166, 0.665, 0.471, 0.343, 0.324, 0.272, 0.229, 0.209, 0.204
[Epoch  57 (160.30s)]	ELBO: 1417.213, 1490.772, 1584.971, 1630.839, 1655.933, 1675.839, 1689.554, 1698.341, 1703.577, 1707.276 (1708.173)	Log prob: 1420.670, 1497.568, 1595.004, 1643.403, 1670.571, 1692.498, 1708.009, 1718.371, 1724.893, 1729.720 (1730.257)	KLD: 3.458, 3.338, 3.237, 2.530, 2.076, 2.019, 1.797, 1.576, 1.284, 1.129 (22.083)	Grad: 1.097, 1.155, 0.640, 0.458, 0.340, 0.313, 0.270, 0.223, 0.194, 0.202
[Epoch  58 (170.01s)]	ELBO: 1417.409, 1491.063, 1585.269, 1631.069, 1656.173, 1676.069, 1689.762, 1698.494, 1703.816, 1707.445 (1707.624)	Log prob: 1420.868, 1497.858, 1595.311, 1643.639, 1670.821, 1692.740, 1708.234, 1718.538, 1725.144, 1729.901 (1730.108)	KLD: 3.460, 3.335, 3.245, 2.529, 2.078, 2.024, 1.801, 1.571, 1.283, 1.129 (22.484)	Grad: 1.074, 1.159, 0.658, 0.460, 0.327, 0.309, 0.279, 0.225, 0.207, 0.208
[Epoch  59 (163.79s)]	ELBO: 1417.545, 1491.330, 1585.501, 1631.245, 1656.390, 1676.324, 1690.080, 1698.825, 1704.049, 1707.721 (1706.767)	Log prob: 1421.014, 1498.138, 1595.553, 1643.826, 1671.053, 1693.012, 1708.560, 1718.877, 1725.386, 1730.185 (1729.273)	KLD: 3.469, 3.338, 3.245, 2.529, 2.081, 2.025, 1.794, 1.569, 1.287, 1.127 (22.506)	Grad: 1.093, 1.137, 0.660, 0.455, 0.343, 0.308, 0.279, 0.225, 0.198, 0.216
[Epoch  60 (147.44s)]	ELBO: 1417.842, 1491.724, 1585.968, 1631.690, 1656.830, 1676.740, 1690.517, 1699.261, 1704.471, 1708.170 (1708.484)	Log prob: 1421.314, 1498.533, 1596.029, 1644.281, 1671.503, 1693.435, 1709.015, 1719.327, 1725.829, 1730.649 (1730.594)	KLD: 3.472, 3.337, 3.251, 2.531, 2.082, 2.022, 1.804, 1.567, 1.292, 1.122 (22.110)	Grad: 1.098, 1.156, 0.657, 0.453, 0.346, 0.308, 0.269, 0.210, 0.202, 0.204
[Epoch  61 (150.42s)]	ELBO: 1418.156, 1492.202, 1586.307, 1632.078, 1657.250, 1677.212, 1690.931, 1699.638, 1704.851, 1708.531 (1709.079)	Log prob: 1421.632, 1499.020, 1596.381, 1644.684, 1671.942, 1693.927, 1709.445, 1719.722, 1726.225, 1731.039 (1731.355)	KLD: 3.478, 3.339, 3.257, 2.533, 2.084, 2.024, 1.799, 1.571, 1.290, 1.134 (22.277)	Grad: 1.057, 1.134, 0.638, 0.447, 0.334, 0.296, 0.254, 0.222, 0.202, 0.206
[Epoch  62 (147.36s)]	ELBO: 1418.345, 1492.220, 1586.449, 1632.186, 1657.347, 1677.235, 1690.966, 1699.667, 1704.930, 1708.594 (1709.267)	Log prob: 1421.828, 1499.043, 1596.533, 1644.800, 1672.046, 1693.955, 1709.493, 1719.763, 1726.317, 1731.099 (1731.990)	KLD: 3.484, 3.340, 3.260, 2.530, 2.084, 2.021, 1.808, 1.568, 1.291, 1.118 (22.723)	Grad: 1.062, 1.134, 0.653, 0.450, 0.324, 0.319, 0.272, 0.224, 0.198, 0.211
[Epoch  63 (151.17s)]	ELBO: 1418.504, 1492.788, 1586.937, 1632.485, 1657.770, 1677.620, 1691.373, 1699.965, 1705.261, 1708.955 (1710.091)	Log prob: 1421.991, 1499.622, 1597.031, 1645.117, 1672.485, 1694.362, 1709.917, 1720.076, 1726.663, 1731.485 (1732.584)	KLD: 3.488, 3.347, 3.259, 2.537, 2.085, 2.025, 1.803, 1.568, 1.290, 1.128 (22.493)	Grad: 1.065, 1.148, 0.672, 0.439, 0.337, 0.327, 0.282, 0.229, 0.204, 0.212
[Epoch  64 (148.21s)]	ELBO: 1418.864, 1493.004, 1587.184, 1632.781, 1658.024, 1677.896, 1691.696, 1700.330, 1705.599, 1709.269 (1709.518)	Log prob: 1422.359, 1499.846, 1597.290, 1645.423, 1672.759, 1694.662, 1710.262, 1720.457, 1727.017, 1731.815 (1731.888)	KLD: 3.496, 3.345, 3.266, 2.537, 2.091, 2.030, 1.800, 1.562, 1.292, 1.127 (22.370)	Grad: 1.070, 1.142, 0.650, 0.442, 0.311, 0.299, 0.270, 0.212, 0.193, 0.217
[Epoch  65 (140.48s)]	ELBO: 1419.128, 1493.337, 1587.491, 1632.909, 1658.247, 1678.143, 1691.883, 1700.521, 1705.815, 1709.506 (1710.362)	Log prob: 1422.626, 1500.176, 1597.600, 1645.555, 1672.980, 1694.907, 1710.446, 1720.642, 1727.223, 1732.043 (1732.906)	KLD: 3.498, 3.341, 3.270, 2.536, 2.089, 2.030, 1.799, 1.559, 1.286, 1.130 (22.543)	Grad: 1.057, 1.165, 0.660, 0.434, 0.322, 0.301, 0.274, 0.216, 0.202, 0.203
[Epoch  66 (143.46s)]	ELBO: 1419.246, 1493.482, 1587.752, 1633.316, 1658.634, 1678.421, 1692.183, 1700.829, 1706.057, 1709.820 (1710.065)	Log prob: 1422.748, 1500.328, 1597.868, 1645.976, 1673.389, 1695.208, 1710.772, 1720.975, 1727.494, 1732.388 (1732.493)	KLD: 3.503, 3.343, 3.272, 2.542, 2.094, 2.033, 1.802, 1.557, 1.290, 1.133 (22.429)	Grad: 1.083, 1.141, 0.645, 0.439, 0.340, 0.311, 0.274, 0.222, 0.197, 0.209
[Epoch  67 (152.42s)]	ELBO: 1419.490, 1493.804, 1588.022, 1633.485, 1658.910, 1678.681, 1692.383, 1701.028, 1706.206, 1709.937 (1711.066)	Log prob: 1423.000, 1500.658, 1598.149, 1646.155, 1673.671, 1695.466, 1710.970, 1721.173, 1727.646, 1732.509 (1733.427)	KLD: 3.510, 3.344, 3.274, 2.543, 2.090, 2.026, 1.800, 1.558, 1.296, 1.132 (22.360)	Grad: 1.094, 1.142, 0.655, 0.443, 0.321, 0.325, 0.276, 0.219, 0.202, 0.208
[Epoch  68 (148.37s)]	ELBO: 1419.805, 1493.958, 1588.290, 1633.662, 1659.127, 1678.893, 1692.681, 1701.231, 1706.485, 1710.124 (1710.328)	Log prob: 1423.318, 1500.814, 1598.423, 1646.335, 1673.900, 1695.692, 1711.279, 1721.385, 1727.928, 1732.695 (1732.727)	KLD: 3.513, 3.343, 3.277, 2.542, 2.096, 2.028, 1.798, 1.556, 1.290, 1.128 (22.398)	Grad: 1.104, 1.145, 0.675, 0.473, 0.332, 0.306, 0.269, 0.219, 0.199, 0.217
[Epoch  69 (143.94s)]	ELBO: 1419.980, 1494.189, 1588.424, 1633.813, 1659.273, 1679.074, 1692.854, 1701.423, 1706.653, 1710.229 (1710.732)	Log prob: 1423.500, 1501.051, 1598.567, 1646.503, 1674.061, 1695.887, 1711.465, 1721.589, 1728.101, 1732.797 (1733.135)	KLD: 3.519, 3.343, 3.280, 2.546, 2.097, 2.027, 1.798, 1.554, 1.284, 1.118 (22.403)	Grad: 1.087, 1.151, 0.682, 0.444, 0.314, 0.297, 0.290, 0.217, 0.195, 0.213
[Epoch  70 (146.59s)]	ELBO: 1420.342, 1494.480, 1588.869, 1634.129, 1659.603, 1679.379, 1693.178, 1701.655, 1706.908, 1710.599 (1711.558)	Log prob: 1423.864, 1501.345, 1599.017, 1646.823, 1674.395, 1696.202, 1711.792, 1721.823, 1728.359, 1733.186 (1734.005)	KLD: 3.521, 3.344, 3.284, 2.544, 2.100, 2.030, 1.792, 1.553, 1.285, 1.134 (22.447)	Grad: 1.049, 1.165, 0.675, 0.452, 0.322, 0.318, 0.276, 0.218, 0.199, 0.204
[Epoch  71 (146.04s)]	ELBO: 1420.809, 1494.787, 1589.193, 1634.461, 1659.945, 1679.643, 1693.353, 1701.792, 1707.116, 1710.709 (1711.345)	Log prob: 1424.343, 1501.667, 1599.366, 1647.180, 1674.766, 1696.489, 1711.991, 1721.987, 1728.603, 1733.328 (1733.870)	KLD: 3.533, 3.348, 3.291, 2.549, 2.099, 2.026, 1.793, 1.555, 1.293, 1.130 (22.525)	Grad: 1.078, 1.151, 0.660, 0.446, 0.348, 0.311, 0.275, 0.220, 0.200, 0.214
[Epoch  72 (140.60s)]	ELBO: 1421.092, 1495.021, 1589.289, 1634.554, 1660.117, 1679.913, 1693.638, 1702.125, 1707.323, 1711.030 (1711.589)	Log prob: 1424.632, 1501.901, 1599.464, 1647.278, 1674.942, 1696.766, 1712.286, 1722.332, 1728.819, 1733.642 (1734.134)	KLD: 3.539, 3.342, 3.294, 2.549, 2.101, 2.028, 1.796, 1.559, 1.290, 1.115 (22.545)	Grad: 1.082, 1.165, 0.664, 0.449, 0.316, 0.305, 0.260, 0.216, 0.200, 0.205
[Epoch  73 (137.65s)]	ELBO: 1421.532, 1495.364, 1589.662, 1634.879, 1660.461, 1680.168, 1693.895, 1702.412, 1707.686, 1711.279 (1710.132)	Log prob: 1425.073, 1502.252, 1599.847, 1647.618, 1675.295, 1697.037, 1712.548, 1722.613, 1729.174, 1733.895 (1732.708)	KLD: 3.541, 3.347, 3.297, 2.553, 2.097, 2.034, 1.786, 1.546, 1.288, 1.127 (22.576)	Grad: 1.083, 1.135, 0.675, 0.430, 0.338, 0.311, 0.254, 0.213, 0.187, 0.200
[Epoch  74 (145.35s)]	ELBO: 1421.779, 1495.522, 1589.852, 1635.006, 1660.609, 1680.350, 1693.999, 1702.582, 1707.792, 1711.397 (1710.781)	Log prob: 1425.329, 1502.416, 1600.045, 1647.752, 1675.460, 1697.230, 1712.674, 1722.813, 1729.308, 1734.052 (1733.395)	KLD: 3.550, 3.344, 3.299, 2.552, 2.105, 2.029, 1.794, 1.555, 1.286, 1.141 (22.615)	Grad: 1.104, 1.138, 0.678, 0.451, 0.322, 0.310, 0.277, 0.211, 0.192, 0.207
[Epoch  75 (145.31s)]	ELBO: 1422.258, 1495.762, 1590.173, 1635.199, 1660.772, 1680.415, 1694.077, 1702.549, 1707.708, 1711.381 (1711.842)	Log prob: 1425.810, 1502.661, 1600.380, 1647.957, 1675.635, 1697.307, 1712.760, 1722.783, 1729.236, 1734.039 (1733.820)	KLD: 3.552, 3.346, 3.308, 2.551, 2.105, 2.030, 1.790, 1.553, 1.291, 1.132 (21.978)	Grad: 1.146, 1.120, 0.699, 0.456, 0.321, 0.331, 0.275, 0.216, 0.205, 0.208
[Epoch  76 (136.99s)]	ELBO: 1422.595, 1496.083, 1590.395, 1635.520, 1661.177, 1680.810, 1694.479, 1702.824, 1708.032, 1711.763 (1711.480)	Log prob: 1426.152, 1502.990, 1600.607, 1648.286, 1676.050, 1697.709, 1713.172, 1723.067, 1729.564, 1734.419 (1734.159)	KLD: 3.557, 3.349, 3.307, 2.554, 2.107, 2.028, 1.792, 1.550, 1.289, 1.126 (22.679)	Grad: 1.116, 1.135, 0.687, 0.437, 0.333, 0.316, 0.268, 0.226, 0.194, 0.200
[Epoch  77 (136.82s)]	ELBO: 1423.155, 1496.462, 1590.804, 1635.721, 1661.308, 1680.946, 1694.655, 1703.115, 1708.308, 1711.924 (1712.920)	Log prob: 1426.718, 1503.371, 1601.020, 1648.492, 1676.188, 1697.856, 1713.356, 1723.370, 1729.850, 1734.597 (1735.607)	KLD: 3.563, 3.346, 3.307, 2.555, 2.108, 2.031, 1.793, 1.552, 1.289, 1.130 (22.686)	Grad: 1.168, 1.141, 0.680, 0.441, 0.334, 0.317, 0.271, 0.212, 0.198, 0.209
[Epoch  78 (148.70s)]	ELBO: 1423.503, 1496.539, 1590.871, 1635.896, 1661.529, 1681.261, 1694.854, 1703.346, 1708.497, 1712.136 (1712.401)	Log prob: 1427.072, 1503.456, 1601.106, 1648.688, 1676.425, 1698.192, 1713.574, 1723.615, 1730.057, 1734.823 (1735.016)	KLD: 3.568, 3.349, 3.318, 2.556, 2.105, 2.035, 1.790, 1.550, 1.290, 1.128 (22.615)	Grad: 1.149, 1.138, 0.689, 0.446, 0.330, 0.301, 0.279, 0.213, 0.202, 0.209
[Epoch  79 (154.57s)]	ELBO: 1423.904, 1496.957, 1591.278, 1636.198, 1661.871, 1681.532, 1695.195, 1703.593, 1708.766, 1712.501 (1711.724)	Log prob: 1427.484, 1503.882, 1601.520, 1648.997, 1676.778, 1698.473, 1713.922, 1723.865, 1730.328, 1735.197 (1734.161)	KLD: 3.580, 3.344, 3.317, 2.557, 2.109, 2.034, 1.786, 1.545, 1.290, 1.133 (22.436)	Grad: 1.148, 1.132, 0.709, 0.436, 0.334, 0.315, 0.263, 0.212, 0.197, 0.197
[Epoch  80 (142.52s)]	ELBO: 1424.157, 1497.150, 1591.414, 1636.278, 1662.103, 1681.876, 1695.385, 1703.776, 1708.900, 1712.465 (1712.625)	Log prob: 1427.741, 1504.083, 1601.666, 1649.091, 1677.026, 1698.831, 1714.127, 1724.062, 1730.470, 1735.169 (1735.133)	KLD: 3.583, 3.350, 3.320, 2.560, 2.110, 2.034, 1.785, 1.543, 1.285, 1.134 (22.508)	Grad: 1.156, 1.158, 0.700, 0.437, 0.336, 0.302, 0.277, 0.215, 0.201, 0.209
[Epoch  81 (147.28s)]	ELBO: 1424.484, 1497.223, 1591.707, 1636.550, 1662.271, 1681.999, 1695.657, 1703.946, 1709.154, 1712.822 (1712.887)	Log prob: 1428.066, 1504.156, 1601.964, 1649.372, 1677.206, 1698.967, 1714.411, 1724.248, 1730.743, 1735.543 (1735.478)	KLD: 3.582, 3.352, 3.323, 2.564, 2.113, 2.034, 1.787, 1.546, 1.288, 1.133 (22.591)	Grad: 1.162, 1.168, 0.690, 0.447, 0.313, 0.307, 0.258, 0.219, 0.200, 0.200
[Epoch  82 (145.09s)]	ELBO: 1424.958, 1497.673, 1591.938, 1636.671, 1662.334, 1682.058, 1695.638, 1704.026, 1709.220, 1712.808 (1712.565)	Log prob: 1428.554, 1504.626, 1602.215, 1649.514, 1677.290, 1699.046, 1714.408, 1724.343, 1730.830, 1735.550 (1735.043)	KLD: 3.596, 3.358, 3.324, 2.565, 2.112, 2.032, 1.785, 1.547, 1.294, 1.130 (22.478)	Grad: 1.180, 1.131, 0.707, 0.435, 0.328, 0.321, 0.254, 0.214, 0.193, 0.196
[Epoch  83 (157.83s)]	ELBO: 1425.363, 1498.049, 1592.167, 1636.857, 1662.633, 1682.304, 1695.944, 1704.239, 1709.431, 1712.970 (1712.739)	Log prob: 1428.962, 1505.002, 1602.451, 1649.708, 1677.597, 1699.307, 1714.734, 1724.571, 1731.055, 1735.721 (1735.248)	KLD: 3.598, 3.354, 3.331, 2.569, 2.113, 2.038, 1.787, 1.544, 1.290, 1.129 (22.509)	Grad: 1.199, 1.138, 0.696, 0.437, 0.324, 0.302, 0.264, 0.218, 0.197, 0.210
[Epoch  84 (159.39s)]	ELBO: 1425.433, 1498.109, 1592.430, 1637.031, 1662.715, 1682.417, 1695.975, 1704.328, 1709.547, 1713.136 (1713.840)	Log prob: 1429.035, 1505.064, 1602.719, 1649.889, 1677.686, 1699.427, 1714.764, 1724.663, 1731.181, 1735.892 (1736.492)	KLD: 3.602, 3.352, 3.335, 2.569, 2.113, 2.038, 1.780, 1.545, 1.299, 1.122 (22.652)	Grad: 1.197, 1.127, 0.704, 0.432, 0.334, 0.306, 0.250, 0.215, 0.187, 0.200
[Epoch  85 (151.04s)]	ELBO: 1425.725, 1498.459, 1592.710, 1637.227, 1662.963, 1682.649, 1696.094, 1704.445, 1709.695, 1713.310 (1712.915)	Log prob: 1429.329, 1505.418, 1602.997, 1650.081, 1677.930, 1699.655, 1714.884, 1724.779, 1731.317, 1736.059 (1735.202)	KLD: 3.605, 3.353, 3.328, 2.567, 2.114, 2.037, 1.784, 1.545, 1.287, 1.127 (22.286)	Grad: 1.269, 1.133, 0.693, 0.445, 0.338, 0.301, 0.275, 0.214, 0.202, 0.202
[Epoch  86 (132.97s)]	ELBO: 1426.240, 1498.531, 1592.797, 1637.259, 1663.050, 1682.622, 1696.046, 1704.455, 1709.645, 1713.195 (1713.951)	Log prob: 1429.847, 1505.492, 1603.098, 1650.129, 1678.032, 1699.641, 1714.847, 1724.797, 1731.273, 1735.955 (1736.482)	KLD: 3.606, 3.353, 3.339, 2.571, 2.113, 2.037, 1.780, 1.541, 1.285, 1.134 (22.531)	Grad: 1.241, 1.144, 0.731, 0.433, 0.329, 0.323, 0.267, 0.214, 0.203, 0.199
[Epoch  87 (132.77s)]	ELBO: 1426.430, 1498.810, 1592.941, 1637.466, 1663.321, 1683.016, 1696.465, 1704.815, 1710.014, 1713.553 (1713.189)	Log prob: 1430.041, 1505.773, 1603.246, 1650.339, 1678.307, 1700.035, 1715.268, 1725.160, 1731.647, 1736.318 (1735.679)	KLD: 3.610, 3.352, 3.342, 2.570, 2.113, 2.034, 1.783, 1.545, 1.285, 1.134 (22.490)	Grad: 1.224, 1.150, 0.717, 0.449, 0.311, 0.319, 0.256, 0.210, 0.190, 0.197
[Epoch  88 (137.33s)]	ELBO: 1427.201, 1499.296, 1593.656, 1637.885, 1663.685, 1683.350, 1696.721, 1705.096, 1710.324, 1713.837 (1713.665)	Log prob: 1430.824, 1506.274, 1603.984, 1650.781, 1678.700, 1700.402, 1715.553, 1725.474, 1731.994, 1736.627 (1736.231)	KLD: 3.623, 3.355, 3.351, 2.569, 2.117, 2.039, 1.778, 1.547, 1.291, 1.123 (22.566)	Grad: 1.183, 1.117, 0.710, 0.420, 0.341, 0.311, 0.281, 0.209, 0.195, 0.198
[Epoch  89 (126.29s)]	ELBO: 1427.338, 1499.354, 1593.783, 1637.990, 1663.835, 1683.494, 1696.938, 1705.309, 1710.438, 1713.937 (1714.389)	Log prob: 1430.961, 1506.335, 1604.118, 1650.893, 1678.856, 1700.556, 1715.781, 1725.695, 1732.116, 1736.744 (1737.266)	KLD: 3.625, 3.357, 3.352, 2.570, 2.118, 2.040, 1.782, 1.544, 1.292, 1.128 (22.877)	Grad: 1.226, 1.143, 0.697, 0.424, 0.327, 0.306, 0.258, 0.212, 0.189, 0.200
[Epoch  90 (123.23s)]	ELBO: 1427.746, 1499.649, 1593.835, 1638.047, 1663.830, 1683.471, 1696.867, 1705.161, 1710.411, 1713.929 (1713.648)	Log prob: 1431.377, 1506.630, 1604.170, 1650.959, 1678.857, 1700.537, 1715.712, 1725.547, 1732.087, 1736.728 (1736.294)	KLD: 3.630, 3.352, 3.352, 2.577, 2.117, 2.038, 1.778, 1.543, 1.290, 1.123 (22.645)	Grad: 1.268, 1.144, 0.719, 0.434, 0.349, 0.312, 0.267, 0.208, 0.195, 0.203
[Epoch  91 (130.39s)]	ELBO: 1427.810, 1499.955, 1594.048, 1638.156, 1663.962, 1683.716, 1697.135, 1705.439, 1710.651, 1714.163 (1713.276)	Log prob: 1431.447, 1506.947, 1604.394, 1651.076, 1679.002, 1700.795, 1715.995, 1725.847, 1732.348, 1736.979 (1735.771)	KLD: 3.635, 3.356, 3.355, 2.574, 2.119, 2.039, 1.782, 1.547, 1.290, 1.118 (22.495)	Grad: 1.263, 1.119, 0.683, 0.436, 0.325, 0.299, 0.264, 0.201, 0.192, 0.196
[Epoch  92 (131.91s)]	ELBO: 1428.200, 1500.066, 1594.404, 1638.358, 1664.286, 1683.897, 1697.330, 1705.588, 1710.734, 1714.315 (1714.197)	Log prob: 1431.846, 1507.067, 1604.760, 1651.293, 1679.341, 1700.993, 1716.202, 1726.001, 1732.435, 1737.141 (1737.111)	KLD: 3.646, 3.355, 3.357, 2.577, 2.122, 2.038, 1.776, 1.543, 1.288, 1.124 (22.914)	Grad: 1.245, 1.111, 0.705, 0.419, 0.321, 0.301, 0.252, 0.225, 0.195, 0.200
[Epoch  93 (120.61s)]	ELBO: 1428.493, 1500.262, 1594.614, 1638.523, 1664.449, 1684.023, 1697.342, 1705.639, 1710.749, 1714.240 (1713.719)	Log prob: 1432.138, 1507.261, 1604.973, 1651.460, 1679.506, 1701.114, 1716.212, 1726.053, 1732.448, 1737.060 (1736.638)	KLD: 3.646, 3.352, 3.361, 2.577, 2.118, 2.036, 1.777, 1.544, 1.287, 1.120 (22.919)	Grad: 1.223, 1.136, 0.725, 0.440, 0.355, 0.311, 0.265, 0.214, 0.198, 0.201
[Epoch  94 (126.32s)]	ELBO: 1428.616, 1500.572, 1594.607, 1638.530, 1664.490, 1684.069, 1697.329, 1705.712, 1710.808, 1714.241 (1712.883)	Log prob: 1432.266, 1507.581, 1604.974, 1651.476, 1679.554, 1701.171, 1716.211, 1726.141, 1732.523, 1737.086 (1735.809)	KLD: 3.651, 3.358, 3.358, 2.578, 2.119, 2.038, 1.779, 1.549, 1.286, 1.129 (22.926)	Grad: 1.266, 1.145, 0.737, 0.444, 0.315, 0.313, 0.265, 0.208, 0.196, 0.205
[Epoch  95 (126.27s)]	ELBO: 1428.685, 1500.804, 1594.825, 1638.718, 1664.581, 1684.150, 1697.456, 1705.744, 1710.931, 1714.429 (1714.678)	Log prob: 1432.338, 1507.822, 1605.214, 1651.682, 1679.665, 1701.270, 1716.356, 1726.190, 1732.663, 1737.292 (1737.663)	KLD: 3.653, 3.366, 3.369, 2.577, 2.119, 2.037, 1.779, 1.547, 1.287, 1.131 (22.985)	Grad: 1.323, 1.143, 0.725, 0.448, 0.323, 0.311, 0.264, 0.218, 0.191, 0.202
[Epoch  96 (127.93s)]	ELBO: 1429.334, 1501.108, 1595.078, 1638.974, 1664.774, 1684.382, 1697.708, 1705.984, 1711.110, 1714.598 (1714.993)	Log prob: 1432.990, 1508.119, 1605.454, 1651.937, 1679.858, 1701.508, 1716.607, 1726.428, 1732.850, 1737.462 (1737.742)	KLD: 3.655, 3.355, 3.365, 2.587, 2.121, 2.041, 1.774, 1.544, 1.297, 1.123 (22.749)	Grad: 1.257, 1.132, 0.723, 0.419, 0.322, 0.322, 0.260, 0.215, 0.200, 0.202
[Epoch  97 (114.27s)]	ELBO: 1429.222, 1501.203, 1595.340, 1639.049, 1664.905, 1684.545, 1697.851, 1706.164, 1711.268, 1714.748 (1714.608)	Log prob: 1432.893, 1508.233, 1605.742, 1652.032, 1680.003, 1701.685, 1716.765, 1726.630, 1733.015, 1737.621 (1737.374)	KLD: 3.670, 3.359, 3.374, 2.580, 2.115, 2.041, 1.775, 1.551, 1.280, 1.127 (22.767)	Grad: 1.263, 1.114, 0.746, 0.444, 0.326, 0.314, 0.259, 0.217, 0.194, 0.199
[Epoch  98 (120.75s)]	ELBO: 1429.860, 1501.577, 1595.545, 1639.251, 1665.196, 1684.781, 1697.918, 1706.282, 1711.365, 1714.925 (1715.701)	Log prob: 1433.524, 1508.601, 1605.937, 1652.224, 1680.290, 1701.916, 1716.830, 1726.736, 1733.103, 1737.771 (1738.373)	KLD: 3.664, 3.359, 3.369, 2.582, 2.121, 2.040, 1.777, 1.542, 1.284, 1.109 (22.671)	Grad: 1.332, 1.100, 0.726, 0.434, 0.324, 0.302, 0.257, 0.218, 0.189, 0.201
[Epoch  99 (115.31s)]	ELBO: 1430.422, 1501.933, 1595.745, 1639.232, 1665.100, 1684.760, 1697.962, 1706.316, 1711.366, 1714.820 (1714.771)	Log prob: 1434.100, 1508.968, 1606.147, 1652.216, 1680.201, 1701.899, 1716.881, 1726.785, 1733.119, 1737.700 (1737.224)	KLD: 3.677, 3.357, 3.368, 2.581, 2.117, 2.040, 1.778, 1.548, 1.286, 1.127 (22.453)	Grad: 1.269, 1.112, 0.730, 0.445, 0.343, 0.300, 0.262, 0.217, 0.196, 0.203
[Epoch 100 (85.60s)]	ELBO: 1430.706, 1502.202, 1596.244, 1639.780, 1665.663, 1685.229, 1698.441, 1706.778, 1711.820, 1715.272 (1714.506)	Log prob: 1434.382, 1509.242, 1606.658, 1652.778, 1680.780, 1702.385, 1717.369, 1727.257, 1733.588, 1738.149 (1737.512)	KLD: 3.676, 3.365, 3.374, 2.583, 2.119, 2.039, 1.773, 1.550, 1.289, 1.111 (23.006)	Grad: 1.322, 1.097, 0.723, 0.424, 0.308, 0.300, 0.262, 0.203, 0.193, 0.193
Best epoch(s): [98]	Training time(s): 13769.33s (13769.33s)	Best ELBO: 1715.272 (1715.701)	Best log prob: 1738.149 (1738.373)
Avg. mu: -0.101, 0.069, -0.041, -0.024, -0.112, 0.042, -0.000, 0.147, 0.114, -0.031
Avg. var: 0.002, 0.003, 0.003, 0.010, 0.016, 0.024, 0.036, 0.058, 0.096, 0.137
Max. mu: 5.666, 4.484, 4.021, 4.256, 4.000, 4.856, 4.166, 4.828, 4.962, 4.904
Max. var: 0.081, 0.055, 0.058, 0.104, 0.075, 0.133, 0.181, 0.556, 0.419, 0.574
Min. mu: -4.707, -4.697, -4.900, -5.355, -3.995, -3.634, -4.703, -4.264, -4.953, -4.015
Min. var: 0.000, 0.000, 0.000, 0.001, 0.005, 0.002, 0.006, 0.010, 0.017, 0.034
Cov. mu:
[[1.503 -0.261 -0.387 0.029 0.104 0.115 0.157 -0.082 -0.241 0.091]
 [-0.261 1.186 0.336 -0.030 -0.042 -0.076 -0.088 -0.009 0.063 0.024]
 [-0.387 0.336 1.660 -0.160 -0.027 -0.137 -0.047 -0.004 0.182 0.077]
 [0.029 -0.030 -0.160 1.118 -0.082 0.001 -0.017 -0.092 -0.019 -0.019]
 [0.104 -0.042 -0.027 -0.082 1.028 0.020 0.062 -0.030 -0.006 0.037]
 [0.115 -0.076 -0.137 0.001 0.020 0.984 0.060 -0.009 -0.013 0.026]
 [0.157 -0.088 -0.047 -0.017 0.062 0.060 0.987 0.023 -0.029 0.048]
 [-0.082 -0.009 -0.004 -0.092 -0.030 -0.009 0.023 0.994 0.013 -0.025]
 [-0.241 0.063 0.182 -0.019 -0.006 -0.013 -0.029 0.013 1.016 -0.039]
 [0.091 0.024 0.077 -0.019 0.037 0.026 0.048 -0.025 -0.039 0.874]]
