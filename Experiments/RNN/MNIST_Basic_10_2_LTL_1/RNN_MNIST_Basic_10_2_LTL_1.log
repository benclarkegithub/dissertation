Encoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Encoder                                  --
├─Linear: 1-1                            31,400
├─Linear: 1-2                            1,640
=================================================================
Total params: 33,040
Trainable params: 33,040
Non-trainable params: 0
=================================================================
Encoder 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Encoder                                  --
├─Linear: 1-1                            31,400
├─Linear: 1-2                            1,640
=================================================================
Total params: 33,040
Trainable params: 33,040
Non-trainable params: 0
=================================================================
Encoder to Latents 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            82
├─Linear: 1-2                            82
=================================================================
Total params: 164
Trainable params: 164
Non-trainable params: 0
=================================================================
Encoder to Latents 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            82
├─Linear: 1-2                            82
=================================================================
Total params: 164
Trainable params: 164
Non-trainable params: 0
=================================================================
Encoder to Latents 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            82
├─Linear: 1-2                            82
=================================================================
Total params: 164
Trainable params: 164
Non-trainable params: 0
=================================================================
Encoder to Latents 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            82
├─Linear: 1-2                            82
=================================================================
Total params: 164
Trainable params: 164
Non-trainable params: 0
=================================================================
Encoder to Latents 4
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            82
├─Linear: 1-2                            82
=================================================================
Total params: 164
Trainable params: 164
Non-trainable params: 0
=================================================================
Latents to Latents
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToLatents                         --
├─Linear: 1-1                            72
├─Linear: 1-2                            18
├─Linear: 1-3                            18
=================================================================
Total params: 108
Trainable params: 108
Non-trainable params: 0
=================================================================
Latents to Decoder 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            120
=================================================================
Total params: 120
Trainable params: 120
Non-trainable params: 0
=================================================================
Latents to Decoder 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            120
=================================================================
Total params: 120
Trainable params: 120
Non-trainable params: 0
=================================================================
Latents to Decoder 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            120
=================================================================
Total params: 120
Trainable params: 120
Non-trainable params: 0
=================================================================
Latents to Decoder 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            120
=================================================================
Total params: 120
Trainable params: 120
Non-trainable params: 0
=================================================================
Latents to Decoder 4
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            120
=================================================================
Total params: 120
Trainable params: 120
Non-trainable params: 0
=================================================================
Decoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Decoder                                  --
├─Linear: 1-1                            1,640
├─Linear: 1-2                            32,144
=================================================================
Total params: 33,784
Trainable params: 33,784
Non-trainable params: 0
=================================================================
Encoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Encoder                                  --
├─Linear: 1-1                            31,400
├─Linear: 1-2                            1,640
=================================================================
Total params: 33,040
Trainable params: 33,040
Non-trainable params: 0
=================================================================
Encoder 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Encoder                                  --
├─Linear: 1-1                            31,400
├─Linear: 1-2                            1,640
=================================================================
Total params: 33,040
Trainable params: 33,040
Non-trainable params: 0
=================================================================
Encoder to Latents 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            82
├─Linear: 1-2                            82
=================================================================
Total params: 164
Trainable params: 164
Non-trainable params: 0
=================================================================
Encoder to Latents 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            82
├─Linear: 1-2                            82
=================================================================
Total params: 164
Trainable params: 164
Non-trainable params: 0
=================================================================
Encoder to Latents 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            82
├─Linear: 1-2                            82
=================================================================
Total params: 164
Trainable params: 164
Non-trainable params: 0
=================================================================
Encoder to Latents 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            82
├─Linear: 1-2                            82
=================================================================
Total params: 164
Trainable params: 164
Non-trainable params: 0
=================================================================
Encoder to Latents 4
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
EncoderToLatents                         --
├─Linear: 1-1                            82
├─Linear: 1-2                            82
=================================================================
Total params: 164
Trainable params: 164
Non-trainable params: 0
=================================================================
Latents to Latents
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToLatents                         --
├─Linear: 1-1                            72
├─Linear: 1-2                            18
├─Linear: 1-3                            18
=================================================================
Total params: 108
Trainable params: 108
Non-trainable params: 0
=================================================================
Latents to Decoder 0
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            120
=================================================================
Total params: 120
Trainable params: 120
Non-trainable params: 0
=================================================================
Latents to Decoder 1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            120
=================================================================
Total params: 120
Trainable params: 120
Non-trainable params: 0
=================================================================
Latents to Decoder 2
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            120
=================================================================
Total params: 120
Trainable params: 120
Non-trainable params: 0
=================================================================
Latents to Decoder 3
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            120
=================================================================
Total params: 120
Trainable params: 120
Non-trainable params: 0
=================================================================
Latents to Decoder 4
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
LatentsToDecoder                         --
├─Linear: 1-1                            120
=================================================================
Total params: 120
Trainable params: 120
Non-trainable params: 0
=================================================================
Decoder
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Decoder                                  --
├─Linear: 1-1                            1,640
├─Linear: 1-2                            32,144
=================================================================
Total params: 33,784
Trainable params: 33,784
Non-trainable params: 0
=================================================================
[Epoch   1 (34.03s)]	ELBO: 1201.190, 1216.656, 1226.260, 1227.778, 1226.305 (1379.496)	Log prob: 1219.837, 1235.914, 1246.762, 1248.841, 1247.871 (1392.453)	KLD: 18.648, 19.257, 20.502, 21.064, 21.566 (12.957)	Grad: 0.163, 0.196, 0.237, 0.260, 0.297
[Epoch   2 (41.07s)]	ELBO: 1392.048, 1394.699, 1394.609, 1393.856, 1392.873 (1403.187)	Log prob: 1400.282, 1403.897, 1404.924, 1405.038, 1404.621 (1413.433)	KLD: 8.234, 9.198, 10.315, 11.182, 11.749 (10.246)	Grad: 0.095, 0.089, 0.119, 0.143, 0.175
[Epoch   3 (64.08s)]	ELBO: 1407.704, 1434.091, 1434.793, 1434.794, 1434.290 (1474.648)	Log prob: 1414.563, 1443.779, 1445.625, 1446.650, 1446.526 (1488.474)	KLD: 6.859, 9.688, 10.832, 11.857, 12.236 (13.826)	Grad: 0.079, 0.087, 0.119, 0.153, 0.191
[Epoch   4 (73.61s)]	ELBO: 1428.753, 1499.681, 1505.750, 1505.607, 1505.139 (1533.249)	Log prob: 1435.680, 1511.809, 1519.958, 1520.847, 1520.640 (1549.277)	KLD: 6.928, 12.126, 14.207, 15.241, 15.501 (16.028)	Grad: 0.077, 0.106, 0.147, 0.195, 0.246
[Epoch   5 (58.16s)]	ELBO: 1454.205, 1541.315, 1553.699, 1553.434, 1553.215 (1571.126)	Log prob: 1461.688, 1554.411, 1569.709, 1569.868, 1569.734 (1587.700)	KLD: 7.483, 13.095, 16.011, 16.434, 16.520 (16.574)	Grad: 0.082, 0.122, 0.169, 0.226, 0.286
[Epoch   6 (59.01s)]	ELBO: 1472.247, 1561.187, 1580.711, 1580.682, 1580.489 (1592.290)	Log prob: 1479.785, 1574.229, 1596.835, 1597.096, 1596.985 (1608.814)	KLD: 7.537, 13.041, 16.124, 16.414, 16.496 (16.524)	Grad: 0.089, 0.135, 0.188, 0.250, 0.316
[Epoch   7 (60.35s)]	ELBO: 1480.380, 1570.997, 1599.874, 1599.993, 1599.983 (1608.639)	Log prob: 1487.859, 1583.918, 1616.264, 1616.619, 1616.731 (1625.510)	KLD: 7.479, 12.921, 16.391, 16.626, 16.748 (16.871)	Grad: 0.097, 0.147, 0.200, 0.264, 0.334
[Epoch   8 (63.14s)]	ELBO: 1485.685, 1578.825, 1614.089, 1615.792, 1615.987 (1624.348)	Log prob: 1493.110, 1591.730, 1630.688, 1632.999, 1633.482 (1642.261)	KLD: 7.426, 12.905, 16.597, 17.208, 17.496 (17.913)	Grad: 0.107, 0.159, 0.217, 0.284, 0.359
[Epoch   9 (61.48s)]	ELBO: 1490.783, 1584.922, 1623.034, 1630.410, 1630.333 (1636.629)	Log prob: 1498.190, 1597.813, 1639.745, 1648.720, 1648.877 (1655.403)	KLD: 7.406, 12.892, 16.711, 18.311, 18.542 (18.774)	Grad: 0.109, 0.161, 0.219, 0.283, 0.355
[Epoch  10 (58.47s)]	ELBO: 1494.535, 1589.533, 1629.514, 1639.794, 1639.773 (1643.576)	Log prob: 1501.960, 1602.452, 1646.311, 1658.635, 1658.765 (1662.572)	KLD: 7.426, 12.919, 16.798, 18.841, 18.993 (18.996)	Grad: 0.113, 0.168, 0.230, 0.299, 0.373
[Epoch  11 (61.39s)]	ELBO: 1497.606, 1593.629, 1634.459, 1645.737, 1645.684 (1647.796)	Log prob: 1505.015, 1606.516, 1651.277, 1664.701, 1664.772 (1666.697)	KLD: 7.409, 12.888, 16.817, 18.962, 19.089 (18.901)	Grad: 0.115, 0.172, 0.234, 0.304, 0.380
[Epoch  12 (63.99s)]	ELBO: 1500.249, 1597.215, 1638.524, 1650.101, 1650.043 (1652.026)	Log prob: 1507.633, 1610.070, 1655.338, 1669.112, 1669.162 (1670.921)	KLD: 7.383, 12.857, 16.813, 19.009, 19.117 (18.895)	Grad: 0.111, 0.167, 0.228, 0.296, 0.371
[Epoch  13 (61.09s)]	ELBO: 1502.559, 1600.325, 1641.837, 1653.720, 1653.670 (1655.443)	Log prob: 1509.910, 1613.118, 1658.602, 1672.724, 1672.782 (1674.322)	KLD: 7.351, 12.793, 16.765, 19.003, 19.112 (18.879)	Grad: 0.110, 0.169, 0.230, 0.298, 0.373
[Epoch  14 (64.28s)]	ELBO: 1504.524, 1603.068, 1644.709, 1656.674, 1656.698 (1658.807)	Log prob: 1511.852, 1615.826, 1661.453, 1675.701, 1675.865 (1678.035)	KLD: 7.327, 12.758, 16.744, 19.027, 19.168 (19.228)	Grad: 0.111, 0.173, 0.237, 0.307, 0.385
[Epoch  15 (75.87s)]	ELBO: 1506.437, 1605.471, 1647.135, 1659.225, 1659.453 (1661.285)	Log prob: 1513.747, 1618.190, 1663.845, 1678.269, 1678.737 (1680.427)	KLD: 7.311, 12.719, 16.711, 19.045, 19.285 (19.142)	Grad: 0.109, 0.171, 0.233, 0.304, 0.381
[Epoch  16 (67.08s)]	ELBO: 1508.263, 1607.564, 1649.364, 1661.844, 1662.478 (1664.436)	Log prob: 1515.577, 1620.274, 1666.079, 1680.965, 1682.037 (1683.964)	KLD: 7.315, 12.710, 16.715, 19.121, 19.560 (19.528)	Grad: 0.110, 0.174, 0.236, 0.306, 0.383
[Epoch  17 (70.66s)]	ELBO: 1509.982, 1609.365, 1651.267, 1664.566, 1666.000 (1667.983)	Log prob: 1517.293, 1622.063, 1667.979, 1683.819, 1685.999 (1688.088)	KLD: 7.311, 12.699, 16.711, 19.253, 19.999 (20.105)	Grad: 0.109, 0.175, 0.238, 0.311, 0.389
[Epoch  18 (73.79s)]	ELBO: 1511.391, 1610.912, 1652.838, 1667.854, 1670.313 (1673.152)	Log prob: 1518.698, 1623.599, 1669.551, 1687.315, 1690.743 (1693.480)	KLD: 7.305, 12.687, 16.712, 19.460, 20.428 (20.329)	Grad: 0.109, 0.174, 0.237, 0.307, 0.383
[Epoch  19 (80.71s)]	ELBO: 1512.578, 1612.134, 1654.148, 1670.844, 1674.499 (1677.502)	Log prob: 1519.861, 1624.797, 1670.848, 1690.479, 1695.267 (1698.434)	KLD: 7.282, 12.665, 16.700, 19.634, 20.768 (20.932)	Grad: 0.114, 0.183, 0.251, 0.327, 0.408
[Epoch  20 (69.71s)]	ELBO: 1513.832, 1613.404, 1655.499, 1673.366, 1677.802 (1680.830)	Log prob: 1521.119, 1626.068, 1672.200, 1693.114, 1698.799 (1701.927)	KLD: 7.287, 12.665, 16.700, 19.748, 20.996 (21.097)	Grad: 0.111, 0.180, 0.247, 0.320, 0.399
[Epoch  21 (76.81s)]	ELBO: 1514.669, 1614.435, 1656.706, 1675.309, 1680.286 (1681.697)	Log prob: 1521.962, 1627.104, 1673.420, 1695.143, 1701.406 (1702.745)	KLD: 7.292, 12.669, 16.714, 19.834, 21.120 (21.048)	Grad: 0.112, 0.181, 0.249, 0.322, 0.401
[Epoch  22 (78.67s)]	ELBO: 1515.966, 1615.669, 1658.032, 1677.178, 1682.376 (1683.191)	Log prob: 1523.256, 1628.327, 1674.729, 1697.027, 1703.537 (1704.361)	KLD: 7.290, 12.657, 16.696, 19.850, 21.162 (21.170)	Grad: 0.114, 0.184, 0.253, 0.326, 0.406
[Epoch  23 (68.77s)]	ELBO: 1516.759, 1616.572, 1658.954, 1678.561, 1683.982 (1684.486)	Log prob: 1524.040, 1629.216, 1675.633, 1698.417, 1705.170 (1705.724)	KLD: 7.282, 12.644, 16.679, 19.856, 21.188 (21.238)	Grad: 0.114, 0.185, 0.254, 0.327, 0.407
[Epoch  24 (84.15s)]	ELBO: 1517.864, 1617.470, 1660.003, 1679.896, 1685.600 (1686.971)	Log prob: 1525.155, 1630.125, 1676.698, 1699.795, 1706.838 (1708.274)	KLD: 7.292, 12.655, 16.696, 19.898, 21.237 (21.302)	Grad: 0.115, 0.187, 0.257, 0.331, 0.410
[Epoch  25 (88.05s)]	ELBO: 1518.612, 1618.305, 1660.903, 1681.166, 1686.969 (1687.545)	Log prob: 1525.901, 1630.952, 1677.579, 1701.065, 1708.221 (1708.814)	KLD: 7.289, 12.646, 16.678, 19.899, 21.252 (21.269)	Grad: 0.114, 0.188, 0.258, 0.333, 0.413
[Epoch  26 (91.24s)]	ELBO: 1519.427, 1619.173, 1661.853, 1682.277, 1688.211 (1689.310)	Log prob: 1526.710, 1631.812, 1678.530, 1702.185, 1709.486 (1710.484)	KLD: 7.283, 12.638, 16.677, 19.910, 21.275 (21.173)	Grad: 0.113, 0.183, 0.250, 0.321, 0.398
[Epoch  27 (72.99s)]	ELBO: 1520.206, 1619.906, 1662.639, 1683.241, 1689.363 (1689.774)	Log prob: 1527.479, 1632.538, 1679.318, 1703.164, 1710.667 (1710.960)	KLD: 7.272, 12.631, 16.681, 19.923, 21.305 (21.186)	Grad: 0.116, 0.188, 0.259, 0.333, 0.414
[Epoch  28 (77.25s)]	ELBO: 1520.888, 1620.742, 1663.388, 1684.137, 1690.384 (1691.681)	Log prob: 1528.160, 1633.368, 1680.068, 1704.068, 1711.705 (1712.970)	KLD: 7.272, 12.626, 16.681, 19.931, 21.319 (21.288)	Grad: 0.114, 0.184, 0.252, 0.323, 0.401
[Epoch  29 (77.51s)]	ELBO: 1521.622, 1621.386, 1664.147, 1685.022, 1691.365 (1691.922)	Log prob: 1528.883, 1634.000, 1680.815, 1704.945, 1712.681 (1713.254)	KLD: 7.260, 12.614, 16.668, 19.922, 21.314 (21.333)	Grad: 0.116, 0.189, 0.259, 0.333, 0.412
[Epoch  30 (68.98s)]	ELBO: 1522.217, 1622.071, 1664.886, 1685.867, 1692.352 (1692.187)	Log prob: 1529.494, 1634.703, 1681.565, 1705.798, 1713.674 (1713.319)	KLD: 7.276, 12.632, 16.679, 19.931, 21.323 (21.131)	Grad: 0.115, 0.188, 0.258, 0.330, 0.409
[Epoch  31 (66.96s)]	ELBO: 1522.674, 1622.617, 1665.545, 1686.445, 1693.057 (1693.675)	Log prob: 1529.942, 1635.243, 1682.219, 1706.388, 1714.400 (1714.854)	KLD: 7.269, 12.626, 16.674, 19.944, 21.342 (21.179)	Grad: 0.117, 0.191, 0.262, 0.338, 0.418
[Epoch  32 (59.52s)]	ELBO: 1523.335, 1623.257, 1666.115, 1687.364, 1693.938 (1694.273)	Log prob: 1530.604, 1635.882, 1682.787, 1707.308, 1715.281 (1715.497)	KLD: 7.268, 12.625, 16.672, 19.943, 21.343 (21.225)	Grad: 0.115, 0.188, 0.259, 0.333, 0.414
[Epoch  33 (56.79s)]	ELBO: 1523.910, 1623.800, 1666.775, 1687.971, 1694.681 (1694.976)	Log prob: 1531.183, 1636.428, 1683.448, 1707.907, 1716.025 (1716.262)	KLD: 7.272, 12.627, 16.674, 19.937, 21.344 (21.287)	Grad: 0.117, 0.189, 0.260, 0.334, 0.413
[Epoch  34 (55.13s)]	ELBO: 1524.430, 1624.398, 1667.404, 1688.582, 1695.379 (1696.026)	Log prob: 1531.698, 1637.013, 1684.068, 1708.506, 1716.707 (1717.495)	KLD: 7.267, 12.614, 16.663, 19.924, 21.328 (21.469)	Grad: 0.117, 0.190, 0.262, 0.336, 0.416
[Epoch  35 (54.94s)]	ELBO: 1524.764, 1624.733, 1667.701, 1688.992, 1695.823 (1696.737)	Log prob: 1532.026, 1637.340, 1684.362, 1708.929, 1717.177 (1717.726)	KLD: 7.262, 12.609, 16.660, 19.938, 21.353 (20.989)	Grad: 0.117, 0.194, 0.267, 0.345, 0.428
[Epoch  36 (56.72s)]	ELBO: 1525.278, 1625.490, 1668.451, 1689.813, 1696.651 (1696.978)	Log prob: 1532.548, 1638.119, 1685.129, 1709.758, 1718.014 (1718.200)	KLD: 7.269, 12.630, 16.680, 19.944, 21.363 (21.222)	Grad: 0.116, 0.189, 0.259, 0.334, 0.413
[Epoch  37 (64.38s)]	ELBO: 1525.939, 1626.124, 1669.130, 1690.542, 1697.375 (1697.840)	Log prob: 1533.206, 1638.750, 1685.810, 1710.489, 1718.743 (1719.426)	KLD: 7.266, 12.626, 16.680, 19.946, 21.369 (21.587)	Grad: 0.116, 0.187, 0.257, 0.330, 0.408
[Epoch  38 (60.85s)]	ELBO: 1526.253, 1626.482, 1669.490, 1690.977, 1697.870 (1698.080)	Log prob: 1533.532, 1639.125, 1686.185, 1710.939, 1719.257 (1719.525)	KLD: 7.280, 12.643, 16.695, 19.962, 21.388 (21.444)	Grad: 0.115, 0.188, 0.257, 0.331, 0.410
[Epoch  39 (65.02s)]	ELBO: 1526.547, 1626.991, 1669.956, 1691.434, 1698.331 (1698.914)	Log prob: 1533.816, 1639.625, 1686.641, 1711.385, 1719.705 (1720.236)	KLD: 7.269, 12.635, 16.684, 19.949, 21.375 (21.322)	Grad: 0.119, 0.193, 0.265, 0.342, 0.424
[Epoch  40 (66.65s)]	ELBO: 1527.157, 1627.518, 1670.517, 1692.014, 1698.955 (1699.138)	Log prob: 1534.420, 1640.145, 1687.195, 1711.963, 1720.343 (1720.431)	KLD: 7.264, 12.627, 16.677, 19.950, 21.389 (21.293)	Grad: 0.116, 0.188, 0.258, 0.332, 0.412
[Epoch  41 (67.96s)]	ELBO: 1527.419, 1627.789, 1670.739, 1692.362, 1699.381 (1699.465)	Log prob: 1534.678, 1640.413, 1687.414, 1712.316, 1720.759 (1720.643)	KLD: 7.259, 12.623, 16.675, 19.956, 21.378 (21.178)	Grad: 0.117, 0.192, 0.263, 0.339, 0.420
[Epoch  42 (69.73s)]	ELBO: 1527.759, 1628.307, 1671.255, 1692.848, 1699.911 (1699.721)	Log prob: 1535.023, 1640.940, 1687.945, 1712.800, 1721.298 (1721.144)	KLD: 7.265, 12.632, 16.690, 19.952, 21.387 (21.423)	Grad: 0.117, 0.189, 0.259, 0.333, 0.413
[Epoch  43 (65.08s)]	ELBO: 1528.341, 1628.794, 1671.752, 1693.392, 1700.454 (1700.222)	Log prob: 1535.605, 1641.433, 1688.442, 1713.348, 1721.859 (1721.666)	KLD: 7.265, 12.640, 16.690, 19.958, 21.405 (21.443)	Grad: 0.116, 0.191, 0.262, 0.337, 0.418
[Epoch  44 (65.33s)]	ELBO: 1528.547, 1629.154, 1672.103, 1693.786, 1700.915 (1701.070)	Log prob: 1535.811, 1641.793, 1688.794, 1713.740, 1722.305 (1722.486)	KLD: 7.265, 12.638, 16.691, 19.953, 21.390 (21.416)	Grad: 0.117, 0.189, 0.260, 0.334, 0.413
[Epoch  45 (74.31s)]	ELBO: 1528.935, 1629.498, 1672.382, 1694.114, 1701.278 (1701.032)	Log prob: 1536.194, 1642.138, 1689.081, 1714.080, 1722.680 (1722.445)	KLD: 7.260, 12.640, 16.699, 19.965, 21.404 (21.413)	Grad: 0.117, 0.192, 0.263, 0.339, 0.420
[Epoch  46 (73.38s)]	ELBO: 1529.238, 1629.980, 1672.898, 1694.592, 1701.777 (1701.542)	Log prob: 1536.503, 1642.625, 1689.590, 1714.547, 1723.184 (1722.970)	KLD: 7.265, 12.645, 16.693, 19.955, 21.407 (21.429)	Grad: 0.118, 0.193, 0.265, 0.342, 0.423
[Epoch  47 (75.01s)]	ELBO: 1529.597, 1630.304, 1673.206, 1694.971, 1702.175 (1701.071)	Log prob: 1536.856, 1642.942, 1689.895, 1714.921, 1723.574 (1722.383)	KLD: 7.259, 12.638, 16.690, 19.951, 21.399 (21.313)	Grad: 0.116, 0.192, 0.262, 0.338, 0.419
[Epoch  48 (79.70s)]	ELBO: 1529.691, 1630.587, 1673.602, 1695.310, 1702.608 (1702.489)	Log prob: 1536.943, 1643.236, 1690.312, 1715.282, 1724.032 (1723.636)	KLD: 7.254, 12.649, 16.709, 19.974, 21.423 (21.147)	Grad: 0.118, 0.192, 0.262, 0.338, 0.418
[Epoch  49 (76.19s)]	ELBO: 1530.087, 1630.910, 1673.835, 1695.663, 1702.938 (1701.870)	Log prob: 1537.355, 1643.573, 1690.546, 1715.645, 1724.373 (1723.362)	KLD: 7.268, 12.662, 16.711, 19.982, 21.435 (21.492)	Grad: 0.118, 0.195, 0.268, 0.346, 0.430
[Epoch  50 (72.14s)]	ELBO: 1530.396, 1631.428, 1674.352, 1696.120, 1703.522 (1702.769)	Log prob: 1537.656, 1644.085, 1691.062, 1716.098, 1724.956 (1724.182)	KLD: 7.261, 12.655, 16.709, 19.978, 21.436 (21.413)	Grad: 0.118, 0.191, 0.261, 0.337, 0.417
[Epoch  51 (68.25s)]	ELBO: 1530.684, 1631.647, 1674.511, 1696.408, 1703.727 (1703.679)	Log prob: 1537.940, 1644.306, 1691.227, 1716.386, 1725.163 (1725.034)	KLD: 7.256, 12.660, 16.715, 19.978, 21.437 (21.355)	Grad: 0.119, 0.192, 0.265, 0.342, 0.423
[Epoch  52 (78.39s)]	ELBO: 1530.958, 1632.028, 1675.009, 1696.736, 1704.188 (1703.813)	Log prob: 1538.223, 1644.702, 1691.739, 1716.728, 1725.641 (1725.290)	KLD: 7.265, 12.675, 16.731, 19.993, 21.453 (21.477)	Grad: 0.116, 0.190, 0.260, 0.336, 0.416
[Epoch  53 (78.38s)]	ELBO: 1531.096, 1632.260, 1675.166, 1697.020, 1704.478 (1704.459)	Log prob: 1538.354, 1644.918, 1691.876, 1717.005, 1725.925 (1725.772)	KLD: 7.257, 12.659, 16.712, 19.984, 21.447 (21.313)	Grad: 0.117, 0.192, 0.263, 0.340, 0.421
[Epoch  54 (68.49s)]	ELBO: 1531.393, 1632.659, 1675.493, 1697.385, 1704.922 (1704.464)	Log prob: 1538.654, 1645.333, 1692.224, 1717.388, 1726.383 (1725.683)	KLD: 7.262, 12.674, 16.732, 20.001, 21.461 (21.219)	Grad: 0.116, 0.190, 0.262, 0.339, 0.420
[Epoch  55 (69.92s)]	ELBO: 1531.762, 1632.872, 1675.773, 1697.691, 1705.177 (1704.107)	Log prob: 1539.011, 1645.542, 1692.495, 1717.691, 1726.645 (1725.620)	KLD: 7.250, 12.670, 16.722, 19.999, 21.467 (21.513)	Grad: 0.118, 0.195, 0.269, 0.347, 0.430
[Epoch  56 (63.48s)]	ELBO: 1532.017, 1633.258, 1676.248, 1698.127, 1705.706 (1705.344)	Log prob: 1539.275, 1645.932, 1692.986, 1718.142, 1727.182 (1726.961)	KLD: 7.257, 12.675, 16.737, 20.014, 21.474 (21.616)	Grad: 0.116, 0.190, 0.260, 0.334, 0.414
[Epoch  57 (62.69s)]	ELBO: 1532.413, 1633.563, 1676.519, 1698.403, 1705.968 (1705.662)	Log prob: 1539.665, 1646.235, 1693.245, 1718.403, 1727.426 (1727.063)	KLD: 7.252, 12.672, 16.728, 20.000, 21.459 (21.401)	Grad: 0.116, 0.190, 0.260, 0.335, 0.415
[Epoch  58 (59.91s)]	ELBO: 1532.487, 1633.641, 1676.735, 1698.646, 1706.154 (1703.205)	Log prob: 1539.739, 1646.328, 1693.479, 1718.659, 1727.639 (1724.527)	KLD: 7.253, 12.686, 16.745, 20.013, 21.485 (21.322)	Grad: 0.118, 0.194, 0.266, 0.343, 0.425
[Epoch  59 (70.44s)]	ELBO: 1532.659, 1633.849, 1676.839, 1698.829, 1706.355 (1704.883)	Log prob: 1539.905, 1646.527, 1693.583, 1718.847, 1727.843 (1726.430)	KLD: 7.246, 12.677, 16.743, 20.019, 21.488 (21.548)	Grad: 0.117, 0.194, 0.268, 0.346, 0.429
[Epoch  60 (68.25s)]	ELBO: 1532.871, 1634.238, 1677.243, 1699.150, 1706.718 (1705.599)	Log prob: 1540.120, 1646.920, 1693.981, 1719.159, 1728.193 (1726.982)	KLD: 7.249, 12.683, 16.739, 20.010, 21.474 (21.382)	Grad: 0.118, 0.194, 0.267, 0.347, 0.431
[Epoch  61 (74.54s)]	ELBO: 1533.222, 1634.430, 1677.594, 1699.498, 1707.078 (1706.662)	Log prob: 1540.479, 1647.120, 1694.340, 1719.522, 1728.562 (1728.194)	KLD: 7.257, 12.690, 16.746, 20.022, 21.486 (21.532)	Grad: 0.115, 0.190, 0.261, 0.337, 0.418
[Epoch  62 (75.33s)]	ELBO: 1533.266, 1634.599, 1677.644, 1699.602, 1707.205 (1705.863)	Log prob: 1540.519, 1647.293, 1694.406, 1719.650, 1728.721 (1727.424)	KLD: 7.253, 12.694, 16.762, 20.049, 21.516 (21.562)	Grad: 0.117, 0.193, 0.265, 0.343, 0.426
[Epoch  63 (79.93s)]	ELBO: 1533.619, 1634.922, 1678.050, 1700.006, 1707.558 (1706.984)	Log prob: 1540.869, 1647.614, 1694.808, 1720.037, 1729.055 (1728.431)	KLD: 7.249, 12.692, 16.757, 20.032, 21.497 (21.446)	Grad: 0.114, 0.190, 0.262, 0.339, 0.422
[Epoch  64 (81.19s)]	ELBO: 1533.964, 1635.176, 1678.230, 1700.185, 1707.781 (1707.381)	Log prob: 1541.206, 1647.856, 1694.972, 1720.207, 1729.275 (1728.937)	KLD: 7.243, 12.680, 16.743, 20.021, 21.494 (21.556)	Grad: 0.115, 0.192, 0.265, 0.343, 0.426
[Epoch  65 (76.88s)]	ELBO: 1534.020, 1635.298, 1678.450, 1700.464, 1708.062 (1707.334)	Log prob: 1541.276, 1648.001, 1695.217, 1720.510, 1729.589 (1728.724)	KLD: 7.256, 12.703, 16.766, 20.047, 21.528 (21.390)	Grad: 0.117, 0.192, 0.265, 0.344, 0.427
[Epoch  66 (93.55s)]	ELBO: 1534.270, 1635.493, 1678.665, 1700.695, 1708.343 (1708.033)	Log prob: 1541.525, 1648.196, 1695.429, 1720.743, 1729.859 (1729.360)	KLD: 7.254, 12.703, 16.764, 20.047, 21.515 (21.327)	Grad: 0.117, 0.192, 0.264, 0.341, 0.422
[Epoch  67 (98.16s)]	ELBO: 1534.499, 1635.750, 1678.927, 1700.939, 1708.583 (1707.222)	Log prob: 1541.759, 1648.460, 1695.696, 1720.983, 1730.098 (1728.780)	KLD: 7.259, 12.710, 16.768, 20.045, 21.513 (21.557)	Grad: 0.118, 0.194, 0.267, 0.345, 0.428
[Epoch  68 (92.13s)]	ELBO: 1534.619, 1636.010, 1679.157, 1701.108, 1708.685 (1707.792)	Log prob: 1541.872, 1648.708, 1695.919, 1721.150, 1730.198 (1729.467)	KLD: 7.254, 12.698, 16.762, 20.043, 21.513 (21.675)	Grad: 0.117, 0.193, 0.266, 0.345, 0.429
[Epoch  69 (75.50s)]	ELBO: 1534.699, 1636.019, 1679.340, 1701.295, 1708.930 (1708.201)	Log prob: 1541.954, 1648.727, 1696.119, 1721.354, 1730.467 (1729.580)	KLD: 7.255, 12.708, 16.780, 20.058, 21.537 (21.379)	Grad: 0.116, 0.191, 0.263, 0.340, 0.422
[Epoch  70 (72.46s)]	ELBO: 1534.939, 1636.305, 1679.625, 1701.543, 1709.110 (1707.720)	Log prob: 1542.189, 1649.013, 1696.392, 1721.595, 1730.644 (1729.216)	KLD: 7.250, 12.707, 16.767, 20.051, 21.534 (21.495)	Grad: 0.116, 0.190, 0.261, 0.339, 0.421
[Epoch  71 (79.80s)]	ELBO: 1535.080, 1636.471, 1679.760, 1701.721, 1709.384 (1708.023)	Log prob: 1542.338, 1649.191, 1696.545, 1721.790, 1730.931 (1729.552)	KLD: 7.258, 12.721, 16.784, 20.068, 21.547 (21.530)	Grad: 0.118, 0.194, 0.268, 0.346, 0.429
[Epoch  72 (81.09s)]	ELBO: 1535.243, 1636.662, 1679.982, 1702.038, 1709.580 (1708.715)	Log prob: 1542.507, 1649.388, 1696.785, 1722.120, 1731.135 (1730.033)	KLD: 7.263, 12.726, 16.802, 20.081, 21.554 (21.317)	Grad: 0.117, 0.192, 0.264, 0.341, 0.423
[Epoch  73 (79.95s)]	ELBO: 1535.391, 1636.812, 1680.079, 1702.103, 1709.636 (1708.862)	Log prob: 1542.651, 1649.537, 1696.872, 1722.181, 1731.190 (1730.366)	KLD: 7.260, 12.724, 16.793, 20.078, 21.555 (21.504)	Grad: 0.118, 0.193, 0.267, 0.347, 0.431
[Epoch  74 (78.46s)]	ELBO: 1535.682, 1637.047, 1680.403, 1702.462, 1710.002 (1708.360)	Log prob: 1542.942, 1649.771, 1697.205, 1722.554, 1731.569 (1729.741)	KLD: 7.260, 12.723, 16.801, 20.093, 21.569 (21.381)	Grad: 0.118, 0.193, 0.266, 0.344, 0.427
[Epoch  75 (80.48s)]	ELBO: 1535.731, 1637.131, 1680.496, 1702.503, 1710.044 (1708.938)	Log prob: 1542.997, 1649.857, 1697.292, 1722.575, 1731.583 (1730.430)	KLD: 7.264, 12.726, 16.795, 20.071, 21.540 (21.492)	Grad: 0.118, 0.195, 0.269, 0.348, 0.431
[Epoch  76 (61.47s)]	ELBO: 1536.106, 1637.441, 1680.795, 1702.780, 1710.316 (1708.750)	Log prob: 1543.376, 1650.175, 1697.601, 1722.875, 1731.890 (1730.124)	KLD: 7.270, 12.735, 16.806, 20.095, 21.574 (21.374)	Grad: 0.116, 0.191, 0.264, 0.342, 0.425
[Epoch  77 (72.41s)]	ELBO: 1536.229, 1637.710, 1681.052, 1702.941, 1710.513 (1709.332)	Log prob: 1543.495, 1650.445, 1697.857, 1723.031, 1732.083 (1730.977)	KLD: 7.266, 12.735, 16.805, 20.091, 21.571 (21.645)	Grad: 0.117, 0.190, 0.262, 0.340, 0.422
[Epoch  78 (61.68s)]	ELBO: 1536.366, 1637.794, 1681.262, 1703.224, 1710.781 (1709.314)	Log prob: 1543.635, 1650.537, 1698.079, 1723.327, 1732.353 (1730.793)	KLD: 7.270, 12.743, 16.816, 20.102, 21.572 (21.479)	Grad: 0.115, 0.189, 0.259, 0.336, 0.417
[Epoch  79 (61.32s)]	ELBO: 1536.517, 1637.972, 1681.336, 1703.405, 1710.847 (1709.185)	Log prob: 1543.785, 1650.711, 1698.154, 1723.505, 1732.421 (1730.699)	KLD: 7.267, 12.740, 16.818, 20.099, 21.574 (21.513)	Grad: 0.118, 0.191, 0.264, 0.343, 0.426
[Epoch  80 (64.71s)]	ELBO: 1536.526, 1638.033, 1681.500, 1703.449, 1711.048 (1709.494)	Log prob: 1543.793, 1650.776, 1698.319, 1723.553, 1732.628 (1731.042)	KLD: 7.268, 12.743, 16.818, 20.105, 21.579 (21.548)	Grad: 0.117, 0.193, 0.266, 0.344, 0.426
[Epoch  81 (69.96s)]	ELBO: 1536.830, 1638.186, 1681.690, 1703.654, 1711.198 (1709.421)	Log prob: 1544.110, 1650.945, 1698.523, 1723.774, 1732.795 (1731.150)	KLD: 7.280, 12.759, 16.833, 20.120, 21.597 (21.730)	Grad: 0.115, 0.190, 0.263, 0.341, 0.423
[Epoch  82 (67.23s)]	ELBO: 1536.892, 1638.248, 1681.824, 1703.857, 1711.336 (1710.267)	Log prob: 1544.154, 1650.977, 1698.623, 1723.935, 1732.888 (1731.709)	KLD: 7.263, 12.729, 16.800, 20.078, 21.551 (21.442)	Grad: 0.118, 0.192, 0.266, 0.343, 0.426
[Epoch  83 (68.16s)]	ELBO: 1537.146, 1638.575, 1682.189, 1704.131, 1711.655 (1709.792)	Log prob: 1544.422, 1651.333, 1699.022, 1724.250, 1733.249 (1731.283)	KLD: 7.277, 12.758, 16.834, 20.119, 21.594 (21.491)	Grad: 0.117, 0.191, 0.264, 0.342, 0.424
[Epoch  84 (64.28s)]	ELBO: 1537.198, 1638.698, 1682.170, 1704.167, 1711.625 (1710.451)	Log prob: 1544.475, 1651.452, 1699.004, 1724.286, 1733.221 (1732.073)	KLD: 7.276, 12.754, 16.832, 20.120, 21.597 (21.622)	Grad: 0.116, 0.191, 0.264, 0.343, 0.426
[Epoch  85 (63.83s)]	ELBO: 1537.440, 1638.884, 1682.425, 1704.416, 1711.907 (1710.210)	Log prob: 1544.712, 1651.637, 1699.264, 1724.530, 1733.488 (1731.544)	KLD: 7.272, 12.754, 16.839, 20.113, 21.581 (21.334)	Grad: 0.117, 0.192, 0.264, 0.343, 0.426
[Epoch  86 (65.98s)]	ELBO: 1537.486, 1638.901, 1682.529, 1704.456, 1711.948 (1710.059)	Log prob: 1544.760, 1651.651, 1699.362, 1724.575, 1733.544 (1731.747)	KLD: 7.274, 12.750, 16.833, 20.118, 21.597 (21.688)	Grad: 0.118, 0.191, 0.263, 0.341, 0.424
[Epoch  87 (69.00s)]	ELBO: 1537.474, 1638.916, 1682.598, 1704.512, 1711.945 (1710.548)	Log prob: 1544.760, 1651.685, 1699.445, 1724.640, 1733.549 (1732.070)	KLD: 7.284, 12.768, 16.847, 20.128, 21.604 (21.521)	Grad: 0.118, 0.194, 0.267, 0.347, 0.430
[Epoch  88 (64.56s)]	ELBO: 1537.763, 1639.119, 1682.777, 1704.703, 1712.172 (1711.112)	Log prob: 1545.035, 1651.873, 1699.606, 1724.825, 1733.776 (1732.896)	KLD: 7.272, 12.755, 16.829, 20.123, 21.604 (21.784)	Grad: 0.118, 0.193, 0.267, 0.347, 0.431
[Epoch  89 (57.09s)]	ELBO: 1537.912, 1639.444, 1683.109, 1705.044, 1712.448 (1711.088)	Log prob: 1545.200, 1652.215, 1699.960, 1725.180, 1734.060 (1732.706)	KLD: 7.287, 12.771, 16.851, 20.137, 21.612 (21.618)	Grad: 0.116, 0.190, 0.263, 0.341, 0.424
[Epoch  90 (52.90s)]	ELBO: 1538.199, 1639.531, 1683.209, 1705.171, 1712.645 (1711.155)	Log prob: 1545.482, 1652.296, 1700.058, 1725.310, 1734.256 (1732.675)	KLD: 7.284, 12.764, 16.850, 20.139, 21.611 (21.520)	Grad: 0.116, 0.191, 0.265, 0.344, 0.427
[Epoch  91 (51.65s)]	ELBO: 1538.109, 1639.583, 1683.291, 1705.207, 1712.633 (1711.789)	Log prob: 1545.394, 1652.351, 1700.141, 1725.339, 1734.240 (1733.260)	KLD: 7.286, 12.768, 16.849, 20.132, 21.606 (21.471)	Grad: 0.118, 0.191, 0.265, 0.343, 0.426
[Epoch  92 (51.69s)]	ELBO: 1538.406, 1639.667, 1683.431, 1705.480, 1712.853 (1710.491)	Log prob: 1545.687, 1652.440, 1700.289, 1725.632, 1734.473 (1732.241)	KLD: 7.281, 12.773, 16.857, 20.150, 21.620 (21.750)	Grad: 0.117, 0.193, 0.267, 0.347, 0.430
[Epoch  93 (52.62s)]	ELBO: 1538.424, 1639.893, 1683.578, 1705.526, 1712.923 (1710.799)	Log prob: 1545.714, 1652.667, 1700.437, 1725.670, 1734.533 (1732.665)	KLD: 7.290, 12.774, 16.858, 20.144, 21.610 (21.866)	Grad: 0.118, 0.193, 0.267, 0.347, 0.431
[Epoch  94 (64.62s)]	ELBO: 1538.568, 1639.952, 1683.763, 1705.602, 1713.127 (1711.205)	Log prob: 1545.851, 1652.722, 1700.628, 1725.747, 1734.746 (1732.496)	KLD: 7.284, 12.770, 16.862, 20.144, 21.618 (21.291)	Grad: 0.116, 0.192, 0.266, 0.346, 0.431
[Epoch  95 (50.55s)]	ELBO: 1538.728, 1640.040, 1683.873, 1705.822, 1713.196 (1710.816)	Log prob: 1546.028, 1652.828, 1700.753, 1725.986, 1734.822 (1732.578)	KLD: 7.299, 12.789, 16.879, 20.165, 21.626 (21.762)	Grad: 0.115, 0.189, 0.262, 0.339, 0.421
[Epoch  96 (46.61s)]	ELBO: 1539.005, 1640.354, 1684.008, 1705.971, 1713.362 (1711.565)	Log prob: 1546.291, 1653.128, 1700.868, 1726.120, 1734.985 (1732.983)	KLD: 7.286, 12.773, 16.859, 20.148, 21.622 (21.417)	Grad: 0.116, 0.191, 0.265, 0.345, 0.428
[Epoch  97 (44.02s)]	ELBO: 1538.931, 1640.408, 1684.174, 1706.136, 1713.568 (1711.543)	Log prob: 1546.238, 1653.203, 1701.054, 1726.303, 1735.208 (1733.232)	KLD: 7.308, 12.795, 16.879, 20.166, 21.639 (21.689)	Grad: 0.115, 0.189, 0.261, 0.339, 0.422
[Epoch  98 (48.74s)]	ELBO: 1539.207, 1640.596, 1684.500, 1706.339, 1713.768 (1711.258)	Log prob: 1546.505, 1653.386, 1701.379, 1726.499, 1735.406 (1732.775)	KLD: 7.298, 12.790, 16.878, 20.160, 21.637 (21.517)	Grad: 0.116, 0.190, 0.262, 0.341, 0.423
[Epoch  99 (43.21s)]	ELBO: 1539.080, 1640.419, 1684.319, 1706.199, 1713.621 (1711.703)	Log prob: 1546.369, 1653.212, 1701.198, 1726.371, 1735.265 (1733.392)	KLD: 7.290, 12.793, 16.881, 20.172, 21.644 (21.689)	Grad: 0.119, 0.194, 0.270, 0.351, 0.436
[Epoch 100 (31.11s)]	ELBO: 1539.392, 1640.753, 1684.622, 1706.550, 1713.962 (1712.614)	Log prob: 1546.692, 1653.555, 1701.516, 1726.740, 1735.625 (1734.189)	KLD: 7.300, 12.803, 16.894, 20.190, 21.662 (21.575)	Grad: 0.115, 0.188, 0.260, 0.337, 0.418
Best epoch(s): [100]	Training time(s): 6729.23s (6729.23s)	Best ELBO: 1713.962 (1712.614)	Best log prob: 1735.625 (1734.189)
Avg. mu: 0.144, -0.054, 0.080, -0.068, -0.130, -0.053, -0.051, 0.029, 0.001, -0.014
Avg. var: 0.001, 0.001, 0.005, 0.004, 0.017, 0.017, 0.035, 0.039, 0.057, 1.022
Max. mu: 4.223, 3.213, 4.180, 3.713, 3.134, 3.630, 4.557, 3.324, 3.743, 0.697
Max. var: 0.004, 0.006, 0.033, 0.032, 0.047, 0.068, 0.173, 0.207, 0.134, 5.454
Min. mu: -3.699, -3.647, -3.442, -3.364, -4.232, -2.891, -3.812, -3.840, -4.224, -0.851
Min. var: 0.000, 0.000, 0.001, 0.001, 0.005, 0.006, 0.009, 0.009, 0.012, 0.220
Cov. mu:
[[1.442 0.130 0.022 0.050 0.002 0.172 0.063 0.000 -0.059 -0.007]
 [0.130 1.586 0.304 -0.077 -0.024 -0.092 0.045 -0.034 -0.097 0.040]
 [0.022 0.304 0.977 -0.057 -0.004 -0.114 -0.053 -0.029 -0.055 0.035]
 [0.050 -0.077 -0.057 0.952 0.050 -0.028 0.029 0.069 0.002 0.003]
 [0.002 -0.024 -0.004 0.050 0.918 0.064 0.036 0.035 0.018 0.045]
 [0.172 -0.092 -0.114 -0.028 0.064 0.968 -0.049 -0.017 -0.025 0.031]
 [0.063 0.045 -0.053 0.029 0.036 -0.049 0.831 0.067 0.017 0.020]
 [0.000 -0.034 -0.029 0.069 0.035 -0.017 0.067 0.895 -0.027 -0.004]
 [-0.059 -0.097 -0.055 0.002 0.018 -0.025 0.017 -0.027 0.813 0.042]
 [-0.007 0.040 0.035 0.003 0.045 0.031 0.020 -0.004 0.042 0.022]]
Avg. mu: 0.144, -0.054, 0.080, -0.068, -0.130, -0.053, -0.051, 0.029, 0.001, -0.014
Avg. var: 0.001, 0.001, 0.005, 0.004, 0.017, 0.017, 0.035, 0.039, 0.057, 1.022
Max. mu: 4.223, 3.213, 4.180, 3.713, 3.134, 3.630, 4.557, 3.324, 3.743, 0.697
Max. var: 0.004, 0.006, 0.033, 0.032, 0.047, 0.068, 0.173, 0.207, 0.134, 5.454
Min. mu: -3.699, -3.647, -3.442, -3.364, -4.232, -2.891, -3.812, -3.840, -4.224, -0.851
Min. var: 0.000, 0.000, 0.001, 0.001, 0.005, 0.006, 0.009, 0.009, 0.012, 0.220
Cov. mu:
[[1.442 0.130 0.022 0.050 0.002 0.172 0.063 0.000 -0.059 -0.007]
 [0.130 1.586 0.304 -0.077 -0.024 -0.092 0.045 -0.034 -0.097 0.040]
 [0.022 0.304 0.977 -0.057 -0.004 -0.114 -0.053 -0.029 -0.055 0.035]
 [0.050 -0.077 -0.057 0.952 0.050 -0.028 0.029 0.069 0.002 0.003]
 [0.002 -0.024 -0.004 0.050 0.918 0.064 0.036 0.035 0.018 0.045]
 [0.172 -0.092 -0.114 -0.028 0.064 0.968 -0.049 -0.017 -0.025 0.031]
 [0.063 0.045 -0.053 0.029 0.036 -0.049 0.831 0.067 0.017 0.020]
 [0.000 -0.034 -0.029 0.069 0.035 -0.017 0.067 0.895 -0.027 -0.004]
 [-0.059 -0.097 -0.055 0.002 0.018 -0.025 0.017 -0.027 0.813 0.042]
 [-0.007 0.040 0.035 0.003 0.045 0.031 0.020 -0.004 0.042 0.022]]
